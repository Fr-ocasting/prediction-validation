{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utilities_DL import get_DataSet_and_invalid_dates,get_MultiModel_loss_args_emb_opts,load_init_trainer\n",
    "from DL_class import MultiModelTrainer, Trainer\n",
    "from config import get_args\n",
    "from save_results import build_results_df\n",
    "from paths import folder_path,file_name,get_save_directory\n",
    "import time \n",
    "import torch\n",
    "\n",
    "import ray \n",
    "from ray import tune \n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "# ==== GET PARAMETERS ====\n",
    "# Load config\n",
    "model_name = 'STGCN' #'CNN' \n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification :\n",
    "args.epochs = 1\n",
    "args.K_fold = 6   # Means we will use the first fold for the Ray Tuning and the 5 other ones to get the metrics\n",
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    args.batch_size = 256\n",
    "else :\n",
    "    args.device = 'cpu'\n",
    "    args.batch_size = 32\n",
    "\n",
    "\n",
    "args.loss_function_type = 'MSE' #'quantile' #'MSE'\n",
    "\n",
    "if args.loss_function_type == 'MSE':\n",
    "    args.out_dim = 1\n",
    "    args.alpha = None\n",
    "    args.type_calendar = 'tuple'\n",
    "\n",
    "else:\n",
    "    args.embedding_dim = 3\n",
    "    args.calendar_class = 3\n",
    "    args.position = 'input'\n",
    "    args.specific_lr = False\n",
    "    args.type_calendar = 'tuple'\n",
    "    args.out_dim = 2\n",
    "    args.alpha = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"lr\": tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "          \"weight_decay\" : tune.uniform(0.0005, 0.1),\n",
    "          \"momentum\" : tune.uniform(0.85, 0.99),\n",
    "          \"dropout\" : tune.uniform(0,0.9),\n",
    "        }\n",
    "\n",
    "config_embedding = {'calendar_class' : tune.choice([1,2,3]),\n",
    "                    'embedding_dim' : tune.choice([2,3,4,5,6]),\n",
    "                    'multi_embedding' : tune.choice([True,False]),\n",
    "                    'TE_transfer' : tune.choice([True,False]),\n",
    "                    }\n",
    "\n",
    "\n",
    "config_stgcn = {\"Kt\" : tune.choice([2,3,4]),\n",
    "                \"stblock_num\" : tune.choice([1,2,3,4]),\n",
    "                \"act_fun\" : tune.choice(['glu','gtu']),\n",
    "                \"Ks\" :  tune.choice([2,3]),\n",
    "                \"graph_conv_type\" : tune.choice(['cheb_graph_conv','graph_conv']),\n",
    "                \"gso_type\" : tune.choice(['sym_norm_lap', 'rw_norm_lap', 'sym_renorm_adj', 'rw_renorm_adj']),\n",
    "                \"adj_type\" : 'dist',\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.time_embedding:\n",
    "    config.update(config_embedding)\n",
    "\n",
    "if args.model_name == 'STGCN':\n",
    "     config.update(config_stgcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning sur le Fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage period: 2019-01-01 00:00:00 - 2020-01-01 00:00:00\n",
      "Time-step per hour: 4.0\n"
     ]
    }
   ],
   "source": [
    "Datasets,DataLoader_list,dic_class2rpz,nb_words_embedding,time_slots_labels,dic_rpz2class = load_init_trainer(folder_path,file_name,args)\n",
    "\n",
    "critical_keys = ['train_prop','valid_prop','test_prop','calib_prop',\n",
    "                 'batch_size','calendar_class','validation','K_fold',\n",
    "              'W','D','H','step_ahead','single_station'] \n",
    "\n",
    "def Ray_Trainer(config,folder_path,file_name,args):\n",
    "    print('start ray trainer')\n",
    "\n",
    "    for key, value in config.items():\n",
    "        if hasattr(args, key):\n",
    "            setattr(args, key, value)\n",
    "    \n",
    "    # Particulièrement long (13s), donc on évite de le relancer à chaque fois si pas nécessaire\n",
    "    if sum([key in critical_keys for key in  config.keys()]) > 0 : \n",
    "        print(\"Need to run 'load_init_trainer' at each iteragtion, which may take some time\")\n",
    "        Datasets,DataLoader_list,dic_class2rpz,nb_words_embedding,time_slots_labels,dic_rpz2class = load_init_trainer(folder_path,file_name,args)\n",
    "\n",
    "    # Load associated K_folds Models: \n",
    "    (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz,n_vertex = len(Datasets[0].columns))\n",
    "\n",
    "    dataset,dataloader,model,optimizer = Datasets[0],DataLoader_list[0],Model_list[0],Optimizer_list[0]\n",
    "\n",
    "    trainer = Trainer(dataset,model,dataloader,\n",
    "                    args,optimizer,loss_function,scheduler = None,\n",
    "                    args_embedding=args_embedding,\n",
    "                    save_dir = None,dic_class2rpz=dic_class2rpz)\n",
    "    \n",
    "    print('\\ start training')\n",
    "    results_df = trainer.train_and_valid()\n",
    "    print('\\ end training \\n')\n",
    "\n",
    "analysis = tune.run(\n",
    "        lambda config: Ray_Trainer(config,folder_path,file_name,args),\n",
    "        config=config,\n",
    "        num_samples=5,  # Increase num_samples for more random combinations\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage period: 2019-01-01 00:00:00 - 2020-01-01 00:00:00\n",
      "Time-step per hour: 4.0\n"
     ]
    }
   ],
   "source": [
    "# Load associated K_folds Models: \n",
    "Datasets,DataLoader_list,dic_class2rpz,nb_words_embedding,time_slots_labels,dic_rpz2class = load_init_trainer(folder_path,file_name,args)\n",
    "(loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz,n_vertex = len(Datasets[0].columns))\n",
    "dataset,dataloader,model,optimizer = Datasets[0],DataLoader_list[0],Model_list[0],Optimizer_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tune.run()\n"
     ]
    }
   ],
   "source": [
    "def Ray_Trainer(config):\n",
    "    trainer = Trainer(dataset,model,dataloader,\n",
    "                    args,optimizer,loss_function,scheduler = None,\n",
    "                    args_embedding=args_embedding,\n",
    "                    save_dir = None,dic_class2rpz=dic_class2rpz)\n",
    "    results_df = trainer.train_and_valid()\n",
    "\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "analysis = tune.run(\n",
    "        lambda config: Ray_Trainer(config,folder_path,file_name,args),\n",
    "        config=config,\n",
    "        num_samples=5,  # Increase num_samples for more random combinations\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des hyperparamer en fonction du Tuning. Puis Cross Validation sur les 5 Fold Restant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refaire l'initialisation avec les args adapté .... \n",
    "#\n",
    "#\n",
    "#\n",
    "args =  ... \n",
    "results_df = pd.DataFrame()\n",
    "save_dir = get_save_directory(args)\n",
    "\n",
    "multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "\n",
    "(results_by_fold,mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds) = multimodeltrainer.K_fold_validation(mod_plot = 10)\n",
    "results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "\n",
    "# Svae results \n",
    "results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds)\n",
    "results_df.to_csv(f\"{args.model_name}_{args.loss_function_type}_H{args.H}_D{args.D}_W{args.W}_E{args.epochs}_K_fold{args.K_fold}_Emb_dim{args.embedding_dim}FC1_17_8_FC2_8_4_save_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Parameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "model_name = 'STGCN' #'CNN' \n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification : \n",
    "args.epochs = 1\n",
    "args.K_fold = 1\n",
    "\n",
    "args.loss_function_type = 'MSE'\n",
    "args.out_dim = 1\n",
    "args.alpha = None\n",
    "# Save Directory:\n",
    "main_dir = get_save_directory(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fixed Dataset K_fold split for each trial: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and invalid_dates\n",
    "dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,args.W,args.D,args.H,args.step_ahead,single_station = False)\n",
    "\n",
    "# Train / Valid / Test split and Normalize for K-fold \n",
    "(Datasets,DataLoader_list,time_slots_labels_list,dic_class2rpz,dic_rpz2class,nb_words_embedding) =  dataset.split_K_fold(args,invalid_dates)\n",
    "\n",
    "# Plot information about split and folds:\n",
    "plot_k_fold_split(Datasets,invalid_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test complet sur les 3 Top STGCN, avec sauvegarde du model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "\n",
    "#for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3,1,3],['input','input','input'],[True,True,False],['tuple','tuple','tuple'])):\n",
    "for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3],['input'],[True],['tuple'])):\n",
    "\n",
    "    args.calendar_class = calendar_class\n",
    "    args.position = position\n",
    "    args.specific_lr = specific_lr\n",
    "    args.type_calendar = type_calendar\n",
    "\n",
    "    save_dir = get_save_directory(args)\n",
    "\n",
    "    # Load dataset and invalid_dates \n",
    "    dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,args.W,args.D,args.H,args.step_ahead,single_station = False)\n",
    "    (Datasets,DataLoader_list,time_slots_labels,dic_class2rpz,dic_rpz2class,nb_words_embedding) =  dataset.split_K_fold(args,invalid_dates)\n",
    "    \n",
    "    # Load associated K_folds Models: \n",
    "    (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz)\n",
    "    multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "    (results_by_fold,mean_picp,mean_mpiw,dict_last,dict_scores) = multimodeltrainer.K_fold_validation(mod_plot = 1)\n",
    "    results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "    \n",
    "    # Svae results \n",
    "    results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last,dict_scores)\n",
    "                            \n",
    "results_df.to_csv('save_results.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== GET PARAMETERS ====\n",
    "# Load config\n",
    "model_name = 'STGCN' #'CNN' \n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification : \n",
    "args.epochs = 300\n",
    "\n",
    "# Save Directory:\n",
    "main_dir = get_save_directory(args)\n",
    "args.H = 0\n",
    "args.W = 0\n",
    "args.D = 0\n",
    "args.L =args.H+args.W+args.D\n",
    "args.single_station = True\n",
    "# ==== TEST  ====\n",
    "for K_fold in [5]:\n",
    "    args.K_fold = K_fold\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    #for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3,1,3],['input','input','input'],[True,True,False],['tuple','tuple','tuple'])):\n",
    "    #for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3],['input'],[True],['tuple'])):\n",
    "    for i,(embedding_dim,calendar_class,position,specific_lr, type_calendar,time_embedding) in enumerate(zip([3], # None\n",
    "                                                                                                             [3], # 3\n",
    "                                                                                               ['input'], # None\n",
    "                                                                                               [False], # None \n",
    "                                                                                               ['tuple'], # None\n",
    "                                                                                               [True] # False\n",
    "                                                                                              )\n",
    "                                                                                            ):\n",
    "        args.embedding_dim = embedding_dim\n",
    "        args.calendar_class = calendar_class\n",
    "        args.position = position\n",
    "        args.specific_lr = specific_lr\n",
    "        args.type_calendar = type_calendar\n",
    "        args.time_embedding = time_embedding\n",
    "\n",
    "        save_dir = get_save_directory(args)\n",
    "\n",
    "        # Load dataset and invalid_dates \n",
    "        dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,args.W,args.D,args.H,args.step_ahead,single_station = args.single_station)\n",
    "        (Datasets,DataLoader_list,time_slots_labels,dic_class2rpz,dic_rpz2class,nb_words_embedding) =  dataset.split_K_fold(args,invalid_dates)\n",
    "\n",
    "        # Load associated K_folds Models: \n",
    "        (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz)\n",
    "        multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "        \n",
    "        (results_by_fold,mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds) = multimodeltrainer.K_fold_validation(mod_plot = 10)\n",
    "        results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "\n",
    "        # Svae results \n",
    "        results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds)\n",
    "        results_df.to_csv(f\"{args.model_name}_H{args.H}_D{args.D}_W{args.W}_E{args.epochs}_K_fold{args.K_fold}_Emb_dim{args.embedding_dim}FC1_17_8_FC2_8_4_save_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
