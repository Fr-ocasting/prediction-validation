{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utilities_DL import get_DataSet_and_invalid_dates,get_MultiModel_loss_args_emb_opts,load_init_trainer\n",
    "from DL_class import MultiModelTrainer, Trainer\n",
    "from config import get_args\n",
    "from save_results import build_results_df\n",
    "from paths import folder_path,file_name,get_save_directory\n",
    "import time \n",
    "import torch\n",
    "import argparse\n",
    "\n",
    "from ray_config import get_ray_config\n",
    "import ray \n",
    "from ray import tune \n",
    "\n",
    "# ==== GET PARAMETERS ====\n",
    "# Load config\n",
    "model_name = 'STGCN'  #'CNN'\n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification :\n",
    "args.epochs = 2\n",
    "args.K_fold = 6   # Means we will use the first fold for the Ray Tuning and the 5 other ones to get the metrics\n",
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    args.batch_size = 256\n",
    "else :\n",
    "    args.device = 'cpu'\n",
    "    args.batch_size = 32\n",
    "\n",
    "args.single_station = True\n",
    "args.ray = True\n",
    "\n",
    "args.loss_function_type = 'quantile'  #'MSE' #\n",
    "\n",
    "if args.loss_function_type == 'MSE':\n",
    "    args.out_dim = 1\n",
    "    args.alpha = None\n",
    "    args.type_calendar = 'tuple'\n",
    "    args.ray_track_pi = False\n",
    "\n",
    "else:\n",
    "    args.embedding_dim = 3\n",
    "    args.calendar_class = 3\n",
    "    args.position = 'input'\n",
    "    args.specific_lr = False\n",
    "    args.type_calendar = 'tuple'\n",
    "    args.out_dim = 2\n",
    "    args.alpha = 0.1\n",
    "    args.ray_track_pi = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"lr\": tune.qloguniform(1e-4, 1e-1, 5e-5),\n",
    "          \"weight_decay\" : tune.uniform(0.0005, 0.1),\n",
    "          \"momentum\" : tune.uniform(0.85, 0.99),\n",
    "          \"dropout\" : tune.uniform(0,0.9),\n",
    "        }\n",
    "\n",
    "config_embedding = {#'calendar_class' : tune.choice([1,2,3]),\n",
    "                    'embedding_dim' : tune.choice([2,3,4,5,6]),\n",
    "                    'multi_embedding' : tune.choice([True,False]),\n",
    "                    #'TE_transfer' : tune.choice([True,False]),\n",
    "                    }\n",
    "\n",
    "\n",
    "config_stgcn = {\"Kt\" : tune.choice([2,3,4]),\n",
    "                \"stblock_num\" : tune.choice([1,2,3,4]),\n",
    "                \"act_fun\" : tune.choice(['glu','gtu']),\n",
    "                \"Ks\" :  tune.choice([2,3]),\n",
    "                \"graph_conv_type\" : tune.choice(['cheb_graph_conv','graph_conv']),\n",
    "                \"gso_type\" : tune.choice(['sym_norm_lap', 'rw_norm_lap', 'sym_renorm_adj', 'rw_renorm_adj']),\n",
    "                \"adj_type\" : 'dist',\n",
    "                }\n",
    "\n",
    "if args.time_embedding:\n",
    "    config.update(config_embedding)\n",
    "\n",
    "if args.model_name == 'STGCN':\n",
    "     config.update(config_stgcn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper Parameter Tuning sur le Fold 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 17:09:52,287\tERROR services.py:1207 -- Failed to start the dashboard , return code 0\n",
      "2024-05-16 17:09:52,290\tERROR services.py:1232 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2024-05-16 17:09:52,308\tERROR services.py:1276 -- \n",
      "The last 20 lines of /tmp/ray/session_2024-05-16_17-09-50_068202_5397/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "  File \"/Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/ray/dashboard/head.py\", line 327, in run\n",
      "    self.http_server = await self._configure_http_server(modules)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/ray/dashboard/head.py\", line 158, in _configure_http_server\n",
      "    http_server = HttpServerDashboardHead(\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/ray/dashboard/http_server_head.py\", line 90, in __init__\n",
      "    raise ex\n",
      "  File \"/Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/ray/dashboard/http_server_head.py\", line 81, in __init__\n",
      "    build_dir = setup_static_dir()\n",
      "                ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/ray/dashboard/http_server_head.py\", line 39, in setup_static_dir\n",
      "    raise dashboard_utils.FrontendNotFoundError(\n",
      "ray.dashboard.utils.FrontendNotFoundError: [Errno 2] Dashboard build directory not found. If installing from source, please follow the additional steps required to build the dashboard(cd python/ray/dashboard/client && npm ci && npm run build): '/Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/ray/dashboard/client/build'\n",
      "\n",
      "2024-05-16 17:09:52,164\tERROR base_events.py:1785 -- Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10cd71a10>\n",
      "2024-05-16 17:09:52,164\tERROR base_events.py:1785 -- Unclosed client session\n",
      "client_session: <aiohttp.client.ClientSession object at 0x10cd71c50>\n",
      "2024-05-16 17:09:52,164\tERROR base_events.py:1785 -- Unclosed client session\n",
      "2024-05-16 17:09:52,481\tINFO worker.py:1621 -- Started a local Ray instance.\n",
      "2024-05-16 17:09:53,661\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-05-16 17:10:32</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:38.64        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.3/16.0 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=6<br>Bracket: Iter 2.000: -0.014845375149022965 | Iter 1.000: -0.030303765162234268<br>Logical resource usage: 1.0/6 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status    </th><th>loc           </th><th style=\"text-align: right;\">  Ks</th><th style=\"text-align: right;\">  Kt</th><th>act_fun  </th><th style=\"text-align: right;\">  dropout</th><th style=\"text-align: right;\">  embedding_dim</th><th>graph_conv_type  </th><th>gso_type      </th><th style=\"text-align: right;\">     lr</th><th style=\"text-align: right;\">  momentum</th><th>multi_embedding  </th><th style=\"text-align: right;\">  stblock_num</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Train_with_tune_5956c_00000</td><td>TERMINATED</td><td>127.0.0.1:5459</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   4</td><td>glu      </td><td style=\"text-align: right;\"> 0.168384</td><td style=\"text-align: right;\">              4</td><td>graph_conv       </td><td>sym_renorm_adj</td><td style=\"text-align: right;\">0.001  </td><td style=\"text-align: right;\">  0.985297</td><td>False            </td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">    0.0372033 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.5103</td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00001</td><td>TERMINATED</td><td>127.0.0.1:5460</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   4</td><td>glu      </td><td style=\"text-align: right;\"> 0.388887</td><td style=\"text-align: right;\">              5</td><td>cheb_graph_conv  </td><td>sym_renorm_adj</td><td style=\"text-align: right;\">0.0279 </td><td style=\"text-align: right;\">  0.956231</td><td>False            </td><td style=\"text-align: right;\">            3</td><td style=\"text-align: right;\">    0.00562806</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.2258</td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00002</td><td>TERMINATED</td><td>127.0.0.1:5461</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   3</td><td>glu      </td><td style=\"text-align: right;\"> 0.448697</td><td style=\"text-align: right;\">              3</td><td>graph_conv       </td><td>sym_norm_lap  </td><td style=\"text-align: right;\">0.0003 </td><td style=\"text-align: right;\">  0.890922</td><td>False            </td><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">    0.0401834 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         26.0946</td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00003</td><td>TERMINATED</td><td>127.0.0.1:5462</td><td style=\"text-align: right;\">   2</td><td style=\"text-align: right;\">   4</td><td>glu      </td><td style=\"text-align: right;\"> 0.419861</td><td style=\"text-align: right;\">              5</td><td>cheb_graph_conv  </td><td>sym_norm_lap  </td><td style=\"text-align: right;\">0.00055</td><td style=\"text-align: right;\">  0.917278</td><td>True             </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">    0.0327489 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         29.635 </td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00004</td><td>TERMINATED</td><td>127.0.0.1:5463</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   3</td><td>gtu      </td><td style=\"text-align: right;\"> 0.278855</td><td style=\"text-align: right;\">              2</td><td>graph_conv       </td><td>sym_norm_lap  </td><td style=\"text-align: right;\">0.0587 </td><td style=\"text-align: right;\">  0.954508</td><td>False            </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">    0.0400115 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         26.9145</td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00005</td><td>TERMINATED</td><td>127.0.0.1:5464</td><td style=\"text-align: right;\">   3</td><td style=\"text-align: right;\">   2</td><td>glu      </td><td style=\"text-align: right;\"> 0.663362</td><td style=\"text-align: right;\">              5</td><td>cheb_graph_conv  </td><td>sym_norm_lap  </td><td style=\"text-align: right;\">0.00015</td><td style=\"text-align: right;\">  0.986806</td><td>True             </td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">    0.00916009</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         28.2391</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m coverage period: 2019-01-01 00:00:00 - 2020-01-01 00:00:00\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Time-step per hour: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00171721]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Use iteration 21 instead with accuracy \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m 0.0017172072956624291.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00171721]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00321617]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Use iteration 20 instead with accuracy \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m 0.0026350128453127516.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00263501]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00979324]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Use iteration 20 instead with accuracy \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m 0.008073384419168161.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00807338]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.02058997]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Use iteration 15 instead with accuracy \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m 0.005230502248589796.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.0052305]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00117914]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Use iteration 21 instead with accuracy \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m 0.0011791406259986088.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00117914]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited at iteration 20 with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00147638]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Use iteration 21 instead with accuracy \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m 0.001476382935009334.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m /Users/romainrochas/opt/anaconda3/envs/tuning/lib/python3.11/site-packages/scipy/sparse/linalg/_eigen/_svds.py:487: UserWarning: Exited postprocessing with accuracies \n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m [0.00147638]\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m not reaching the requested tolerance 5.960464477539062e-07.\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m   _, eigvec = lobpcg(XH_X, X, tol=tol ** 2, maxiter=maxiter,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Train_with_tune pid=5459)\u001b[0m start training\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5464)\u001b[0m coverage period: 2019-01-01 00:00:00 - 2020-01-01 00:00:00\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5464)\u001b[0m Time-step per hour: 4.0\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5461)\u001b[0m Proportion of label with quantile order set to 1: 26.8%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>_metric                                                                                       </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>Train_with_tune_5956c_00000</td><td>{&#x27;Loss_model&#x27;: 0.03162562436172887, &#x27;MPIW&#x27;: -10.806896209716797, &#x27;PICP&#x27;: 0.4439484126984127}  </td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00001</td><td>{&#x27;Loss_model&#x27;: 0.03088225501160773, &#x27;MPIW&#x27;: -20.088762283325195, &#x27;PICP&#x27;: 0.14484126984126985} </td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00002</td><td>{&#x27;Loss_model&#x27;: 0.015297703563220917, &#x27;MPIW&#x27;: -26.507434844970703, &#x27;PICP&#x27;: 0.08928571428571429}</td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00003</td><td>{&#x27;Loss_model&#x27;: 0.014393046734825013, &#x27;MPIW&#x27;: -13.358352661132812, &#x27;PICP&#x27;: 0.2619047619047619} </td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00004</td><td>{&#x27;Loss_model&#x27;: 0.029725275312860806, &#x27;MPIW&#x27;: -6.498607635498047, &#x27;PICP&#x27;: 0.25}                </td></tr>\n",
       "<tr><td>Train_with_tune_5956c_00005</td><td>{&#x27;Loss_model&#x27;: 0.05281252756951347, &#x27;MPIW&#x27;: -161.0552520751953, &#x27;PICP&#x27;: 0.037698412698412696} </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(Train_with_tune pid=5464)\u001b[0m start training\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(Train_with_tune pid=5462)\u001b[0m Proportion of label with quantile order set to 1: 28.0%\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-16 17:10:32,322\tINFO tune.py:1148 -- Total run time: 38.66 seconds (38.64 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "def load_trainer(config,folder_path,file_name,args):\n",
    "\n",
    "    for key, value in config.items():\n",
    "        if hasattr(args, key):\n",
    "            setattr(args, key, value)\n",
    "\n",
    "    Datasets,DataLoader_list,dic_class2rpz,nb_words_embedding,time_slots_labels,dic_rpz2class = load_init_trainer(folder_path,file_name,args)\n",
    "    (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz,n_vertex = len(Datasets[0].columns))\n",
    "    dataset,dataloader,model,optimizer = Datasets[0],DataLoader_list[0],Model_list[0],Optimizer_list[0]\n",
    "\n",
    "\n",
    "    trainer = Trainer(dataset,model,dataloader,\n",
    "                    args,optimizer,loss_function,scheduler = None,\n",
    "                    args_embedding=args_embedding,\n",
    "                    save_dir = None,dic_class2rpz=dic_class2rpz)\n",
    "    return(trainer)\n",
    "\n",
    "def Train_with_tune(config):\n",
    "    trainer = load_trainer(config,folder_path,file_name,args)\n",
    "    result_df = trainer.train_and_valid()\n",
    "\n",
    "\n",
    "\n",
    "ray_scheduler,ray_search_alg,resources_per_trial,num_gpus,max_concurrent_trials = get_ray_config(args)\n",
    "\n",
    "\n",
    "if ray.is_initialized:\n",
    "    ray.shutdown()\n",
    "    ray.init(num_gpus=num_gpus)\n",
    "\n",
    "analysis = tune.run(\n",
    "        Train_with_tune,\n",
    "        config=config,\n",
    "        num_samples=6,  # Increase num_samples for more random combinations\n",
    "        resources_per_trial = resources_per_trial,\n",
    "        max_concurrent_trials = max_concurrent_trials,\n",
    "        scheduler = ray_scheduler,\n",
    "        search_alg = ray_search_alg,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_this_iter_s</th>\n",
       "      <th>done</th>\n",
       "      <th>training_iteration</th>\n",
       "      <th>trial_id</th>\n",
       "      <th>date</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>time_total_s</th>\n",
       "      <th>pid</th>\n",
       "      <th>hostname</th>\n",
       "      <th>node_ip</th>\n",
       "      <th>...</th>\n",
       "      <th>config/dropout</th>\n",
       "      <th>config/embedding_dim</th>\n",
       "      <th>config/graph_conv_type</th>\n",
       "      <th>config/gso_type</th>\n",
       "      <th>config/lr</th>\n",
       "      <th>config/momentum</th>\n",
       "      <th>config/multi_embedding</th>\n",
       "      <th>config/stblock_num</th>\n",
       "      <th>config/weight_decay</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.632186</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5956c_00003</td>\n",
       "      <td>2024-05-16_17-10-32</td>\n",
       "      <td>1715872232</td>\n",
       "      <td>29.635034</td>\n",
       "      <td>5462</td>\n",
       "      <td>mbro-21-005</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419861</td>\n",
       "      <td>5</td>\n",
       "      <td>cheb_graph_conv</td>\n",
       "      <td>sym_norm_lap</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.917278</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>/Users/romainrochas/ray_results/Train_with_tun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.410849</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5956c_00002</td>\n",
       "      <td>2024-05-16_17-10-28</td>\n",
       "      <td>1715872228</td>\n",
       "      <td>26.094634</td>\n",
       "      <td>5461</td>\n",
       "      <td>mbro-21-005</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448697</td>\n",
       "      <td>3</td>\n",
       "      <td>graph_conv</td>\n",
       "      <td>sym_norm_lap</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.890922</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0.040183</td>\n",
       "      <td>/Users/romainrochas/ray_results/Train_with_tun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.914531</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5956c_00004</td>\n",
       "      <td>2024-05-16_17-10-29</td>\n",
       "      <td>1715872229</td>\n",
       "      <td>26.914531</td>\n",
       "      <td>5463</td>\n",
       "      <td>mbro-21-005</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278855</td>\n",
       "      <td>2</td>\n",
       "      <td>graph_conv</td>\n",
       "      <td>sym_norm_lap</td>\n",
       "      <td>0.05870</td>\n",
       "      <td>0.954508</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0.040012</td>\n",
       "      <td>/Users/romainrochas/ray_results/Train_with_tun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28.225816</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5956c_00001</td>\n",
       "      <td>2024-05-16_17-10-30</td>\n",
       "      <td>1715872230</td>\n",
       "      <td>28.225816</td>\n",
       "      <td>5460</td>\n",
       "      <td>mbro-21-005</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388887</td>\n",
       "      <td>5</td>\n",
       "      <td>cheb_graph_conv</td>\n",
       "      <td>sym_renorm_adj</td>\n",
       "      <td>0.02790</td>\n",
       "      <td>0.956231</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>/Users/romainrochas/ray_results/Train_with_tun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.510311</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5956c_00000</td>\n",
       "      <td>2024-05-16_17-10-31</td>\n",
       "      <td>1715872231</td>\n",
       "      <td>28.510311</td>\n",
       "      <td>5459</td>\n",
       "      <td>mbro-21-005</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168384</td>\n",
       "      <td>4</td>\n",
       "      <td>graph_conv</td>\n",
       "      <td>sym_renorm_adj</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.985297</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>0.037203</td>\n",
       "      <td>/Users/romainrochas/ray_results/Train_with_tun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.239110</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>5956c_00005</td>\n",
       "      <td>2024-05-16_17-10-31</td>\n",
       "      <td>1715872231</td>\n",
       "      <td>28.239110</td>\n",
       "      <td>5464</td>\n",
       "      <td>mbro-21-005</td>\n",
       "      <td>127.0.0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.663362</td>\n",
       "      <td>5</td>\n",
       "      <td>cheb_graph_conv</td>\n",
       "      <td>sym_norm_lap</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.986806</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>/Users/romainrochas/ray_results/Train_with_tun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_this_iter_s  done  training_iteration     trial_id  \\\n",
       "3          3.632186  True                   2  5956c_00003   \n",
       "2          2.410849  True                   2  5956c_00002   \n",
       "4         26.914531  True                   1  5956c_00004   \n",
       "1         28.225816  True                   1  5956c_00001   \n",
       "0         28.510311  True                   1  5956c_00000   \n",
       "5         28.239110  True                   1  5956c_00005   \n",
       "\n",
       "                  date   timestamp  time_total_s   pid     hostname  \\\n",
       "3  2024-05-16_17-10-32  1715872232     29.635034  5462  mbro-21-005   \n",
       "2  2024-05-16_17-10-28  1715872228     26.094634  5461  mbro-21-005   \n",
       "4  2024-05-16_17-10-29  1715872229     26.914531  5463  mbro-21-005   \n",
       "1  2024-05-16_17-10-30  1715872230     28.225816  5460  mbro-21-005   \n",
       "0  2024-05-16_17-10-31  1715872231     28.510311  5459  mbro-21-005   \n",
       "5  2024-05-16_17-10-31  1715872231     28.239110  5464  mbro-21-005   \n",
       "\n",
       "     node_ip  ...  config/dropout  config/embedding_dim  \\\n",
       "3  127.0.0.1  ...        0.419861                     5   \n",
       "2  127.0.0.1  ...        0.448697                     3   \n",
       "4  127.0.0.1  ...        0.278855                     2   \n",
       "1  127.0.0.1  ...        0.388887                     5   \n",
       "0  127.0.0.1  ...        0.168384                     4   \n",
       "5  127.0.0.1  ...        0.663362                     5   \n",
       "\n",
       "   config/graph_conv_type  config/gso_type  config/lr  config/momentum  \\\n",
       "3         cheb_graph_conv     sym_norm_lap    0.00055         0.917278   \n",
       "2              graph_conv     sym_norm_lap    0.00030         0.890922   \n",
       "4              graph_conv     sym_norm_lap    0.05870         0.954508   \n",
       "1         cheb_graph_conv   sym_renorm_adj    0.02790         0.956231   \n",
       "0              graph_conv   sym_renorm_adj    0.00100         0.985297   \n",
       "5         cheb_graph_conv     sym_norm_lap    0.00015         0.986806   \n",
       "\n",
       "   config/multi_embedding config/stblock_num config/weight_decay  \\\n",
       "3                    True                  2            0.032749   \n",
       "2                   False                  1            0.040183   \n",
       "4                   False                  2            0.040012   \n",
       "1                   False                  3            0.005628   \n",
       "0                   False                  4            0.037203   \n",
       "5                    True                  4            0.009160   \n",
       "\n",
       "                                              logdir  \n",
       "3  /Users/romainrochas/ray_results/Train_with_tun...  \n",
       "2  /Users/romainrochas/ray_results/Train_with_tun...  \n",
       "4  /Users/romainrochas/ray_results/Train_with_tun...  \n",
       "1  /Users/romainrochas/ray_results/Train_with_tun...  \n",
       "0  /Users/romainrochas/ray_results/Train_with_tun...  \n",
       "5  /Users/romainrochas/ray_results/Train_with_tun...  \n",
       "\n",
       "[6 rows x 29 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis.dataframe().sort_values('_metric/Loss_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix des hyperparamer en fonction du Tuning. Puis Cross Validation sur les 5 Fold Restant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refaire l'initialisation avec les args adapté .... \n",
    "#\n",
    "#\n",
    "#\n",
    "args =  ... \n",
    "results_df = pd.DataFrame()\n",
    "save_dir = get_save_directory(args)\n",
    "\n",
    "multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "\n",
    "(results_by_fold,mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds) = multimodeltrainer.K_fold_validation(mod_plot = 10)\n",
    "results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "\n",
    "# Svae results \n",
    "results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds)\n",
    "results_df.to_csv(f\"{args.model_name}_{args.loss_function_type}_H{args.H}_D{args.D}_W{args.W}_E{args.epochs}_K_fold{args.K_fold}_Emb_dim{args.embedding_dim}FC1_17_8_FC2_8_4_save_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Parameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "model_name = 'STGCN' #'CNN' \n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification : \n",
    "args.epochs = 1\n",
    "args.K_fold = 1\n",
    "\n",
    "args.loss_function_type = 'MSE'\n",
    "args.out_dim = 1\n",
    "args.alpha = None\n",
    "# Save Directory:\n",
    "main_dir = get_save_directory(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fixed Dataset K_fold split for each trial: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and invalid_dates\n",
    "dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,args.W,args.D,args.H,args.step_ahead,single_station = False)\n",
    "\n",
    "# Train / Valid / Test split and Normalize for K-fold \n",
    "(Datasets,DataLoader_list,time_slots_labels_list,dic_class2rpz,dic_rpz2class,nb_words_embedding) =  dataset.split_K_fold(args,invalid_dates)\n",
    "\n",
    "# Plot information about split and folds:\n",
    "plot_k_fold_split(Datasets,invalid_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test complet sur les 3 Top STGCN, avec sauvegarde du model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame()\n",
    "\n",
    "#for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3,1,3],['input','input','input'],[True,True,False],['tuple','tuple','tuple'])):\n",
    "for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3],['input'],[True],['tuple'])):\n",
    "\n",
    "    args.calendar_class = calendar_class\n",
    "    args.position = position\n",
    "    args.specific_lr = specific_lr\n",
    "    args.type_calendar = type_calendar\n",
    "\n",
    "    save_dir = get_save_directory(args)\n",
    "\n",
    "    # Load dataset and invalid_dates \n",
    "    dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,args.W,args.D,args.H,args.step_ahead,single_station = False)\n",
    "    (Datasets,DataLoader_list,time_slots_labels,dic_class2rpz,dic_rpz2class,nb_words_embedding) =  dataset.split_K_fold(args,invalid_dates)\n",
    "    \n",
    "    # Load associated K_folds Models: \n",
    "    (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz)\n",
    "    multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "    (results_by_fold,mean_picp,mean_mpiw,dict_last,dict_scores) = multimodeltrainer.K_fold_validation(mod_plot = 1)\n",
    "    results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "    \n",
    "    # Svae results \n",
    "    results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last,dict_scores)\n",
    "                            \n",
    "results_df.to_csv('save_results.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== GET PARAMETERS ====\n",
    "# Load config\n",
    "model_name = 'STGCN' #'CNN' \n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification : \n",
    "args.epochs = 300\n",
    "\n",
    "# Save Directory:\n",
    "main_dir = get_save_directory(args)\n",
    "args.H = 0\n",
    "args.W = 0\n",
    "args.D = 0\n",
    "args.L =args.H+args.W+args.D\n",
    "args.single_station = True\n",
    "# ==== TEST  ====\n",
    "for K_fold in [5]:\n",
    "    args.K_fold = K_fold\n",
    "    results_df = pd.DataFrame()\n",
    "\n",
    "    #for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3,1,3],['input','input','input'],[True,True,False],['tuple','tuple','tuple'])):\n",
    "    #for i,(calendar_class,position,specific_lr, type_calendar) in enumerate(zip([3],['input'],[True],['tuple'])):\n",
    "    for i,(embedding_dim,calendar_class,position,specific_lr, type_calendar,time_embedding) in enumerate(zip([3], # None\n",
    "                                                                                                             [3], # 3\n",
    "                                                                                               ['input'], # None\n",
    "                                                                                               [False], # None \n",
    "                                                                                               ['tuple'], # None\n",
    "                                                                                               [True] # False\n",
    "                                                                                              )\n",
    "                                                                                            ):\n",
    "        args.embedding_dim = embedding_dim\n",
    "        args.calendar_class = calendar_class\n",
    "        args.position = position\n",
    "        args.specific_lr = specific_lr\n",
    "        args.type_calendar = type_calendar\n",
    "        args.time_embedding = time_embedding\n",
    "\n",
    "        save_dir = get_save_directory(args)\n",
    "\n",
    "        # Load dataset and invalid_dates \n",
    "        dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,args.W,args.D,args.H,args.step_ahead,single_station = args.single_station)\n",
    "        (Datasets,DataLoader_list,time_slots_labels,dic_class2rpz,dic_rpz2class,nb_words_embedding) =  dataset.split_K_fold(args,invalid_dates)\n",
    "\n",
    "        # Load associated K_folds Models: \n",
    "        (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz)\n",
    "        multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "        \n",
    "        (results_by_fold,mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds) = multimodeltrainer.K_fold_validation(mod_plot = 10)\n",
    "        results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "\n",
    "        # Svae results \n",
    "        results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds)\n",
    "        results_df.to_csv(f\"{args.model_name}_H{args.H}_D{args.D}_W{args.W}_E{args.epochs}_K_fold{args.K_fold}_Emb_dim{args.embedding_dim}FC1_17_8_FC2_8_4_save_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
