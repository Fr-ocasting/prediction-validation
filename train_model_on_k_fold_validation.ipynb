{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "# Personnal Import \n",
    "from utilities_DL import get_DataSet_and_invalid_dates,get_MultiModel_loss_args_emb_opts\n",
    "from DL_class import MultiModelTrainer\n",
    "from config import get_config,get_parameters\n",
    "from plotting import plot_k_fold_split\n",
    "from save_results import update_results_df\n",
    "# ...\n",
    "\n",
    "# Paths\n",
    "folder_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Init and load data: \n",
    "H,W,D = 6,1,1\n",
    "L = H+W+D \n",
    "step_ahead = 1\n",
    "\n",
    "window_pred = np.arange(2*96)\n",
    "\n",
    "# Load subway in data:\n",
    "#file_name = 'preprocessed_subway_15_min.csv'\n",
    "#file_name = 'subway_IN_interpol_neg_15_min_16Mar2019_1Jun2020.csv'\n",
    "file_name = 'subway_IN_interpol_neg_15_min_2019_2020.csv'\n",
    "\n",
    "# Load CRITER data : \n",
    "#file_name = 'preprocessed_CRITER_6min.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Parameters : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Model :\n",
    "model_name =  'CNN' #'STGCN'\n",
    "\n",
    "# Choose config \n",
    "config = get_config(model_name = model_name,other_params= {'seq_length':L})\n",
    "#config = get_config(model_name = model_name,learn_graph_structure = True,other_params= {'seq_length':L})  # MTGNN\n",
    "args = get_parameters(config)\n",
    "\n",
    "# Modification : \n",
    "args.epochs = 100\n",
    "args.optimizer = 'adamw'\n",
    "args.train_prop= 0.6\n",
    "args.calib_prop=None\n",
    "args.valid_prop= 0.2  \n",
    "\n",
    "# Time Embedding: \n",
    "args.type_calendar = 'tuple'\n",
    "args.embedding_dim = 2\n",
    "\n",
    "# Validation : \n",
    "args.validation = 'sliding_window'\n",
    "args.K_fold = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define fixed Dataset K_fold split for each trial: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage period: 2019-01-01 00:00:00 - 2020-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and invalid_dates\n",
    "dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,W,D,H,step_ahead,single_station = False)\n",
    "\n",
    "# Train / Valid / Test split and Normalize for K-fold \n",
    "(Datasets,DataLoader_list,time_slots_labels_list,dic_clasxs2rpz_list,dic_rpz2class_list,nb_words_embedding_list) =  dataset.split_K_fold(args.K_fold,invalid_dates,args.train_prop, args.valid_prop,args.test_prop,args.calib_prop,args.validation,args.batch_size,calendar_class= args.calendar_class,no_common_dates_between_set = args.no_common_dates_between_set)\n",
    "\n",
    "# Plot information about split and folds:\n",
    "plot_k_fold_split(Datasets,invalid_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop on different config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([50, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([672, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-06-01 00:00:00\n",
      "\n",
      "\n",
      "K_fold 0\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 1\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 2\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 3\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 4\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 5\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "K_fold 6\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.00\n",
      "torch.Size([168, 3])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CalendarClass</th>\n",
       "      <th>Position</th>\n",
       "      <th>Specific_lr</th>\n",
       "      <th>Type_calendar</th>\n",
       "      <th>PICP_mean</th>\n",
       "      <th>MPIW_mean</th>\n",
       "      <th>mean_last_train_loss</th>\n",
       "      <th>std_of_lasts_train_loss</th>\n",
       "      <th>mean_last_valid_loss</th>\n",
       "      <th>std_of_lasts_valid_loss</th>\n",
       "      <th>best_mean_train_loss</th>\n",
       "      <th>std_of_best_mean_train_loss</th>\n",
       "      <th>best_mean_valid_loss</th>\n",
       "      <th>std_of_best_mean_valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>input</td>\n",
       "      <td>True</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.136815</td>\n",
       "      <td>-0.034300</td>\n",
       "      <td>0.236532</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>0.215081</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>0.236532</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>0.215081</td>\n",
       "      <td>0.099011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>input</td>\n",
       "      <td>True</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.151789</td>\n",
       "      <td>-0.043997</td>\n",
       "      <td>0.260791</td>\n",
       "      <td>0.103233</td>\n",
       "      <td>0.239759</td>\n",
       "      <td>0.103233</td>\n",
       "      <td>0.260791</td>\n",
       "      <td>0.103233</td>\n",
       "      <td>0.239759</td>\n",
       "      <td>0.097305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>input</td>\n",
       "      <td>False</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.100481</td>\n",
       "      <td>-0.062387</td>\n",
       "      <td>0.226823</td>\n",
       "      <td>0.094724</td>\n",
       "      <td>0.216355</td>\n",
       "      <td>0.094724</td>\n",
       "      <td>0.226823</td>\n",
       "      <td>0.094724</td>\n",
       "      <td>0.216355</td>\n",
       "      <td>0.115369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>input</td>\n",
       "      <td>False</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.293750</td>\n",
       "      <td>0.141665</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.176537</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.187142</td>\n",
       "      <td>0.084360</td>\n",
       "      <td>0.176537</td>\n",
       "      <td>0.116669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>output</td>\n",
       "      <td>True</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.349490</td>\n",
       "      <td>0.161578</td>\n",
       "      <td>0.189271</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.140770</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.189271</td>\n",
       "      <td>0.103875</td>\n",
       "      <td>0.140770</td>\n",
       "      <td>0.119882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>output</td>\n",
       "      <td>True</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.083630</td>\n",
       "      <td>-0.027184</td>\n",
       "      <td>0.238417</td>\n",
       "      <td>0.110851</td>\n",
       "      <td>0.207789</td>\n",
       "      <td>0.110851</td>\n",
       "      <td>0.238417</td>\n",
       "      <td>0.110851</td>\n",
       "      <td>0.207789</td>\n",
       "      <td>0.091693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.176593</td>\n",
       "      <td>-0.028057</td>\n",
       "      <td>0.282099</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>0.264267</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>0.282099</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>0.264267</td>\n",
       "      <td>0.129158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.110375</td>\n",
       "      <td>0.054805</td>\n",
       "      <td>0.261430</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>0.245074</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>0.261430</td>\n",
       "      <td>0.101570</td>\n",
       "      <td>0.245074</td>\n",
       "      <td>0.095320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>input</td>\n",
       "      <td>True</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.207784</td>\n",
       "      <td>0.085829</td>\n",
       "      <td>0.237601</td>\n",
       "      <td>0.111259</td>\n",
       "      <td>0.216035</td>\n",
       "      <td>0.111259</td>\n",
       "      <td>0.237601</td>\n",
       "      <td>0.111259</td>\n",
       "      <td>0.216035</td>\n",
       "      <td>0.113280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>input</td>\n",
       "      <td>True</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.220663</td>\n",
       "      <td>0.106222</td>\n",
       "      <td>0.189820</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.171047</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.189820</td>\n",
       "      <td>0.088428</td>\n",
       "      <td>0.171047</td>\n",
       "      <td>0.080525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>input</td>\n",
       "      <td>False</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.094552</td>\n",
       "      <td>-0.026389</td>\n",
       "      <td>0.231969</td>\n",
       "      <td>0.076636</td>\n",
       "      <td>0.216006</td>\n",
       "      <td>0.076636</td>\n",
       "      <td>0.231969</td>\n",
       "      <td>0.076636</td>\n",
       "      <td>0.216006</td>\n",
       "      <td>0.068066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>input</td>\n",
       "      <td>False</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.067249</td>\n",
       "      <td>-0.147784</td>\n",
       "      <td>0.313078</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.296341</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.313078</td>\n",
       "      <td>0.117338</td>\n",
       "      <td>0.296341</td>\n",
       "      <td>0.098220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>output</td>\n",
       "      <td>True</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>0.155841</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>0.133430</td>\n",
       "      <td>0.216833</td>\n",
       "      <td>0.133430</td>\n",
       "      <td>0.285628</td>\n",
       "      <td>0.133430</td>\n",
       "      <td>0.216833</td>\n",
       "      <td>0.189277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>output</td>\n",
       "      <td>True</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.316042</td>\n",
       "      <td>0.151807</td>\n",
       "      <td>0.210021</td>\n",
       "      <td>0.109268</td>\n",
       "      <td>0.191126</td>\n",
       "      <td>0.109268</td>\n",
       "      <td>0.210021</td>\n",
       "      <td>0.109268</td>\n",
       "      <td>0.191126</td>\n",
       "      <td>0.118601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.148313</td>\n",
       "      <td>-0.042166</td>\n",
       "      <td>0.291184</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.269730</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.291184</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.269730</td>\n",
       "      <td>0.136980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.188593</td>\n",
       "      <td>0.055572</td>\n",
       "      <td>0.178018</td>\n",
       "      <td>0.096115</td>\n",
       "      <td>0.172355</td>\n",
       "      <td>0.096115</td>\n",
       "      <td>0.178018</td>\n",
       "      <td>0.096115</td>\n",
       "      <td>0.172355</td>\n",
       "      <td>0.140543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3</td>\n",
       "      <td>input</td>\n",
       "      <td>True</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.166173</td>\n",
       "      <td>0.021784</td>\n",
       "      <td>0.254992</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>0.254992</td>\n",
       "      <td>0.097812</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.085602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>input</td>\n",
       "      <td>True</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.175328</td>\n",
       "      <td>-0.080600</td>\n",
       "      <td>0.262075</td>\n",
       "      <td>0.164342</td>\n",
       "      <td>0.246052</td>\n",
       "      <td>0.164342</td>\n",
       "      <td>0.262075</td>\n",
       "      <td>0.164342</td>\n",
       "      <td>0.246052</td>\n",
       "      <td>0.209161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>input</td>\n",
       "      <td>False</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.314628</td>\n",
       "      <td>0.152859</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>0.120143</td>\n",
       "      <td>0.171545</td>\n",
       "      <td>0.120143</td>\n",
       "      <td>0.185172</td>\n",
       "      <td>0.120143</td>\n",
       "      <td>0.171545</td>\n",
       "      <td>0.139992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>input</td>\n",
       "      <td>False</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.021560</td>\n",
       "      <td>-0.135252</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.119304</td>\n",
       "      <td>0.278393</td>\n",
       "      <td>0.119304</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.119304</td>\n",
       "      <td>0.278393</td>\n",
       "      <td>0.135567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3</td>\n",
       "      <td>output</td>\n",
       "      <td>True</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.314457</td>\n",
       "      <td>0.207467</td>\n",
       "      <td>0.218081</td>\n",
       "      <td>0.142256</td>\n",
       "      <td>0.169027</td>\n",
       "      <td>0.142256</td>\n",
       "      <td>0.218081</td>\n",
       "      <td>0.142256</td>\n",
       "      <td>0.169027</td>\n",
       "      <td>0.129683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3</td>\n",
       "      <td>output</td>\n",
       "      <td>True</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.156112</td>\n",
       "      <td>-0.006256</td>\n",
       "      <td>0.229847</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.208784</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.229847</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.208784</td>\n",
       "      <td>0.163640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "      <td>tuple</td>\n",
       "      <td>0.093021</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.253040</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>0.233895</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>0.253040</td>\n",
       "      <td>0.100193</td>\n",
       "      <td>0.233895</td>\n",
       "      <td>0.097314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3</td>\n",
       "      <td>output</td>\n",
       "      <td>False</td>\n",
       "      <td>unique_long_embedding</td>\n",
       "      <td>0.355722</td>\n",
       "      <td>0.127718</td>\n",
       "      <td>0.196617</td>\n",
       "      <td>0.121694</td>\n",
       "      <td>0.185863</td>\n",
       "      <td>0.121694</td>\n",
       "      <td>0.196617</td>\n",
       "      <td>0.121694</td>\n",
       "      <td>0.185863</td>\n",
       "      <td>0.158244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CalendarClass Position  Specific_lr          Type_calendar  PICP_mean  \\\n",
       "0               1    input         True                  tuple   0.136815   \n",
       "1               1    input         True  unique_long_embedding   0.151789   \n",
       "2               1    input        False                  tuple   0.100481   \n",
       "3               1    input        False  unique_long_embedding   0.293750   \n",
       "4               1   output         True                  tuple   0.349490   \n",
       "5               1   output         True  unique_long_embedding   0.083630   \n",
       "6               1   output        False                  tuple   0.176593   \n",
       "7               1   output        False  unique_long_embedding   0.110375   \n",
       "8               2    input         True                  tuple   0.207784   \n",
       "9               2    input         True  unique_long_embedding   0.220663   \n",
       "10              2    input        False                  tuple   0.094552   \n",
       "11              2    input        False  unique_long_embedding   0.067249   \n",
       "12              2   output         True                  tuple   0.311173   \n",
       "13              2   output         True  unique_long_embedding   0.316042   \n",
       "14              2   output        False                  tuple   0.148313   \n",
       "15              2   output        False  unique_long_embedding   0.188593   \n",
       "16              3    input         True                  tuple   0.166173   \n",
       "17              3    input         True  unique_long_embedding   0.175328   \n",
       "18              3    input        False                  tuple   0.314628   \n",
       "19              3    input        False  unique_long_embedding   0.021560   \n",
       "20              3   output         True                  tuple   0.314457   \n",
       "21              3   output         True  unique_long_embedding   0.156112   \n",
       "22              3   output        False                  tuple   0.093021   \n",
       "23              3   output        False  unique_long_embedding   0.355722   \n",
       "\n",
       "    MPIW_mean  mean_last_train_loss  std_of_lasts_train_loss  \\\n",
       "0   -0.034300              0.236532                 0.121876   \n",
       "1   -0.043997              0.260791                 0.103233   \n",
       "2   -0.062387              0.226823                 0.094724   \n",
       "3    0.141665              0.187142                 0.084360   \n",
       "4    0.161578              0.189271                 0.103875   \n",
       "5   -0.027184              0.238417                 0.110851   \n",
       "6   -0.028057              0.282099                 0.149054   \n",
       "7    0.054805              0.261430                 0.101570   \n",
       "8    0.085829              0.237601                 0.111259   \n",
       "9    0.106222              0.189820                 0.088428   \n",
       "10  -0.026389              0.231969                 0.076636   \n",
       "11  -0.147784              0.313078                 0.117338   \n",
       "12   0.155841              0.285628                 0.133430   \n",
       "13   0.151807              0.210021                 0.109268   \n",
       "14  -0.042166              0.291184                 0.142984   \n",
       "15   0.055572              0.178018                 0.096115   \n",
       "16   0.021784              0.254992                 0.097812   \n",
       "17  -0.080600              0.262075                 0.164342   \n",
       "18   0.152859              0.185172                 0.120143   \n",
       "19  -0.135252              0.294118                 0.119304   \n",
       "20   0.207467              0.218081                 0.142256   \n",
       "21  -0.006256              0.229847                 0.133500   \n",
       "22   0.000061              0.253040                 0.100193   \n",
       "23   0.127718              0.196617                 0.121694   \n",
       "\n",
       "    mean_last_valid_loss  std_of_lasts_valid_loss  best_mean_train_loss  \\\n",
       "0               0.215081                 0.121876              0.236532   \n",
       "1               0.239759                 0.103233              0.260791   \n",
       "2               0.216355                 0.094724              0.226823   \n",
       "3               0.176537                 0.084360              0.187142   \n",
       "4               0.140770                 0.103875              0.189271   \n",
       "5               0.207789                 0.110851              0.238417   \n",
       "6               0.264267                 0.149054              0.282099   \n",
       "7               0.245074                 0.101570              0.261430   \n",
       "8               0.216035                 0.111259              0.237601   \n",
       "9               0.171047                 0.088428              0.189820   \n",
       "10              0.216006                 0.076636              0.231969   \n",
       "11              0.296341                 0.117338              0.313078   \n",
       "12              0.216833                 0.133430              0.285628   \n",
       "13              0.191126                 0.109268              0.210021   \n",
       "14              0.269730                 0.142984              0.291184   \n",
       "15              0.172355                 0.096115              0.178018   \n",
       "16              0.231134                 0.097812              0.254992   \n",
       "17              0.246052                 0.164342              0.262075   \n",
       "18              0.171545                 0.120143              0.185172   \n",
       "19              0.278393                 0.119304              0.294118   \n",
       "20              0.169027                 0.142256              0.218081   \n",
       "21              0.208784                 0.133500              0.229847   \n",
       "22              0.233895                 0.100193              0.253040   \n",
       "23              0.185863                 0.121694              0.196617   \n",
       "\n",
       "    std_of_best_mean_train_loss  best_mean_valid_loss  \\\n",
       "0                      0.121876              0.215081   \n",
       "1                      0.103233              0.239759   \n",
       "2                      0.094724              0.216355   \n",
       "3                      0.084360              0.176537   \n",
       "4                      0.103875              0.140770   \n",
       "5                      0.110851              0.207789   \n",
       "6                      0.149054              0.264267   \n",
       "7                      0.101570              0.245074   \n",
       "8                      0.111259              0.216035   \n",
       "9                      0.088428              0.171047   \n",
       "10                     0.076636              0.216006   \n",
       "11                     0.117338              0.296341   \n",
       "12                     0.133430              0.216833   \n",
       "13                     0.109268              0.191126   \n",
       "14                     0.142984              0.269730   \n",
       "15                     0.096115              0.172355   \n",
       "16                     0.097812              0.231134   \n",
       "17                     0.164342              0.246052   \n",
       "18                     0.120143              0.171545   \n",
       "19                     0.119304              0.278393   \n",
       "20                     0.142256              0.169027   \n",
       "21                     0.133500              0.208784   \n",
       "22                     0.100193              0.233895   \n",
       "23                     0.121694              0.185863   \n",
       "\n",
       "    std_of_best_mean_valid_loss  \n",
       "0                      0.099011  \n",
       "1                      0.097305  \n",
       "2                      0.115369  \n",
       "3                      0.116669  \n",
       "4                      0.119882  \n",
       "5                      0.091693  \n",
       "6                      0.129158  \n",
       "7                      0.095320  \n",
       "8                      0.113280  \n",
       "9                      0.080525  \n",
       "10                     0.068066  \n",
       "11                     0.098220  \n",
       "12                     0.189277  \n",
       "13                     0.118601  \n",
       "14                     0.136980  \n",
       "15                     0.140543  \n",
       "16                     0.085602  \n",
       "17                     0.209161  \n",
       "18                     0.139992  \n",
       "19                     0.135567  \n",
       "20                     0.129683  \n",
       "21                     0.163640  \n",
       "22                     0.097314  \n",
       "23                     0.158244  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Init results dataframe:\n",
    "results_df = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "file_name = 'preprocessed_subway_15_min.csv'\n",
    "#file_name = 'subway_IN_interpol_neg_15_min_2019_2020.csv'\n",
    "\n",
    "args.epochs = 1\n",
    "bool_plot_split = False  # Ne plot pas les Train/Valid/Test split sur les K_folds\n",
    "\n",
    "\n",
    "# Set Variable Config : \n",
    "Calendar_class = [1,2,3]\n",
    "Position = ['input','output']\n",
    "Specific_lr = [True,False]\n",
    "Type_calendar = ['tuple','unique_long_embedding']  # Lors qu'il y a 'tuple', le matching tensor renvoit le tuple associ√© au calendar class.\n",
    "args.time_embedding = True   # Be sure the time embedding is activated\n",
    "\n",
    "\n",
    "# Loop on all possible config:\n",
    "for calendar_class in Calendar_class:\n",
    "    for position in Position:\n",
    "        for specific_lr in Specific_lr:\n",
    "            for type_calendar in Type_calendar:\n",
    "\n",
    "                # Modify 'args':\n",
    "                args.calendar_class = calendar_class\n",
    "                args.position = position\n",
    "                args.specific_lr = specific_lr\n",
    "                args.type_calendar = type_calendar\n",
    "                # ...\n",
    "\n",
    "                # Load dataset and invalid_dates \n",
    "                dataset,invalid_dates = get_DataSet_and_invalid_dates(folder_path,file_name,W,D,H,step_ahead,single_station = False)\n",
    "\n",
    "                # Train / Valid / Test split and Normalize for K-fold \n",
    "                assert(args.calib_prop is None),('args.calib_prop is not None, which mean there is different train_set for each trial')\n",
    "                (Datasets,DataLoader_list,time_slots_labels_list,dic_class2rpz_list,dic_rpz2class_list,nb_words_embedding_list) =  dataset.split_K_fold(args.K_fold,invalid_dates,args.train_prop, args.valid_prop,args.test_prop,args.calib_prop,args.validation,args.batch_size,calendar_class= args.calendar_class,no_common_dates_between_set = args.no_common_dates_between_set)\n",
    "\n",
    "                # Plot information about split and folds:\n",
    "                if bool_plot_split:\n",
    "                    plot_k_fold_split(Datasets,invalid_dates)\n",
    "\n",
    "\n",
    "                # Load associated K_folds Models: \n",
    "                (loss_function,Model_list,Optimizer_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding_list,dic_class2rpz_list)\n",
    "                multimodeltrainer = MultiModelTrainer(Model_list,DataLoader_list,args,Optimizer_list,loss_function,scheduler = None,args_embedding=args_embedding,ray= False)\n",
    "                (mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds) = multimodeltrainer.K_fold_validation()\n",
    "\n",
    "                # Svae results \n",
    "                results_df = update_results_df(results_df,args, mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds,i)\n",
    "                i += 1\n",
    "                            \n",
    "results_df.to_csv('save_results.csv')\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.2086971551179886,\n",
       " 0.1885807067155838,\n",
       " -0.21632690727710724,\n",
       " -0.19072620570659637,\n",
       " 0.182303324341774,\n",
       " -0.07127311825752258,\n",
       " -0.17025382816791534]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodeltrainer.mpiw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
