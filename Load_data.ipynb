{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "\n",
    "# Personnal Import \n",
    "from utilities import DataSet, get_batch,get_mode_date2path\n",
    "from load_data import load_subway_15_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Individuelles :                         [J,F,M,A,M,J,J,A,S,O,N,D],[J,F,M, , , , , , , , , ],[J,F,M, , , , , , , , , ]\n",
    "# Subway 15 Min :   Novembre 2019 - Mai 2021         [ , , , , , , , , , ,N,D],[J,F,M,A,M,J,J,A,S,O,N,D],[J,F,M,A,M, , , , , , , ]\n",
    "# NetMob 15 Min :                                   [ , ,M,A,M, , , , , , , ],[ , , , , , , , , , , , ],[ , , , , , , , , , , , ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "- Validation individuelles, aggrégée 3min.\n",
    "- Metro 15 min (entrée/sortie)\n",
    "\n",
    "Idée : Identifier des coupure de métro longue :\n",
    "    - entrée et sortie inhabituelles, montre que le métro est suspendu et laisse les portes ouvertes\n",
    "    - Sortie plus faible (coupure > 15min)\n",
    "Evaluer les qualités de prédiction sur ces moments là.\n",
    "\n",
    "## Data Description\n",
    "- Un 'VAL_ARRET_CODE' peut être l'arrêt de plusieurs mêmes bus, voir d'un même bus et d'un même arrêt de métro. Où d'un même bus et d'un même arrêt de tram. \n",
    "    - Je dois donc nommer différement les VAL_ARRET_CODE de chacun des modes. Une proposition est de mettre le mode (B,S,T) devant les id. Comme ça on pourra regrouper sans soucis.\n",
    "- La moyenne des déplacement de la df_subway est de 5 trajet toute les 3 minutes, quelque soit la station et l'heure (d'ouverture) considéré. Max 88.\n",
    "\n",
    "#### Questionnement \n",
    "- Ok on a aggrégé 3 min, mais est-ce qu'on peut recouper les sorties 3min avec les validation + Sortie de métro 15 min? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Individuelles\n",
    "Load 3 df : df_sub, df_tram, df_bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_1708\\2127861133.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_1708\\2127861133.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_1708\\2127861133.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_1708\\2127861133.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "C:\\Users\\romai\\AppData\\Local\\Temp\\ipykernel_1708\\2127861133.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'data/'\n",
    "valid_ind_path = folder_path + 'Sub_Tram_11_2019_03_2020'\n",
    "dates = ['11-2019','12-2019','1-2020','2-2020','3-2020']\n",
    "\n",
    "subway_paths, tramway_paths, bus_paths = sorted(glob.glob(os.path.join(valid_ind_path, \"*df_subway*.csv\"))),sorted(glob.glob(os.path.join(valid_ind_path, \"*df_tramway*.csv\"))),sorted(glob.glob(os.path.join(valid_ind_path, \"*df_bus*.csv\")))\n",
    "mode_month2path = get_mode_date2path([subway_paths,tramway_paths,bus_paths],['sub','tram','bus'])\n",
    "\n",
    "for name in ['sub','tram','bus']:\n",
    "    globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Subway 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Station</th>\n",
       "      <th>Code ligne</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime             Station Code ligne  in  out\n",
       "0 2019-01-01 00:00:00  Ampère Victor Hugo          A   2  4.0\n",
       "1 2019-01-01 00:15:00  Ampère Victor Hugo          A   3  2.0\n",
       "2 2019-01-01 00:30:00  Ampère Victor Hugo          A   3  7.0\n",
       "3 2019-01-01 00:45:00  Ampère Victor Hugo          A   1  9.0\n",
       "4 2019-01-01 01:00:00  Ampère Victor Hugo          A   0  0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_path = \"Métro 15 minutes 2019 2020.txt\"\n",
    "\n",
    "df_metro_funi_2019_2020 = load_subway_15_min(folder_path+txt_path)\n",
    "df_metro_funi_2019_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1er Etape : Prédiction Métro\n",
    "- On va d'abord prédire la demande sur une ligne (disons A).  \n",
    "- On va comparer des modèle : LSTM, CNN, CNN-LSTM, GNN.\n",
    "    - A priori pas de \"raison\" que le GNN marche mieux. Si c'est le cas, c'est peut être simplement que le modèle est plus complexe, mais j'ai du mal à croire que si on donne les bonnes informations (historique -7d, -1d, -4,3,2,1t), on a des meilleurs résultats avec GNN. Sauf si il y a des relation asynchrone \"récurrentes\", mais sans causalité. De la même manière que l'historique -7d sert de référence, mais ne témoigne pas d'un lien causal.\n",
    "- Identifier des moments interessants : anomalies sur entrée/sortie métro. Voir les prédictions sur ces moments là particulier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Coverage for each station, IN, OUT, and IN+OUT\n",
    "\n",
    "#### Visualisation des flux IN et OUT entre 6h et 24H. En virant les outliers (0.95) type fête des lumières:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from plotting import coverage_day_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init \n",
    "freq  = '15min'\n",
    "columns = 'hour'\n",
    "index = 'date'\n",
    "quantile = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting for each station \n",
    "for station in df_metro_funi_2019_2020.Station.unique():\n",
    "    df_tmps = df_metro_funi_2019_2020[df_metro_funi_2019_2020.Station == station]\n",
    "    df_tmps = df_tmps[df_tmps.datetime.dt.hour > 5]\n",
    "    in99,out99 = df_tmps['in'].quantile(quantile),df_tmps['out'].quantile(quantile)\n",
    "    df_tmps.loc[df_tmps['in']>in99,'in'] = in99\n",
    "    df_tmps.loc[df_tmps['out']>out99,'out'] = out99\n",
    "    coverage_day_month(df_tmps, freq = freq,index = index,columns = columns,save = station,folder_save = 'save/profile flux 15min filtred outliers 95/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation des flux IN et OUT pour chacunes des stations, without filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in df_metro_funi_2019_2020.Station.unique():\n",
    "    df_tmps = df_metro_funi_2019_2020[df_metro_funi_2019_2020.Station == station]\n",
    "    coverage_day_month(df_tmps, freq = '60min',index = 'date',columns = 'hour',save = station,folder_save = 'save/profile flux')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1er Etape : Prédiction Métro\n",
    "- On va d'abord prédire la demande sur une ligne (disons A).  \n",
    "- On va comparer des modèle : LSTM, CNN, CNN-LSTM, GNN.\n",
    "    - A priori pas de \"raison\" que le GNN marche mieux. Si c'est le cas, c'est peut être simplement que le modèle est plus complexe, mais j'ai du mal à croire que si on donne les bonnes informations (historique -7d, -1d, -4,3,2,1t), on a des meilleurs résultats avec GNN. Sauf si il y a des relation asynchrone \"récurrentes\", mais sans causalité.\n",
    "- Identifier des moment interessant : anomalie sur entrée/sortie métro. Voir les prédictions sur ces moments là particulier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vector\n",
    "A définir pour chacune des stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bla Bla : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bijecction entre un entier, et son label\n",
    "def int2lab(int,n_adj=2,B=3):\n",
    "    n = 1+(int-1)//B \n",
    "    b = int-(n-1)*B\n",
    "    return(f'n{n}_b{b}')\n",
    "\n",
    "def lab2int(lab,n_adj=2,B=3):\n",
    "    nb = lab.split('_')\n",
    "    n,b = int(nb[0][1:]),int(nb[1][1:])\n",
    "    return((n-1)*B+b)\n",
    "\n",
    "for k in range(1,15):\n",
    "    print(int2lab(k),lab2int(int2lab(k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des numéro des cellules du Tensor\n",
    "Permet de faire des affichages graphique, et de s'assurer que les \".reshape\" font ce que l'on souhaite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int2lab(integer, n_adj=2, B=3, C=4, N=5, L=6):\n",
    "    N_adj_L = N * L\n",
    "    N_adj_C_L = C * N_adj_L\n",
    "    N_adj_B_C_L = B * N_adj_C_L\n",
    "\n",
    "    l = 1 + ((integer - 1) % L)\n",
    "    remaining = (integer - 1) // L\n",
    "    n = 1 + (remaining % N)\n",
    "    remaining //= N\n",
    "    c = 1 + (remaining % C)\n",
    "    remaining //= C\n",
    "    b = 1 + (remaining % B)\n",
    "    remaining //= B\n",
    "    n_adj = 1 + remaining % n_adj\n",
    "\n",
    "    return f'adj{n_adj}_b{b}_c{c}_n{n}_l{l}'\n",
    "\n",
    "def lab2int(label, n_adj=2, B=3, C=4, N=5, L=6):\n",
    "    split_label = label.split('_')\n",
    "    n_adj = int(split_label[0][3:])\n",
    "    b = int(split_label[1][1:])\n",
    "    c = int(split_label[2][1:])\n",
    "    n = int(split_label[3][1:])\n",
    "    l = int(split_label[4][1:])\n",
    "\n",
    "    N_adj_L = N * L\n",
    "    N_adj_C_L = C * N_adj_L\n",
    "    N_adj_B_C_L = B * N_adj_C_L\n",
    "\n",
    "    integer = ((l - 1) + (n - 1) * L + (c - 1) * N * L + (b - 1) * C * N * L + (n_adj - 1) * B * C * N * L) + 1\n",
    "    return integer\n",
    "\n",
    "\n",
    "for k in range(1,400):\n",
    "    print(int2lab(k),lab2int(int2lab(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = int2lab(k)\n",
    "label.split('_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permuted_H = output_H.permute(0, 1, 3, 4, 2)\n",
    "print(permuted_H.shape)\n",
    "\n",
    "new_c_in = permuted_H.shape[-1]\n",
    "first_attn = permuted_H.reshape(K,-1,new_c_in)\n",
    "print(first_attn.shape)  # [K, B*L*N, C_in']\n",
    "\n",
    "attn_weight = nn.Linear(new_c_in,1)\n",
    "softmax = nn.Softmax(-1)  #SoftMax on the last dimension \n",
    "\n",
    "#Coefficient d'attention \n",
    "attn = attn_weight(first_attn)    # \"Embedding\" du spatial channel \n",
    "attn = attn.permute(1,2,0)  # Permute pour avoir la nombre d'adjacency matrix en dernière dimension\n",
    "attn = softmax(attn)  # Coefficient d'attention pour chaque Matrices d'adjacence et Embedding spatial assicié  (Ici 1 seule matrice d'adjacence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
