{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_time_slots_labels' from 'utilities_DL' (/Users/romainrochas/Desktop/Codes/Cleaned_Code/prediction_validation/utilities_DL.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vc/gn83ctb97rd5lmlbh8djj9fr0000gr/T/ipykernel_5507/68842539.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpaths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities_DL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_DataSet_and_invalid_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_period_coverage_with_netmob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Codes/Cleaned_Code/prediction_validation/utilities_DL.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptimizer_specific_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mDL_class\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantileLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mDataSet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTE_transfer_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTE_transfer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Codes/Cleaned_Code/prediction_validation/dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msplit_df\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_valid_test_split_iterative_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msave_results\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mread_object\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDataset_get_save_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutilities_DL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_time_slots_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m# ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_time_slots_labels' from 'utilities_DL' (/Users/romainrochas/Desktop/Codes/Cleaned_Code/prediction_validation/utilities_DL.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from DL_class import TrainValidTest_Split_Normalize,InvalidDatesCleaner,DatesVerifFeatureVect\n",
    "\n",
    "import os\n",
    "import pandas as pd \n",
    "import torch\n",
    "import pickle \n",
    "import numpy as np \n",
    "\n",
    "from paths import folder_path,file_name\n",
    "from config import get_args\n",
    "from utilities_DL import get_DataSet_and_invalid_dates, match_period_coverage_with_netmob\n",
    "\n",
    "\n",
    "# ==================== Load Subway-in Dataset : ====================\n",
    "# Load config\n",
    "model_name = 'STGCN' #'CNN'\n",
    "netmob = True\n",
    "args = get_args(model_name)\n",
    "#args = get_args(model_name = model_name,learn_graph_structure = True)  # MTGNN\n",
    "\n",
    "# Modification : \n",
    "args.K_fold = 1\n",
    "args.ray = False\n",
    "\n",
    "# Load Init DataSet \n",
    "dataset,invalid_dates = get_DataSet_and_invalid_dates(args.abs_path, folder_path,file_name,\n",
    "                                                      args.W,args.D,args.H,args.step_ahead,\n",
    "                                                      single_station = False,coverage_period = None)\n",
    "\n",
    "coverage = match_period_coverage_with_netmob(dataset)\n",
    "\n",
    "dataset,invalid_dates = get_DataSet_and_invalid_dates(args.abs_path, folder_path,file_name,\n",
    "                                                      args.W,args.D,args.H,args.step_ahead,\n",
    "                                                      single_station = False,coverage_period = coverage)\n",
    "\n",
    "# ==================== ........................ ====================\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    data_folder_path = '../../../data/' \n",
    "else:\n",
    "    data_folder_path = '../../Data/'\n",
    "\n",
    "\n",
    "# === INIT ====\n",
    "save_folder = f\"{data_folder_path}NetMob_tensor/\"\n",
    "netmob_data_folder_path = f\"{data_folder_path}NetMob/\"\n",
    "step_south_north = 287  # Incremente by 287-ids when passing from south to north. \n",
    "epsilon=1000  #epsilon : radius, in meter (1000m) \n",
    "# W,H = 2*(epsilon//100 + 1), 2*(epsilon//100 + 1)\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "# === .... ===\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ===== Load NetMob Data: =====\n",
    "# NetMob Tensor : [T,N,C,H,W]\n",
    "# dims : [0,-2,-1]  -> dimension for which we want to retrieve stats \n",
    "try :\n",
    "    netmob_T = torch.stack([torch.load(f\"{save_folder}station_{station}.pt\") for station in ref_subway.COD_TRG])\n",
    "    netmob_T = netmob_T.permute(1,0,*range(2, netmob_T.dim()))\n",
    "\n",
    "except:\n",
    "    netmob_T = torch.randn(7300,40,2,22,22)\n",
    "    print(\"Load impossible. Création d'un random Tensor\")\n",
    "\n",
    "print('Init NetMob Dataset: ', netmob_T.size())\n",
    "print('Number of Nan Value: ',torch.isnan(netmob_T).sum())\n",
    "print('Total Number of Elements: ', netmob_T.numel() )\n",
    "# ===== ....... =====\n",
    "T = netmob_T.size(0)\n",
    "\n",
    "# Tackle a specific fold : \n",
    "netmob_T1 = netmob_T[:100]\n",
    "\n",
    "# Init :\n",
    "dims = [0,-2,-1]\n",
    "minmaxnorm = True\n",
    "standardize = False\n",
    "\n",
    "# ============ Load Train/Valid/Test Indices and removed forbidden dates : ============\n",
    "# invalid dates = \n",
    "# invalid_indices = get_indices_from_dates(invalid)\n",
    "indices = np.arange(T)\n",
    "np.random.shuffle(indices)\n",
    "invalid_indices = indices[:100]\n",
    "\n",
    "# Get Split indices :\n",
    "train_indices = np.arange(50)\n",
    "valid_indices = np.arange(60,70)\n",
    "test_indices = np.arange(80,100)\n",
    "\n",
    "# Remove invalid_dates from indices :\n",
    "cleaner = InvalidDatesCleaner(invalid_indices = invalid_indices)\n",
    "\n",
    "train_indices = cleaner.clean_indices(train_indices)\n",
    "valid_indices = cleaner.clean_indices(valid_indices)\n",
    "test_indices = cleaner.clean_indices(test_indices)\n",
    "# ============ .......................................................... ============\n",
    "\n",
    "# Load Splitter Object\n",
    "splitter = TrainValidTest_Split_Normalize(netmob_T1,dims,train_indices, valid_indices, test_indices,minmaxnorm=minmaxnorm,standardize=standardize)\n",
    "\n",
    "\n",
    "# Split DataSet and Normalize accoding Stats from Training Set \n",
    "train_dataset,valid_dataset,test_dataset = splitter.load_normalize_tensor_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pour le cas des NetMob Data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Trouver un moyen d'uniformiser 'time_step_per_hour' pour toute les données, genre dénominateur commun etc.\n",
    "dates_verif_obj = DatesVerifFeatureVect(dataset.df_dates, Weeks = args.W, Days = args.D, historical_len = args.H, step_ahead = args.step_ahead, time_step_per_hour = dataset.time_step_per_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.get_feature_vect(invalid_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-16 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-16 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-16 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-16 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>2019-05-31 22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>2019-05-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>2019-05-31 23:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>2019-05-31 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>2019-05-31 23:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7392 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date\n",
       "0    2019-03-16 00:00:00\n",
       "1    2019-03-16 00:15:00\n",
       "2    2019-03-16 00:30:00\n",
       "3    2019-03-16 00:45:00\n",
       "4    2019-03-16 01:00:00\n",
       "...                  ...\n",
       "7387 2019-05-31 22:45:00\n",
       "7388 2019-05-31 23:00:00\n",
       "7389 2019-05-31 23:15:00\n",
       "7390 2019-05-31 23:30:00\n",
       "7391 2019-05-31 23:45:00\n",
       "\n",
       "[7392 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-672</th>\n",
       "      <th>t-96</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t+0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>2019-03-16 00:00:00</td>\n",
       "      <td>2019-03-22 00:00:00</td>\n",
       "      <td>2019-03-22 22:30:00</td>\n",
       "      <td>2019-03-22 22:45:00</td>\n",
       "      <td>2019-03-22 23:00:00</td>\n",
       "      <td>2019-03-22 23:15:00</td>\n",
       "      <td>2019-03-22 23:30:00</td>\n",
       "      <td>2019-03-22 23:45:00</td>\n",
       "      <td>2019-03-23 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>2019-03-16 00:15:00</td>\n",
       "      <td>2019-03-22 00:15:00</td>\n",
       "      <td>2019-03-22 22:45:00</td>\n",
       "      <td>2019-03-22 23:00:00</td>\n",
       "      <td>2019-03-22 23:15:00</td>\n",
       "      <td>2019-03-22 23:30:00</td>\n",
       "      <td>2019-03-22 23:45:00</td>\n",
       "      <td>2019-03-23 00:00:00</td>\n",
       "      <td>2019-03-23 00:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2019-03-16 00:30:00</td>\n",
       "      <td>2019-03-22 00:30:00</td>\n",
       "      <td>2019-03-22 23:00:00</td>\n",
       "      <td>2019-03-22 23:15:00</td>\n",
       "      <td>2019-03-22 23:30:00</td>\n",
       "      <td>2019-03-22 23:45:00</td>\n",
       "      <td>2019-03-23 00:00:00</td>\n",
       "      <td>2019-03-23 00:15:00</td>\n",
       "      <td>2019-03-23 00:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2019-03-16 00:45:00</td>\n",
       "      <td>2019-03-22 00:45:00</td>\n",
       "      <td>2019-03-22 23:15:00</td>\n",
       "      <td>2019-03-22 23:30:00</td>\n",
       "      <td>2019-03-22 23:45:00</td>\n",
       "      <td>2019-03-23 00:00:00</td>\n",
       "      <td>2019-03-23 00:15:00</td>\n",
       "      <td>2019-03-23 00:30:00</td>\n",
       "      <td>2019-03-23 00:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2019-03-16 01:00:00</td>\n",
       "      <td>2019-03-22 01:00:00</td>\n",
       "      <td>2019-03-22 23:30:00</td>\n",
       "      <td>2019-03-22 23:45:00</td>\n",
       "      <td>2019-03-23 00:00:00</td>\n",
       "      <td>2019-03-23 00:15:00</td>\n",
       "      <td>2019-03-23 00:30:00</td>\n",
       "      <td>2019-03-23 00:45:00</td>\n",
       "      <td>2019-03-23 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7387</th>\n",
       "      <td>2019-05-24 22:45:00</td>\n",
       "      <td>2019-05-30 22:45:00</td>\n",
       "      <td>2019-05-31 21:15:00</td>\n",
       "      <td>2019-05-31 21:30:00</td>\n",
       "      <td>2019-05-31 21:45:00</td>\n",
       "      <td>2019-05-31 22:00:00</td>\n",
       "      <td>2019-05-31 22:15:00</td>\n",
       "      <td>2019-05-31 22:30:00</td>\n",
       "      <td>2019-05-31 22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7388</th>\n",
       "      <td>2019-05-24 23:00:00</td>\n",
       "      <td>2019-05-30 23:00:00</td>\n",
       "      <td>2019-05-31 21:30:00</td>\n",
       "      <td>2019-05-31 21:45:00</td>\n",
       "      <td>2019-05-31 22:00:00</td>\n",
       "      <td>2019-05-31 22:15:00</td>\n",
       "      <td>2019-05-31 22:30:00</td>\n",
       "      <td>2019-05-31 22:45:00</td>\n",
       "      <td>2019-05-31 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7389</th>\n",
       "      <td>2019-05-24 23:15:00</td>\n",
       "      <td>2019-05-30 23:15:00</td>\n",
       "      <td>2019-05-31 21:45:00</td>\n",
       "      <td>2019-05-31 22:00:00</td>\n",
       "      <td>2019-05-31 22:15:00</td>\n",
       "      <td>2019-05-31 22:30:00</td>\n",
       "      <td>2019-05-31 22:45:00</td>\n",
       "      <td>2019-05-31 23:00:00</td>\n",
       "      <td>2019-05-31 23:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7390</th>\n",
       "      <td>2019-05-24 23:30:00</td>\n",
       "      <td>2019-05-30 23:30:00</td>\n",
       "      <td>2019-05-31 22:00:00</td>\n",
       "      <td>2019-05-31 22:15:00</td>\n",
       "      <td>2019-05-31 22:30:00</td>\n",
       "      <td>2019-05-31 22:45:00</td>\n",
       "      <td>2019-05-31 23:00:00</td>\n",
       "      <td>2019-05-31 23:15:00</td>\n",
       "      <td>2019-05-31 23:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>2019-05-24 23:45:00</td>\n",
       "      <td>2019-05-30 23:45:00</td>\n",
       "      <td>2019-05-31 22:15:00</td>\n",
       "      <td>2019-05-31 22:30:00</td>\n",
       "      <td>2019-05-31 22:45:00</td>\n",
       "      <td>2019-05-31 23:00:00</td>\n",
       "      <td>2019-05-31 23:15:00</td>\n",
       "      <td>2019-05-31 23:30:00</td>\n",
       "      <td>2019-05-31 23:45:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5662 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   t-672                t-96                 t-6  \\\n",
       "672  2019-03-16 00:00:00 2019-03-22 00:00:00 2019-03-22 22:30:00   \n",
       "673  2019-03-16 00:15:00 2019-03-22 00:15:00 2019-03-22 22:45:00   \n",
       "674  2019-03-16 00:30:00 2019-03-22 00:30:00 2019-03-22 23:00:00   \n",
       "675  2019-03-16 00:45:00 2019-03-22 00:45:00 2019-03-22 23:15:00   \n",
       "676  2019-03-16 01:00:00 2019-03-22 01:00:00 2019-03-22 23:30:00   \n",
       "...                  ...                 ...                 ...   \n",
       "7387 2019-05-24 22:45:00 2019-05-30 22:45:00 2019-05-31 21:15:00   \n",
       "7388 2019-05-24 23:00:00 2019-05-30 23:00:00 2019-05-31 21:30:00   \n",
       "7389 2019-05-24 23:15:00 2019-05-30 23:15:00 2019-05-31 21:45:00   \n",
       "7390 2019-05-24 23:30:00 2019-05-30 23:30:00 2019-05-31 22:00:00   \n",
       "7391 2019-05-24 23:45:00 2019-05-30 23:45:00 2019-05-31 22:15:00   \n",
       "\n",
       "                     t-5                 t-4                 t-3  \\\n",
       "672  2019-03-22 22:45:00 2019-03-22 23:00:00 2019-03-22 23:15:00   \n",
       "673  2019-03-22 23:00:00 2019-03-22 23:15:00 2019-03-22 23:30:00   \n",
       "674  2019-03-22 23:15:00 2019-03-22 23:30:00 2019-03-22 23:45:00   \n",
       "675  2019-03-22 23:30:00 2019-03-22 23:45:00 2019-03-23 00:00:00   \n",
       "676  2019-03-22 23:45:00 2019-03-23 00:00:00 2019-03-23 00:15:00   \n",
       "...                  ...                 ...                 ...   \n",
       "7387 2019-05-31 21:30:00 2019-05-31 21:45:00 2019-05-31 22:00:00   \n",
       "7388 2019-05-31 21:45:00 2019-05-31 22:00:00 2019-05-31 22:15:00   \n",
       "7389 2019-05-31 22:00:00 2019-05-31 22:15:00 2019-05-31 22:30:00   \n",
       "7390 2019-05-31 22:15:00 2019-05-31 22:30:00 2019-05-31 22:45:00   \n",
       "7391 2019-05-31 22:30:00 2019-05-31 22:45:00 2019-05-31 23:00:00   \n",
       "\n",
       "                     t-2                 t-1                 t+0  \n",
       "672  2019-03-22 23:30:00 2019-03-22 23:45:00 2019-03-23 00:00:00  \n",
       "673  2019-03-22 23:45:00 2019-03-23 00:00:00 2019-03-23 00:15:00  \n",
       "674  2019-03-23 00:00:00 2019-03-23 00:15:00 2019-03-23 00:30:00  \n",
       "675  2019-03-23 00:15:00 2019-03-23 00:30:00 2019-03-23 00:45:00  \n",
       "676  2019-03-23 00:30:00 2019-03-23 00:45:00 2019-03-23 01:00:00  \n",
       "...                  ...                 ...                 ...  \n",
       "7387 2019-05-31 22:15:00 2019-05-31 22:30:00 2019-05-31 22:45:00  \n",
       "7388 2019-05-31 22:30:00 2019-05-31 22:45:00 2019-05-31 23:00:00  \n",
       "7389 2019-05-31 22:45:00 2019-05-31 23:00:00 2019-05-31 23:15:00  \n",
       "7390 2019-05-31 23:00:00 2019-05-31 23:15:00 2019-05-31 23:30:00  \n",
       "7391 2019-05-31 23:15:00 2019-05-31 23:30:00 2019-05-31 23:45:00  \n",
       "\n",
       "[5662 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_verif"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessingclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
