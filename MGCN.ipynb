{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utilities import DataSet\n",
    "import pandas as pd\n",
    "from dl_models.GCN_based_model import graphconv,MGCN_conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq  ='3min'\n",
    "freq_min = int(freq.split('min')[0])\n",
    "\n",
    "time_step_per_hour = int(60/freq_min) #3min agg\n",
    "\n",
    "historical_len = 7\n",
    "Days = 1\n",
    "Weeks = 1\n",
    "step_ahead = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'data/Sub_Tram_11_2019_03_2020/1_month_df_subway.csv'\n",
    "subway_nov = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep only lane 'A'. Fill empty value by '0' :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>COD_TRG</th>\n",
       "      <th>PER</th>\n",
       "      <th>AMP</th>\n",
       "      <th>BEL</th>\n",
       "      <th>COR</th>\n",
       "      <th>HOT</th>\n",
       "      <th>FOC</th>\n",
       "      <th>MAS</th>\n",
       "      <th>CHA</th>\n",
       "      <th>REP</th>\n",
       "      <th>GRA</th>\n",
       "      <th>FLA</th>\n",
       "      <th>CUS</th>\n",
       "      <th>BON</th>\n",
       "      <th>SOI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:03:00</th>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:06:00</th>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:09:00</th>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:12:00</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "COD_TRG               PER   AMP   BEL   COR   HOT  FOC   MAS   CHA  REP   GRA  \\\n",
       "2019-11-01 00:00:00  10.0  10.0  29.0  14.0  43.0  2.0  13.0   4.0  6.0  19.0   \n",
       "2019-11-01 00:03:00  28.0   2.0  18.0  32.0  41.0  3.0   7.0  16.0  2.0   6.0   \n",
       "2019-11-01 00:06:00  19.0   5.0  23.0  16.0  41.0  5.0  10.0   7.0  1.0   9.0   \n",
       "2019-11-01 00:09:00  19.0   3.0  29.0   8.0  64.0  0.0  12.0   0.0  2.0   2.0   \n",
       "2019-11-01 00:12:00  13.0   0.0  25.0  18.0  34.0  3.0   3.0  15.0  1.0   1.0   \n",
       "\n",
       "COD_TRG              FLA  CUS  BON  SOI  \n",
       "2019-11-01 00:00:00  2.0  0.0  1.0  1.0  \n",
       "2019-11-01 00:03:00  0.0  2.0  2.0  1.0  \n",
       "2019-11-01 00:06:00  1.0  0.0  0.0  0.0  \n",
       "2019-11-01 00:09:00  0.0  0.0  0.0  0.0  \n",
       "2019-11-01 00:12:00  0.0  3.0  0.0  1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = subway_nov[subway_nov['lane'] =='A'][['COD_TRG','Flow','VAL_DATE']]\n",
    "sub_df = sub_df.groupby(['COD_TRG','VAL_DATE']).sum()\n",
    "sub_df = sub_df.reset_index()\n",
    "sub_df.VAL_DATE = pd.to_datetime(sub_df.VAL_DATE) \n",
    "\n",
    "# Reindex date\n",
    "start,end = sub_df.VAL_DATE.iloc[0],sub_df.VAL_DATE.iloc[-1]\n",
    "date_index = pd.date_range(start = start,end = end, freq = '3min')\n",
    "sub_df = sub_df.pivot(index = 'VAL_DATE',columns = 'COD_TRG',values = 'Flow')\n",
    "sub_df = sub_df.reindex(date_index).fillna(0)\n",
    "\n",
    "#Reindex columns :\n",
    "stations = ['PER','AMP','BEL','COR','HOT','FOC','MAS','CHA','REP','GRA','FLA','CUS','BON','SOI']\n",
    "sub_df = sub_df[stations]\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Inputs : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Feature Vector :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector shape:  torch.Size([10560, 14, 9])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t-3360</th>\n",
       "      <th>t-480</th>\n",
       "      <th>t-7</th>\n",
       "      <th>t-6</th>\n",
       "      <th>t-5</th>\n",
       "      <th>t-4</th>\n",
       "      <th>t-3</th>\n",
       "      <th>t-2</th>\n",
       "      <th>t-1</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>2019-11-01 00:00:00</td>\n",
       "      <td>2019-11-07 00:00:00</td>\n",
       "      <td>2019-11-07 23:12:00</td>\n",
       "      <td>2019-11-07 23:15:00</td>\n",
       "      <td>2019-11-07 23:18:00</td>\n",
       "      <td>2019-11-07 23:21:00</td>\n",
       "      <td>2019-11-07 23:24:00</td>\n",
       "      <td>2019-11-07 23:27:00</td>\n",
       "      <td>2019-11-07 23:30:00</td>\n",
       "      <td>2019-11-08 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3361</th>\n",
       "      <td>2019-11-01 00:03:00</td>\n",
       "      <td>2019-11-07 00:03:00</td>\n",
       "      <td>2019-11-07 23:15:00</td>\n",
       "      <td>2019-11-07 23:18:00</td>\n",
       "      <td>2019-11-07 23:21:00</td>\n",
       "      <td>2019-11-07 23:24:00</td>\n",
       "      <td>2019-11-07 23:27:00</td>\n",
       "      <td>2019-11-07 23:30:00</td>\n",
       "      <td>2019-11-07 23:33:00</td>\n",
       "      <td>2019-11-08 00:03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>2019-11-01 00:06:00</td>\n",
       "      <td>2019-11-07 00:06:00</td>\n",
       "      <td>2019-11-07 23:18:00</td>\n",
       "      <td>2019-11-07 23:21:00</td>\n",
       "      <td>2019-11-07 23:24:00</td>\n",
       "      <td>2019-11-07 23:27:00</td>\n",
       "      <td>2019-11-07 23:30:00</td>\n",
       "      <td>2019-11-07 23:33:00</td>\n",
       "      <td>2019-11-07 23:36:00</td>\n",
       "      <td>2019-11-08 00:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3363</th>\n",
       "      <td>2019-11-01 00:09:00</td>\n",
       "      <td>2019-11-07 00:09:00</td>\n",
       "      <td>2019-11-07 23:21:00</td>\n",
       "      <td>2019-11-07 23:24:00</td>\n",
       "      <td>2019-11-07 23:27:00</td>\n",
       "      <td>2019-11-07 23:30:00</td>\n",
       "      <td>2019-11-07 23:33:00</td>\n",
       "      <td>2019-11-07 23:36:00</td>\n",
       "      <td>2019-11-07 23:39:00</td>\n",
       "      <td>2019-11-08 00:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3364</th>\n",
       "      <td>2019-11-01 00:12:00</td>\n",
       "      <td>2019-11-07 00:12:00</td>\n",
       "      <td>2019-11-07 23:24:00</td>\n",
       "      <td>2019-11-07 23:27:00</td>\n",
       "      <td>2019-11-07 23:30:00</td>\n",
       "      <td>2019-11-07 23:33:00</td>\n",
       "      <td>2019-11-07 23:36:00</td>\n",
       "      <td>2019-11-07 23:39:00</td>\n",
       "      <td>2019-11-07 23:42:00</td>\n",
       "      <td>2019-11-08 00:12:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  t-3360               t-480                 t-7  \\\n",
       "3360 2019-11-01 00:00:00 2019-11-07 00:00:00 2019-11-07 23:12:00   \n",
       "3361 2019-11-01 00:03:00 2019-11-07 00:03:00 2019-11-07 23:15:00   \n",
       "3362 2019-11-01 00:06:00 2019-11-07 00:06:00 2019-11-07 23:18:00   \n",
       "3363 2019-11-01 00:09:00 2019-11-07 00:09:00 2019-11-07 23:21:00   \n",
       "3364 2019-11-01 00:12:00 2019-11-07 00:12:00 2019-11-07 23:24:00   \n",
       "\n",
       "                     t-6                 t-5                 t-4  \\\n",
       "3360 2019-11-07 23:15:00 2019-11-07 23:18:00 2019-11-07 23:21:00   \n",
       "3361 2019-11-07 23:18:00 2019-11-07 23:21:00 2019-11-07 23:24:00   \n",
       "3362 2019-11-07 23:21:00 2019-11-07 23:24:00 2019-11-07 23:27:00   \n",
       "3363 2019-11-07 23:24:00 2019-11-07 23:27:00 2019-11-07 23:30:00   \n",
       "3364 2019-11-07 23:27:00 2019-11-07 23:30:00 2019-11-07 23:33:00   \n",
       "\n",
       "                     t-3                 t-2                 t-1  \\\n",
       "3360 2019-11-07 23:24:00 2019-11-07 23:27:00 2019-11-07 23:30:00   \n",
       "3361 2019-11-07 23:27:00 2019-11-07 23:30:00 2019-11-07 23:33:00   \n",
       "3362 2019-11-07 23:30:00 2019-11-07 23:33:00 2019-11-07 23:36:00   \n",
       "3363 2019-11-07 23:33:00 2019-11-07 23:36:00 2019-11-07 23:39:00   \n",
       "3364 2019-11-07 23:36:00 2019-11-07 23:39:00 2019-11-07 23:42:00   \n",
       "\n",
       "                       t  \n",
       "3360 2019-11-08 00:00:00  \n",
       "3361 2019-11-08 00:03:00  \n",
       "3362 2019-11-08 00:06:00  \n",
       "3363 2019-11-08 00:09:00  \n",
       "3364 2019-11-08 00:12:00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ut = DataSet(sub_df,time_step_per_hour=time_step_per_hour)\n",
    "norm_Ut = Ut.normalize()    # Normalize before getting the \"Feature vector\"  (or \"Feature Tensor\")\n",
    "(X,Y,dates_verif) = norm_Ut.get_feature_vect(step_ahead,historical_len,Days,Weeks)\n",
    "print('Feature vector shape: ',X.shape)   # Nb Sample, Nb Nodes, Sequence Length\n",
    "dates_verif.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Adjacency Matrices :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_indep = torch.diag(torch.ones(len(Ut.df.columns)))   # Matrice d'adjacence identité, personne n'est connecté avec personne\n",
    "A_Neighbors = torch.sum(torch.stack([torch.diag(torch.ones(len(Ut.df.columns)-abs(i)),i) for i in [-1,0,1]]),dim =0)   #Une seule ligne de métro, donc tri-diagonale\n",
    "A_learnable = torch.nn.Parameter(torch.randn(len(Ut.df.columns),len(Ut.df.columns)),requires_grad=True)   #Matrice d'adjacence apprentissable\n",
    "\n",
    "gcnconv_matrix = A_indep.unsqueeze(0)\n",
    "# Then convert into \"Laplacian Matrix\", or with \"random_walk Matrix\", or with another one ...\n",
    "#A_indep = \n",
    "#A_Neighbors =\n",
    "#A_learnable = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T,N,L = X.shape # [ Number of available time-slot ,Number of spatial unities, Historical Length ]\n",
    "x = X.unsqueeze(1) # add the channel dimension (here, only \"flow')\n",
    "x_b = x[:32]   # Select only one batch \n",
    "n_adj =  A_indep.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B,C,N,L : [32,1,14,9]\n"
     ]
    }
   ],
   "source": [
    "GCN = graphconv(c_in = x.shape[1], c_out = 64, K=2, graph_conv_act_func = 'relu',enable_bias=True)  # K =2 dans MRGNN car considère Pattern et Adj matrix\n",
    "B, C, N, L = x_b.shape\n",
    "K = 1\n",
    "c_out = 64\n",
    "\n",
    "\n",
    "print(f'B,C,N,L : [{B},{C},{N},{L}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "einsum(): subscript b has size 448 for operand 1 which does not broadcast with previously seen size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m mgcn_model \u001b[38;5;241m=\u001b[39m MGCN_conv(L,c_out,n_adj)\n\u001b[1;32m      3\u001b[0m x_b \u001b[38;5;241m=\u001b[39m X[:\u001b[38;5;241m32\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m AXW,embedding,reshaped_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmgcn_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgcnconv_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding a d\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabord été opéré sur la dernière dimension (X*W, temporelle), Puis la convolution (A*(XW)) a sommmé les embedding de chacun des voisins (ou Noeud en lien avec le noeud tagret).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX.shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, AXW.shape:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mAXW\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ray_tensorboard/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ray_tensorboard/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Codes/Cleaned_Code/prediction validation/dl_models/GCN_based_model.py:64\u001b[0m, in \u001b[0;36mMGCN_conv.forward\u001b[0;34m(self, x, adj_matrix)\u001b[0m\n\u001b[1;32m     61\u001b[0m embedding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbnl,klh -> bknh\u001b[39m\u001b[38;5;124m'\u001b[39m,x,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight)   \u001b[38;5;66;03m# Embedding sur les feature de chaque Noeud\u001b[39;00m\n\u001b[1;32m     62\u001b[0m reshaped_embedding \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,N2,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_out)    \u001b[38;5;66;03m#Stack la dimension k sur l'axe 0  [n_adj*B,N2,C_out]  et pour einsum : [b,n,h]\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m convoluted \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbpn,bnh -> bph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstacked_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreshaped_embedding\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     65\u001b[0m convoluted \u001b[38;5;241m=\u001b[39m convoluted\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_adj,B,N1,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_out)      \u001b[38;5;66;03m#Unstack la dimension 0, pour séparer les n_adj matrices d'adjacences\u001b[39;00m\n\u001b[1;32m     67\u001b[0m convoluted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(convoluted \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ray_tensorboard/lib/python3.10/site-packages/torch/functional.py:377\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m einsum(equation, \u001b[38;5;241m*\u001b[39m_operands)\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(operands) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39menabled:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# the path for contracting 0 or 1 time(s) is already optimized\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;66;03m# or the user has disabled using opt_einsum\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mequation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperands\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    379\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt_einsum\u001b[38;5;241m.\u001b[39mis_available():\n",
      "\u001b[0;31mRuntimeError\u001b[0m: einsum(): subscript b has size 448 for operand 1 which does not broadcast with previously seen size 32"
     ]
    }
   ],
   "source": [
    "c_out = 16\n",
    "mgcn_model = MGCN_conv(L,c_out,n_adj)\n",
    "x_b = X[:32]\n",
    "AXW,embedding,reshaped_embedding = mgcn_model(x_b,gcnconv_matrix)\n",
    "\n",
    "print(\"L'embedding a d'abord été opéré sur la dernière dimension (X*W, temporelle), Puis la convolution (A*(XW)) a sommmé les embedding de chacun des voisins (ou Noeud en lien avec le noeud tagret).\")\n",
    "print(f'X.shape: {x.shape}, AXW.shape:{AXW.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mGCN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mA_Neighbors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ray_tensorboard/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ray_tensorboard/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Codes/Cleaned_Code/prediction validation/dl_models/GCN_based_model.py:22\u001b[0m, in \u001b[0;36mgraphconv.forward\u001b[0;34m(self, x, gcnconv_matrix)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,x,gcnconv_matrix):\n\u001b[0;32m---> 22\u001b[0m     B, C, L, N \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     23\u001b[0m     n_mat \u001b[38;5;241m=\u001b[39m  gcnconv_matrix\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_in)  \u001b[38;5;66;03m#[B, C_in, L, N] -> [BLN, C_in]\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "GCN(x_b,A_Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GCN Détaillé : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_b: torch.Size([32, 1, 14, 9]), W: torch.Size([1, 1, 64]), Cause there are 1 adjacency matrices (K), 1 C_in and 64 C_out\n",
      "reshaped x_b: torch.Size([4032, 1]), Cause we have to flatten x_b along the Channel axis, and then pass through a SPATIAL embedding (Linear layer, on C_in of each sample,nodes,historical element)\n",
      "shape of reshaped_xb after K embedding on C_in:  torch.Size([1, 4032, 64])\n",
      "Embedded feature vect reshaped:  torch.Size([1, 288, 14, 64]) \n",
      "\n",
      "Adjacency matrix A_indep:  torch.Size([14, 14]) batched Multi adj_matrix:  torch.Size([1, 288, 14, 14])\n",
      "Convolution A*(XW):  torch.Size([1, 288, 14, 64])\n",
      "Reshaped convolution output: torch.Size([1, 32, 64, 14, 9])\n"
     ]
    }
   ],
   "source": [
    "weight = nn.Parameter(torch.FloatTensor(K,C,c_out))\n",
    "bias = nn.Parameter(torch.FloatTensor(c_out))\n",
    "print(f'x_b: {x_b.shape}, W: {weight.shape}, Cause there are {K} adjacency matrices (K), {C} C_in and {c_out} C_out')\n",
    "x_b = x_b.reshape(-1, C)  #[B, C_in, L, N] -> [BLN, C_in]\n",
    "print(f'reshaped x_b: {x_b.shape}, Cause we have to flatten x_b along the Channel axis, and then pass through a SPATIAL embedding (Linear layer, on C_in of each sample,nodes,historical element)')\n",
    "\n",
    "# Embedding on C_in:  X*W\n",
    "embedd_c_in = torch.einsum('ab, cbd->cad',x_b,weight)   # [BLN,C_in], [K,C_in,C_out] -> [K,BLN,C_out]n  Propose K embedding de C_in\n",
    "print('shape of reshaped_xb after K embedding on C_in: ',embedd_c_in.shape)\n",
    "reshaped_embedd_c_in = embedd_c_in.view(K, B*L,N,-1)  #[K,BLN,C_out] ->  [K,BL,N,C_out] \n",
    "print('Embedded feature vect reshaped: ',reshaped_embedd_c_in.shape, '\\n')\n",
    "\n",
    "# Concat Adj Matrix \n",
    "batched_adj_matrix = A_indep.repeat(1,B*L,1,1)\n",
    "print('Adjacency matrix A_indep: ',A_indep.shape,'batched Multi adj_matrix: ',batched_adj_matrix.shape)\n",
    "\n",
    "# Convolution A*(XW)\n",
    "convolutionned = torch.einsum('ecab,ecbd->ecad',batched_adj_matrix,reshaped_embedd_c_in)  #[K,BL,N1,N2] ,[K,BL,N2,C_out]  -> [K,BL,N1,C_out] \n",
    "print('Convolution A*(XW): ',convolutionned.shape)\n",
    "\n",
    "#Add bias: \n",
    "convolutionned_n_biased = convolutionned + bias\n",
    "\n",
    "# Reshape and Permute: \n",
    "H =convolutionned_n_biased.view(K,B,L,-1,c_out).permute(0,1,4,3,2)\n",
    "print(f'Reshaped convolution output: {H.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ray_tensorboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
