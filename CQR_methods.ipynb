{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utilities_DL import get_DataSet_and_invalid_dates,get_MultiModel_loss_args_emb_opts,load_init_trainer\n",
    "from DL_class import MultiModelTrainer, Trainer\n",
    "from config import get_args\n",
    "from save_results import build_results_df\n",
    "from paths import folder_path,file_name,get_save_directory\n",
    "import torch\n",
    "from plotting import plot_k_fold_split\n",
    "\n",
    "# ==== GET PARAMETERS ====\n",
    "# Load config\n",
    "model_name ='DCRNN' #'MTGNN' # 'STGCN'  #'CNN' # \n",
    "args = get_args(model_name)\n",
    "\n",
    "# Modification :\n",
    "args.epochs = 100\n",
    "args.K_fold = 6   # Means we will use the first fold for the Ray Tuning and the 5 other ones to get the metrics\n",
    "if torch.cuda.is_available():\n",
    "    args.device = 'cuda:0'\n",
    "    args.batch_size = 256\n",
    "    args.single_station = False\n",
    "else :\n",
    "    args.device = 'cpu'\n",
    "    args.batch_size = 32\n",
    "    args.single_station = False\n",
    "\n",
    "args.ray = False\n",
    "\n",
    "args.loss_function_type = 'quantile'  #'MSE' #\n",
    "\n",
    "if args.loss_function_type == 'MSE':\n",
    "    args.out_dim = 1\n",
    "    args.alpha = None\n",
    "    args.type_calendar = 'tuple'\n",
    "\n",
    "else:\n",
    "    args.embedding_dim = 3\n",
    "    args.calendar_class = 3\n",
    "    args.position = 'input'\n",
    "    args.specific_lr = False\n",
    "    args.type_calendar = 'tuple'\n",
    "    args.out_dim = 2\n",
    "    args.alpha = 0.1\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "save_dir = get_save_directory(args)\n",
    "\n",
    "Datasets,DataLoader_list,dic_class2rpz,nb_words_embedding,time_slots_labels,dic_rpz2class = load_init_trainer(folder_path,file_name,args)\n",
    "(loss_function,Model_list,Optimizer_list,Scheduler_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz,n_vertex = len(Datasets[0].columns))\n",
    "Datasets,DataLoader_list,Model_list,Optimizer_list,Scheduler_list = Datasets[1:],DataLoader_list[1:],Model_list[1:],Optimizer_list[1:],Scheduler_list[1:]\n",
    "\n",
    "multimodeltrainer = MultiModelTrainer(Datasets,Model_list,DataLoader_list,args,Optimizer_list,loss_function,Scheduler_list,args_embedding=args_embedding,save_dir = save_dir,dic_class2rpz=dic_class2rpz)\n",
    "\n",
    "(results_by_fold,mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds) = multimodeltrainer.K_fold_validation(mod_plot = 10)\n",
    "results_by_fold.to_csv(f\"{save_dir}results_by_fold.csv\")\n",
    "\n",
    "# Svae results \n",
    "results_df = build_results_df(results_df,args, mean_picp,mean_mpiw,dict_last_from_mean_of_folds,dict_best_from_mean_of_folds)\n",
    "results_df.to_csv(f\"{args.model_name}_{args.loss_function_type}_H{args.H}_D{args.D}_W{args.W}_E{args.epochs}_K_fold{args.K_fold}_Emb_dim{args.embedding_dim}FC1_17_8_FC2_8_4_save_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessingclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
