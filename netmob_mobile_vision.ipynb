{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_netmob_data import load_subway_shp,load_netmob_gdf,find_ids_within_epsilon,tackle_all_days,calculate_grid_size,get_grid,match_tile_ids_with_grid,resize_tensor\n",
    "from os import listdir\n",
    "import os \n",
    "import pandas as pd \n",
    "\n",
    "import torch\n",
    "import pickle \n",
    "import os\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number of NetMob Cell associated to a subway station: 318\n"
     ]
    }
   ],
   "source": [
    "data_folder_path = '../../../data/'\n",
    "save_folder = f\"{data_folder_path}NetMob_tensor/\"\n",
    "netmob_data_folder_path = f\"{data_folder_path}NetMob/\"\n",
    "epsilon=1000  #epsilon : radius, in meter (1000m) \n",
    "# W,H = 2*(epsilon//100 + 1), 2*(epsilon//100 + 1)\n",
    "\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "    \n",
    "# Load subway gdf adn NetMob gdf\n",
    "ref_subway = load_subway_shp(folder_path = data_folder_path)\n",
    "Netmob_gdf,working_zones = load_netmob_gdf(folder_path = netmob_data_folder_path,\n",
    "                             data_folder = '../Data/lyon_iris_shapefile/', \n",
    "                             geojson_path = 'Lyon.geojson',\n",
    "                             zones_path = 'lyon.shp')\n",
    "Netmob_gdf_dropped = Netmob_gdf.drop_duplicates(subset = ['tile_id'])  # Some Doubles are exis\n",
    "\n",
    "# Get Cell-Id within epsilon : \n",
    "result,joined = find_ids_within_epsilon(Netmob_gdf_dropped,ref_subway,epsilon=epsilon) \n",
    "maxi_nb_tile =  result.apply(lambda row: len(row.tile_id),axis=1).max()\n",
    "print(f\"Maximum number of NetMob Cell associated to a subway station: {maxi_nb_tile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined.explore('COD_TRG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = [app for app in listdir(netmob_data_folder_path) if ((app != 'Lyon.geojson') and (not app.startswith('.'))) ]   # Avoid hidden folder and Lyon.geojson\n",
    "Tensors = []\n",
    "# For each app\n",
    "if False:\n",
    "    for app in apps: \n",
    "        print('App: ',app)\n",
    "        metadata = {result['COD_TRG'][station_ind] : {} for station_ind in range(len(result))}\n",
    "        folder_days = [day for day in listdir(f'{netmob_data_folder_path}/{app}') if (not day.startswith('.')) ]\n",
    "        Tensors_days,metadata = tackle_all_days(result,metadata,netmob_data_folder_path,app,maxi_nb_tile,folder_days)\n",
    "        torch.save(Tensors_days,f\"{save_folder}{app}.pt\")\n",
    "        pickle.dump(metadata,open(f\"{save_folder}{app}_metadata.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tensor example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple_Video Tensor: torch.Size([77, 2, 43, 318, 96])\n"
     ]
    }
   ],
   "source": [
    "app = 'Apple_Video'\n",
    "\n",
    "Apple_Video_meta = pickle.load(open(f\"{save_folder}{app}_metadata.pkl\",\"rb\"))\n",
    "Apple_Video = torch.load(f\"{save_folder}{app}.pt\")  #[day, transfer_mode, Station, Tile_id, (hour,minutes)]\n",
    "print(f\"{app} Tensor: {Apple_Video.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ti: torch.Size([7392, 2, 318])\n"
     ]
    }
   ],
   "source": [
    "# Input adapted to station i:\n",
    "T = Apple_Video  #[Day, DL/UL, Nstation, Tile-id, (hour,minute)] \n",
    "metadata = Apple_Video_meta\n",
    "\n",
    "stations = list(metadata.keys())\n",
    "\n",
    "i = 0\n",
    "station = stations[i]\n",
    "tile_ids = np.array(metadata[station]['tile_id'])\n",
    "T_i = torch.squeeze(T[:,:,i,:,:])  #[Day, DL/UL, Tile-id, (hour,minute)] \n",
    "# BIEN ETRE SUR DE CE PERMUTE RESHAPE §§§§\n",
    "T_i = T_i.permute(1,2,0,3)  #[DL/UL, Tile-id,Day,(hour,minute)] \n",
    "T_i = T_i.reshape(T_i.size(0),T_i.size(1),-1) #[DL/UL, Tile-id, Day*(hour,minute)]\n",
    "#  ................................\n",
    "T_i = T_i.permute(2,0,1) #[Day*(hour,minute), DL/UL, Tile-id]   <-> [N,C,H*W]\n",
    "print(f\"Ti: {T_i.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_south_north = 287\n",
    "\n",
    "# Find dimensions\n",
    "H, W, tile_ids_real = calculate_grid_size(tile_ids,epsilon)\n",
    "\n",
    "# Get Grid \n",
    "grid = get_grid(tile_ids_real,H,W,step_south_north)\n",
    "\n",
    "# Match Metadata with Grid \n",
    "positions = match_tile_ids_with_grid(tile_ids_real,grid.reshape(-1))\n",
    "\n",
    "# Re-organize Tensor  \n",
    "new_T_i = resize_tensor(T_i, H,W, positions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch-2.0.1_py-3.10.5]",
   "language": "python",
   "name": "conda-env-pytorch-2.0.1_py-3.10.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
