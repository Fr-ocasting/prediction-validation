{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module xgboost\n",
      "Training and Hyper-parameter tuning with Ray is not possible\n",
      "Training and Hyper-parameter tuning with Ray is not possible\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GET PARAMETERS\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch \n",
    "import pickle\n",
    "import numpy as np \n",
    "import importlib\n",
    "import pickle\n",
    "\n",
    "# Get Parent folder : \n",
    "current_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "\n",
    "# Personnal imports: \n",
    "from constants.paths import SAVE_DIRECTORY, FOLDER_PATH\n",
    "from examples.accuracy_comparison import load_trainer_ds_from_saved_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model, without the use of NetMob: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Loading the Complete Dataset for K-fold splitting\n",
      "Coverage Period: 7392 elts between 2019-03-16 00:00:00 and 2019-05-31 23:45:00\n",
      "Invalid dates within this fold: 776\n",
      "\n",
      ">>>Tackle Target dataset: subway_in\n",
      "   Load data from: //home/rrochas/../../data/rrochas/prediction_validation/subway_in/subway_in.csv\n",
      "   Init Dataset: 'torch.Size([7392, 40]). 0 Nan values\n",
      "   TRAIN contextual_ds: torch.Size([2821, 40, 7])\n",
      "   VALID contextual_ds: torch.Size([940, 40, 7])\n",
      "   TEST contextual_ds: torch.Size([940, 40, 7])\n",
      "\n",
      ">>>Loading calendar embedding inputs ...\n",
      "    dict_keys(['dayofweek_OHE', 'hour_OHE'])\n",
      "   args_embedding.variable_selection_model_name:  MLP\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 2821 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "----------------------------------------\n",
      "Loading the dataset for fold n°5\n",
      "number of Parameters in Embedding Module: 167087\n",
      "Model size: 0.004GB\n"
     ]
    }
   ],
   "source": [
    "subfolder = 'K_fold_validation/training_wo_HP_tuning/optim/subway_in_STGCN'\n",
    "path_model_args = f\"{SAVE_DIRECTORY}/{subfolder}/best_models\"\n",
    "model_args = pickle.load(open(f\"{path_model_args}/model_args.pkl\", 'rb'))\n",
    "\n",
    "\n",
    "# trial_id1 = 'subway_in_calendar_emb64_out64_Huber_MinMax_bis1'   \n",
    "# trial_id1 = 'subway_in_calendar_emb64_out64_Huber_MinMax_horizon1_bis1'\n",
    "# trial_id1 = 'subway_in_calendar_emb64_out64_Huber_MinMax_horizon2_bis1'\n",
    "# trial_id1 = 'subway_in_calendar_emb64_out64_Huber_MinMax_horizon3_bis1'\n",
    "# trial_id1 = 'subway_in_calendar_emb64_out64_Huber_MinMax_horizon4_bis1'\n",
    "\n",
    "# Load Model from trial : \n",
    "trial_id = 'subway_in_calendar_emb64_out64_Huber_MinMax_horizon1_bis1'\n",
    "\n",
    "trial_id_updated = f\"_{trial_id}_f5\"\n",
    "args = model_args['model'][trial_id_updated]['args']\n",
    "model_save_path = f\"{path_model_args}/{trial_id_updated}.pkl\"\n",
    "trained_trainer, trained_ds, trained_args = load_trainer_ds_from_saved_trial(args,model_save_path,modification = {('device'): torch.device('cuda:0')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a New Trainer, with NetMob Inputs : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Loading the Complete Dataset for K-fold splitting\n",
      "Coverage Period: 7392 elts between 2019-03-16 00:00:00 and 2019-05-31 23:45:00\n",
      "Invalid dates within this fold: 776\n",
      "\n",
      ">>>Tackle Target dataset: subway_in\n",
      "   Load data from: //home/rrochas/../../data/rrochas/prediction_validation/subway_in/subway_in.csv\n",
      "   Init Dataset: 'torch.Size([7392, 40]). 0 Nan values\n",
      "   TRAIN contextual_ds: torch.Size([2821, 40, 7])\n",
      "   VALID contextual_ds: torch.Size([940, 40, 7])\n",
      "   TEST contextual_ds: torch.Size([940, 40, 7])\n",
      "\n",
      ">>>Loading calendar embedding inputs ...\n",
      "    dict_keys(['dayofweek_OHE', 'hour_OHE'])\n",
      "   args_embedding.variable_selection_model_name:  MLP\n",
      "\n",
      ">>>Tackle Contextual dataset:  netmob_POIs\n",
      "    ATTENTION: Dimension reduction by clustering is applied on the entire dataset. This should be done only on the training set.\n",
      "    Netmob_T.size(): torch.Size([7392, 556]). Dimensionality reduced by 35.3%\n",
      "\n",
      "\n",
      "Restraining all datasets to train common dates: 2821 dates\n",
      "Restraining all datasets to valid common dates: 940 dates\n",
      "Restraining all datasets to test common dates: 940 dates\n",
      "\n",
      "Size of Contextual datasets:\n",
      "   Init Dataset: '[torch.Size([7392, 556])]\n",
      "   TRAIN contextual_ds: [torch.Size([2821, 556, 7])]\n",
      "   VALID contextual_ds: [torch.Size([940, 556, 7])]\n",
      "   TEST contextual_ds: [torch.Size([940, 556, 7])]\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 2821 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "----------------------------------------\n",
      "Loading the dataset for fold n°1\n",
      "model_name: STGCN\n",
      "dataset_names: ['subway_in', 'calendar_embedding', 'netmob_POIs']\n",
      "dataset_for_coverage: ['subway_in', 'netmob_POIs']\n",
      "calendar_types: ['dayofweek', 'timeofday']\n",
      "embedding_calendar_types: ['dayofweek', 'hour']\n",
      "device: cuda\n",
      "optimizer: adamw\n",
      "single_station: False\n",
      "loss_function_type: HuberLoss\n",
      "freq: 15min\n",
      "train_pourcent: 100\n",
      "minmaxnorm: True\n",
      "standardize: False\n",
      "learnable_adj_matrix: False\n",
      "contextual_positions: {'calendar_dayofweek_OHE': 0, 'calendar_hour_OHE': 1, 'netmob_POIs': 2}\n",
      "quick_vision: False\n",
      "evaluate_complete_ds: True\n",
      "train_valid_test_split_method: similar_length_method\n",
      "set_spatial_units: None\n",
      "hp_tuning_on_first_fold: True\n",
      "keep_best_weights: False\n",
      "num_workers: 0\n",
      "persistent_workers: False\n",
      "pin_memory: False\n",
      "prefetch_factor: None\n",
      "drop_last: False\n",
      "mixed_precision: False\n",
      "non_blocking: True\n",
      "torch_compile: False\n",
      "backend: inductor\n",
      "prefetch_all: False\n",
      "denoising_names: ['netmob_POIs']\n",
      "denoiser_names: ['exponential']\n",
      "denoising_modes: ['train', 'valid', 'test']\n",
      "denoiser_kwargs: {'exponential': {'alpha': 0.8}}\n",
      "contextual_kwargs: {'netmob_POIs': {'need_global_attn': True, 'stacked_contextual': False, 'NetMob_selected_apps': ['Google_Maps', 'Web_Weather'], 'NetMob_transfer_mode': ['DL'], 'NetMob_selected_tags': ['iris'], 'NetMob_expanded': '', 'NetMob_only_epsilon': False, 'vision_model_name': None, 'epsilon_clustering': 0.1, 'agg_iris_target_n': None, 'use_only_for_common_dates': False, 'attn_kwargs': {'dim_feedforward': 128, 'num_heads': 4, 'dim_model': 64, 'keep_topk': 30, 'nb_layers': 3, 'latent_dim': 64}, 'loading_contextual_data': True, 'list_correspondence': ['Google_Maps_iris_DL', 'Web_Weather_iris_DL'], 'dictionnary_aggregated_iris': None, 'dict_label2agg': {0: 147, 1: 53, 2: 481, 3: 123, 4: 345, 5: 497, 6: 242, 7: 539, 8: 375, 9: 341, 10: 373, 11: 148, 12: 437, 13: 552, 14: 341, 15: 507, 16: 460, 17: 444, 18: 296, 19: 247, 20: 205, 21: 25, 22: 144, 23: 64, 24: 17, 25: 247, 26: 149, 27: 494, 28: 229, 29: 155, 30: 50, 31: 164, 32: 41, 33: 269, 34: 416, 35: 117, 36: 484, 37: 120, 38: 538, 39: 307, 40: 151, 41: 277, 42: 510, 43: 200, 44: 344, 45: 84, 46: 25, 47: 462, 48: 79, 49: 230, 50: 553, 51: 13, 52: 84, 53: 51, 54: 107, 55: 355, 56: 178, 57: 508, 58: 79, 59: 330, 60: 211, 61: 136, 62: 77, 63: 547, 64: 315, 65: 138, 66: 270, 67: 86, 68: 478, 69: 77, 70: 184, 71: 25, 72: 296, 73: 216, 74: 143, 75: 111, 76: 29, 77: 79, 78: 313, 79: 93, 80: 23, 81: 69, 82: 178, 83: 97, 84: 151, 85: 55, 86: 97, 87: 384, 88: 145, 89: 66, 90: 413, 91: 88, 92: 76, 93: 46, 94: 209, 95: 64, 96: 4, 97: 13, 98: 53, 99: 416, 100: 117, 101: 147, 102: 543, 103: 33, 104: 233, 105: 439, 106: 336, 107: 93, 108: 200, 109: 123, 110: 499, 111: 147, 112: 160, 113: 480, 114: 168, 115: 534, 116: 19, 117: 82, 118: 272, 119: 294, 120: 65, 121: 447, 122: 109, 123: 172, 124: 344, 125: 92, 126: 36, 127: 63, 128: 51, 129: 7, 130: 415, 131: 343, 132: 158, 133: 540, 134: 402, 135: 229, 136: 160, 137: 349, 138: 111, 139: 205, 140: 270, 141: 183, 142: 67, 143: 334, 144: 73, 145: 133, 146: 487, 147: 106, 148: 535, 149: 89, 150: 98, 151: 110, 152: 184, 153: 193, 154: 487, 155: 107, 156: 406, 157: 13, 158: 16, 159: 39, 160: 490, 161: 53, 162: 19, 163: 460, 164: 200, 165: 48, 166: 330, 167: 358, 168: 395, 169: 7, 170: 144, 171: 247, 172: 464, 173: 14, 174: 70, 175: 212, 176: 18, 177: 215, 178: 314, 179: 47, 180: 113, 181: 86, 182: 246, 183: 193, 184: 546, 185: 63, 186: 112, 187: 198, 188: 92, 189: 435, 190: 533, 191: 246, 192: 31, 193: 135, 194: 27, 195: 233, 196: 82, 197: 56, 198: 183, 199: 67, 200: 187, 201: 463, 202: 252, 203: 450, 204: 335, 205: 491, 206: 4, 207: 36, 208: 215, 209: 25, 210: 39, 211: 29, 212: 501, 213: 23, 214: 302, 215: 347, 216: 34, 217: 164, 218: 158, 219: 100, 220: 92, 221: 32, 222: 357, 223: 494, 224: 407, 225: 132, 226: 65, 227: 88, 228: 243, 229: 461, 230: 17, 231: 155, 232: 368, 233: 134, 234: 344, 235: 31, 236: 453, 237: 432, 238: 60, 239: 243, 240: 79, 241: 123, 242: 62, 243: 25, 244: 390, 245: 454, 246: 34, 247: 16, 248: 54, 249: 106, 250: 336, 251: 416, 252: 55, 253: 143, 254: 375, 255: 17, 256: 169, 257: 113, 258: 148, 259: 230, 260: 60, 261: 125, 262: 56, 263: 391, 264: 162, 265: 403, 266: 56, 267: 136, 268: 112, 269: 5, 270: 322, 271: 345, 272: 132, 273: 62, 274: 289, 275: 325, 276: 307, 277: 162, 278: 23, 279: 145, 280: 18, 281: 54, 282: 84, 283: 73, 284: 479, 285: 473, 286: 118, 287: 100, 288: 366, 289: 62, 290: 388, 291: 269, 292: 348, 293: 322, 294: 131, 295: 477, 296: 405, 297: 314, 298: 46, 299: 162, 300: 125, 301: 149, 302: 25, 303: 343, 304: 72, 305: 459, 306: 209, 307: 93, 308: 236, 309: 131, 310: 27, 311: 511, 312: 538, 313: 215, 314: 359, 315: 277, 316: 226, 317: 544, 318: 106, 319: 32, 320: 124, 321: 55, 322: 445, 323: 2, 324: 150, 325: 4, 326: 89, 327: 515, 328: 29, 329: 343, 330: 161, 331: 98, 332: 17, 333: 272, 334: 2, 335: 554, 336: 293, 337: 161, 338: 134, 339: 325, 340: 236, 341: 60, 342: 120, 343: 70, 344: 66, 345: 546, 346: 211, 347: 107, 348: 120, 349: 47, 350: 39, 351: 5, 352: 516, 353: 40, 354: 137, 355: 137, 356: 33, 357: 32, 358: 330, 359: 127, 360: 408, 361: 169, 362: 100, 363: 279, 364: 524, 365: 133, 366: 172, 367: 168, 368: 118, 369: 76, 370: 69, 371: 127, 372: 109, 373: 313, 374: 72, 375: 405, 376: 100, 377: 489, 378: 457, 379: 522, 380: 405, 381: 391, 382: 54, 383: 62, 384: 40, 385: 50, 386: 48, 387: 284, 388: 41, 389: 339, 390: 198, 391: 79, 392: 170, 393: 5, 394: 252, 395: 40, 396: 3, 397: 135, 398: 242, 399: 41, 400: 203, 401: 187, 402: 3, 403: 50, 404: 313, 405: 97, 406: 386, 407: 431, 408: 401, 409: 344, 410: 328, 411: 124, 412: 414, 413: 183, 414: 4, 415: 212, 416: 319, 417: 243, 418: 164, 419: 110, 420: 170, 421: 216, 422: 460, 423: 365, 424: 14, 425: 150, 426: 88, 427: 13, 428: 17, 429: 138, 430: 531, 431: 26, 432: 451, 433: 90, 434: 15, 435: 309, 436: 171, 437: 468, 438: 103, 439: 512, 440: 312, 441: 541, 442: 396, 443: 488, 444: 387, 445: 351, 446: 80, 447: 433, 448: 436, 449: 472, 450: 545, 451: 58, 452: 24, 453: 528, 454: 363, 455: 129, 456: 474, 457: 52, 458: 202, 459: 521, 460: 381, 461: 122, 462: 370, 463: 228, 464: 104, 465: 6, 466: 418, 467: 85, 468: 153, 469: 141, 470: 20, 471: 95, 472: 299, 473: 38, 474: 121, 475: 174, 476: 181, 477: 378, 478: 74, 479: 44, 480: 397, 481: 513, 482: 174, 483: 394, 484: 87, 485: 523, 486: 11, 487: 424, 488: 9, 489: 75, 490: 492, 491: 440, 492: 529, 493: 282, 494: 536, 495: 482, 496: 12, 497: 483, 498: 379, 499: 338, 500: 239, 501: 58, 502: 361, 503: 59, 504: 101, 505: 115, 506: 308, 507: 385, 508: 163, 509: 30, 510: 35, 511: 449, 512: 503, 513: 49, 514: 20, 515: 61, 516: 495, 517: 428, 518: 146, 519: 443, 520: 411, 521: 175, 522: 520, 523: 448, 524: 458, 525: 217, 526: 245, 527: 156, 528: 26, 529: 104, 530: 6, 531: 423, 532: 6, 533: 476, 534: 519, 535: 255, 536: 238, 537: 30, 538: 504, 539: 380, 540: 532, 541: 505, 542: 470, 543: 326, 544: 1, 545: 382, 546: 455, 547: 485, 548: 321, 549: 276, 550: 37, 551: 346, 552: 10, 553: 116, 554: 121, 555: 278, 556: 327, 557: 500, 558: 469, 559: 452, 560: 323, 561: 91, 562: 78, 563: 446, 564: 305, 565: 202, 566: 525, 567: 316, 568: 115, 569: 295, 570: 12, 571: 140, 572: 393, 573: 333, 574: 421, 575: 253, 576: 176, 577: 475, 578: 197, 579: 81, 580: 438, 581: 206, 582: 239, 583: 166, 584: 176, 585: 409, 586: 422, 587: 353, 588: 456, 589: 537, 590: 332, 591: 8, 592: 182, 593: 80, 594: 38, 595: 526, 596: 471, 597: 244, 598: 260, 599: 290, 600: 24, 601: 129, 602: 317, 603: 548, 604: 273, 605: 425, 606: 157, 607: 83, 608: 201, 609: 550, 610: 43, 611: 291, 612: 45, 613: 166, 614: 167, 615: 324, 616: 320, 617: 465, 618: 44, 619: 304, 620: 392, 621: 45, 622: 412, 623: 119, 624: 427, 625: 285, 626: 356, 627: 21, 628: 140, 629: 399, 630: 262, 631: 11, 632: 180, 633: 303, 634: 221, 635: 498, 636: 527, 637: 331, 638: 83, 639: 181, 640: 342, 641: 240, 642: 329, 643: 219, 644: 283, 645: 530, 646: 496, 647: 122, 648: 78, 649: 389, 650: 278, 651: 231, 652: 441, 653: 52, 654: 241, 655: 337, 656: 37, 657: 551, 658: 96, 659: 374, 660: 57, 661: 311, 662: 369, 663: 275, 664: 517, 665: 235, 666: 417, 667: 371, 668: 105, 669: 96, 670: 74, 671: 90, 672: 518, 673: 181, 674: 196, 675: 173, 676: 400, 677: 362, 678: 28, 679: 426, 680: 238, 681: 104, 682: 61, 683: 101, 684: 103, 685: 57, 686: 71, 687: 43, 688: 430, 689: 466, 690: 105, 691: 410, 692: 280, 693: 502, 694: 42, 695: 186, 696: 21, 697: 258, 698: 367, 699: 189, 700: 506, 701: 15, 702: 337, 703: 177, 704: 300, 705: 94, 706: 141, 707: 42, 708: 35, 709: 8, 710: 398, 711: 542, 712: 467, 713: 218, 714: 372, 715: 306, 716: 248, 717: 442, 718: 185, 719: 179, 720: 377, 721: 228, 722: 281, 723: 376, 724: 237, 725: 194, 726: 354, 727: 201, 728: 192, 729: 42, 730: 404, 731: 474, 732: 509, 733: 266, 734: 254, 735: 419, 736: 208, 737: 514, 738: 268, 739: 237, 740: 310, 741: 297, 742: 153, 743: 83, 744: 286, 745: 95, 746: 199, 747: 318, 748: 426, 749: 126, 750: 75, 751: 261, 752: 288, 753: 251, 754: 102, 755: 245, 756: 81, 757: 301, 758: 308, 759: 91, 760: 68, 761: 360, 762: 57, 763: 555, 764: 256, 765: 154, 766: 108, 767: 68, 768: 130, 769: 94, 770: 268, 771: 105, 772: 114, 773: 271, 774: 190, 775: 167, 776: 257, 777: 87, 778: 85, 779: 227, 780: 259, 781: 189, 782: 232, 783: 429, 784: 207, 785: 207, 786: 204, 787: 231, 788: 321, 789: 22, 790: 223, 791: 71, 792: 99, 793: 364, 794: 350, 795: 214, 796: 116, 797: 1, 798: 549, 799: 210, 800: 298, 801: 22, 802: 10, 803: 163, 804: 420, 805: 354, 806: 99, 807: 152, 808: 352, 809: 250, 810: 354, 811: 142, 812: 28, 813: 179, 814: 195, 815: 263, 816: 165, 817: 267, 818: 188, 819: 265, 820: 486, 821: 9, 822: 0, 823: 383, 824: 180, 825: 195, 826: 234, 827: 119, 828: 171, 829: 188, 830: 139, 831: 222, 832: 213, 833: 292, 834: 163, 835: 49, 836: 249, 837: 434, 838: 264, 839: 121, 840: 493, 841: 340, 842: 224, 843: 140, 844: 225, 845: 159, 846: 114, 847: 128, 848: 122, 849: 206, 850: 0, 851: 59, 852: 80, 853: 191, 854: 220, 855: 102, 856: 175, 857: 156, 858: 274, 859: 287}, 'args_vision': Namespace(), 'added_dim': 64, 'out_dim': 64}}\n",
      "ray: False\n",
      "ray_scheduler: ASHA\n",
      "ray_search_alg: HyperOpt\n",
      "grace_period: 2\n",
      "HP_max_epochs: 100\n",
      "alpha: None\n",
      "data_augmentation: False\n",
      "H: 6\n",
      "W: 0\n",
      "D: 1\n",
      "step_ahead: 1\n",
      "horizon_step: 1\n",
      "L: 7\n",
      "shuffle: True\n",
      "train_prop: 0.6\n",
      "calib_prop: None\n",
      "valid_prop: 0.2\n",
      "test_prop: 0.19999999999999996\n",
      "track_pi: False\n",
      "track_grad_norm: True\n",
      "validation_split_method: forward_chaining_cv\n",
      "min_fold_size_proportion: 0.75\n",
      "no_common_dates_between_set: False\n",
      "K_fold: 2\n",
      "current_fold: 0\n",
      "metrics: ['rmse', 'mse', 'mae', 'mape', 'mase']\n",
      "abs_path: /home/rrochas/\n",
      "out_dim_factor: 1\n",
      "temporal_graph_transformer_encoder: False\n",
      "Kt: 2\n",
      "stblock_num: 4\n",
      "Ks: 2\n",
      "graph_conv_type: graph_conv\n",
      "gso_type: sym_renorm_adj\n",
      "enable_bias: True\n",
      "adj_type: corr\n",
      "enable_padding: True\n",
      "threshold: 0.3\n",
      "act_func: glu\n",
      "temporal_h_dim: 64\n",
      "spatial_h_dim: 256\n",
      "output_h_dim: 64\n",
      "weight_decay: 0.0006214716516792\n",
      "batch_size: 128\n",
      "lr: 0.0002481832349353\n",
      "dropout: 0.145169206052754\n",
      "epochs: 1000\n",
      "scheduler: None\n",
      "args_embedding: Namespace(embedding_dim=64, multi_embedding=True, specific_lr=False, concatenation_late=True, concatenation_early=False, out_h_dim=64, variable_selection_model_name='MLP', embedding_dim_calendar_units=[3, 5], dic_sizes=[7, 18], device=device(type='cuda'))\n",
      "target_data: subway_in\n",
      "use_target_as_context: False\n",
      "unormalize_loss: True\n",
      "torch_scheduler: None\n",
      "TE_embedding_dim: 64\n",
      "TE_out_h_dim: 64\n",
      "TE_concatenation_late: True\n",
      "TE_concatenation_early: False\n",
      "TE_multi_embedding: True\n",
      "TE_specific_lr: False\n",
      "TE_variable_selection_model_name: MLP\n",
      "TE_embedding_dim_calendar_units: [3, 5]\n",
      "need_global_attn: False\n",
      "out_dim: 1\n",
      "num_nodes: 40\n",
      "C: 1\n",
      "contextual_dataset_names: ['netmob_POIs']\n",
      "n_units_netmob_POIs: 556\n",
      "input_dim_netmob_POIs: 7\n",
      "ds_which_need_spatial_attn_per_station: []\n",
      "dict_pos_node_attr2ds: {2: 'netmob_POIs'}\n",
      "ds_which_need_global_attn: ['netmob_POIs']\n",
      "ds_which_need_global_attn_late: []\n",
      "number of Parameters in Embedding Module: 167087\n",
      "Model size: 0.004GB\n"
     ]
    }
   ],
   "source": [
    "from examples.train_model import load_init_model_trainer_ds\n",
    "from examples.benchmark import local_get_args\n",
    "from examples.reproductibility.config_STGCN_Subway_in_NetMob_calendar_h1 import modifications\n",
    "\n",
    "modification = modifications['HPO_subway_in_calendar_embedding_netmob_POIs_STGCN_HuberLossLoss_2025_08_11_23_22_40073_h1']\n",
    "save_folder = None\n",
    "\n",
    "args_init = local_get_args(modification['model_name'],\n",
    "                args_init = None,\n",
    "                dataset_names=modification['dataset_names'],\n",
    "                dataset_for_coverage=modification['dataset_for_coverage'],\n",
    "                modification = modification)\n",
    "fold_to_evaluate=[args_init.K_fold-1]\n",
    "\n",
    "trainer,ds,model,args = load_init_model_trainer_ds(fold_to_evaluate,save_folder,args_init,modification,trial_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Transferring all possible weights ---\n",
      "62 layers have been frozen.\n",
      "\n",
      "--- Transfer Summary ---\n",
      "Kept 41 layers to train.\n",
      "Found 1 layers with mismatched shapes (weights not transferred):\n",
      "  - core_model.output.fc1.weight: Dest: torch.Size([64, 192]) vs Source: torch.Size([64, 128])\n",
      "------------------------\n",
      "\n",
      "Model structure after transfer:\n",
      "\n",
      "- Blue:  All parameters in the module were transferred AND are frozen\n",
      " - Green:  All parameters in the module were transferred AND are NOT frozen\n",
      " - Yellow: Some, but not all, parameters were transferred\n",
      " - White: No parameters were transferred\n",
      "\n",
      "(spatial_attn_per_station): ModuleDict()\n",
      "(spatial_attn_poi): ModuleDict(\n",
      "spatial_attn_poi.(netmob_POIs): model(\n",
      "spatial_attn_poi.netmob_POIs.(mha_list): ModuleList(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.(0): MHA_layer(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.(mha): MultiHeadAttention(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.mha.(softmax): Softmax(dim=-1)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.mha.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.mha.(layer_normq): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.mha.(layer_normkv): LayerNorm((7,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.mha.(res_proj): Linear(in_features=7, out_features=64, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.(feedforward): Sequential(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.feedforward.(0): Linear(in_features=64, out_features=128, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.feedforward.(1): Mish()\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.feedforward.(2): Linear(in_features=128, out_features=64, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.(layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.0.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.(1): MHA_layer(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.(mha): MultiHeadAttention(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.mha.(softmax): Softmax(dim=-1)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.mha.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.mha.(layer_normq): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.mha.(layer_normkv): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.(feedforward): Sequential(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.feedforward.(0): Linear(in_features=64, out_features=128, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.feedforward.(1): Mish()\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.feedforward.(2): Linear(in_features=128, out_features=64, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.(layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.1.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.(2): MHA_layer(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.(mha): MultiHeadAttention(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.mha.(softmax): Softmax(dim=-1)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.mha.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.mha.(layer_normq): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.mha.(layer_normkv): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.(feedforward): Sequential(\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.feedforward.(0): Linear(in_features=64, out_features=128, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.feedforward.(1): Mish()\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.feedforward.(2): Linear(in_features=128, out_features=64, bias=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.(layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "spatial_attn_poi.netmob_POIs.mha_list.2.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "\u001b[94m(te): TE_module(\u001b[0m\n",
      "\u001b[94mte.(Tembedding): TimeEmbedding(\u001b[0m\n",
      "\u001b[94mte.Tembedding.(embedding): ModuleList(\u001b[0m\n",
      "\u001b[94mte.Tembedding.embedding.(0): Embedding(7, 3)\u001b[0m\n",
      "\u001b[94mte.Tembedding.embedding.(1): Embedding(18, 5)\u001b[0m\n",
      "\u001b[94mte.Tembedding.(output_module): OutputModule(\u001b[0m\n",
      "\u001b[94mte.Tembedding.output_module.(module): MLP_embedding(\u001b[0m\n",
      "\u001b[94mte.Tembedding.output_module.module.(output1): Linear(in_features=8, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[94mte.Tembedding.output_module.module.(output2): Linear(in_features=64, out_features=2560, bias=True)\u001b[0m\n",
      "te.Tembedding.output_module.module.(relu): ReLU()\n",
      "te.Tembedding.output_module.module.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "\u001b[93m(core_model): STGCN(\u001b[0m\n",
      "\u001b[94mcore_model.(st_blocks): Sequential(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.(0): STConvBlock(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.(tmp_conv1): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv1.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv1.align.(align_conv): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv1.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv1.causal_conv.(conv2d): Conv2d(1, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.0.tmp_conv1.(relu): ReLU()\n",
      "core_model.st_blocks.0.tmp_conv1.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.0.(graph_conv): GraphConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.graph_conv.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.graph_conv.align.(align_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.graph_conv.(graph_conv): GraphConv()\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.(tmp_conv2): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv2.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv2.align.(align_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv2.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.0.tmp_conv2.causal_conv.(conv2d): Conv2d(256, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.0.tmp_conv2.(relu): ReLU()\n",
      "core_model.st_blocks.0.tmp_conv2.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.0.(tc2_ln): LayerNorm((40, 64), eps=1e-05, elementwise_affine=True)\u001b[0m\n",
      "core_model.st_blocks.0.(relu): ReLU()\n",
      "core_model.st_blocks.0.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "\u001b[94mcore_model.st_blocks.(1): STConvBlock(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.(tmp_conv1): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv1.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv1.align.(align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv1.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv1.causal_conv.(conv2d): Conv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.1.tmp_conv1.(relu): ReLU()\n",
      "core_model.st_blocks.1.tmp_conv1.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.1.(graph_conv): GraphConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.graph_conv.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.graph_conv.align.(align_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.graph_conv.(graph_conv): GraphConv()\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.(tmp_conv2): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv2.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv2.align.(align_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv2.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.1.tmp_conv2.causal_conv.(conv2d): Conv2d(256, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.1.tmp_conv2.(relu): ReLU()\n",
      "core_model.st_blocks.1.tmp_conv2.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.1.(tc2_ln): LayerNorm((40, 64), eps=1e-05, elementwise_affine=True)\u001b[0m\n",
      "core_model.st_blocks.1.(relu): ReLU()\n",
      "core_model.st_blocks.1.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "\u001b[94mcore_model.st_blocks.(2): STConvBlock(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.(tmp_conv1): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv1.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv1.align.(align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv1.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv1.causal_conv.(conv2d): Conv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.2.tmp_conv1.(relu): ReLU()\n",
      "core_model.st_blocks.2.tmp_conv1.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.2.(graph_conv): GraphConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.graph_conv.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.graph_conv.align.(align_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.graph_conv.(graph_conv): GraphConv()\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.(tmp_conv2): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv2.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv2.align.(align_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv2.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.2.tmp_conv2.causal_conv.(conv2d): Conv2d(256, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.2.tmp_conv2.(relu): ReLU()\n",
      "core_model.st_blocks.2.tmp_conv2.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.2.(tc2_ln): LayerNorm((40, 64), eps=1e-05, elementwise_affine=True)\u001b[0m\n",
      "core_model.st_blocks.2.(relu): ReLU()\n",
      "core_model.st_blocks.2.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "\u001b[94mcore_model.st_blocks.(3): STConvBlock(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.(tmp_conv1): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv1.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv1.align.(align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv1.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv1.causal_conv.(conv2d): Conv2d(64, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.3.tmp_conv1.(relu): ReLU()\n",
      "core_model.st_blocks.3.tmp_conv1.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.3.(graph_conv): GraphConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.graph_conv.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.graph_conv.align.(align_conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.graph_conv.(graph_conv): GraphConv()\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.(tmp_conv2): TemporalConvLayer(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv2.(align): Align(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv2.align.(align_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv2.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[94mcore_model.st_blocks.3.tmp_conv2.causal_conv.(conv2d): Conv2d(256, 128, kernel_size=(2, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.st_blocks.3.tmp_conv2.(relu): ReLU()\n",
      "core_model.st_blocks.3.tmp_conv2.(silu): SiLU()\n",
      "\u001b[94mcore_model.st_blocks.3.(tc2_ln): LayerNorm((40, 64), eps=1e-05, elementwise_affine=True)\u001b[0m\n",
      "core_model.st_blocks.3.(relu): ReLU()\n",
      "core_model.st_blocks.3.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "\u001b[93mcore_model.(output): OutputBlock(\u001b[0m\n",
      "core_model.output.(temporal_agg): Identity()\n",
      "core_model.output.(ModuleContextualAttnLate): ModuleDict()\n",
      "\u001b[92mcore_model.output.(temporal_conv_out): TemporalConvLayer(\u001b[0m\n",
      "\u001b[92mcore_model.output.temporal_conv_out.(align): Align(\u001b[0m\n",
      "\u001b[92mcore_model.output.temporal_conv_out.align.(align_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\u001b[0m\n",
      "\u001b[92mcore_model.output.temporal_conv_out.(causal_conv): CausalConv2d(\u001b[0m\n",
      "\u001b[92mcore_model.output.temporal_conv_out.causal_conv.(conv2d): Conv2d(64, 128, kernel_size=(7, 1), stride=(1, 1))\u001b[0m\n",
      "core_model.output.temporal_conv_out.(relu): ReLU()\n",
      "core_model.output.temporal_conv_out.(silu): SiLU()\n",
      "\u001b[93mcore_model.output.(fc1): Linear(in_features=192, out_features=64, bias=True)\u001b[0m\n",
      "\u001b[92mcore_model.output.(fc2): Linear(in_features=64, out_features=1, bias=True)\u001b[0m\n",
      "\u001b[92mcore_model.output.(tc1_ln): LayerNorm((40, 64), eps=1e-05, elementwise_affine=True)\u001b[0m\n",
      "core_model.output.(relu): ReLU()\n",
      "core_model.output.(dropout): Dropout(p=0.145169206052754, inplace=False)\n",
      "core_model.(fc1): Identity()\n",
      "core_model.(fc2): Identity()\n",
      "core_model.(relu): ReLU()\n"
     ]
    }
   ],
   "source": [
    "# Option 1: Transférer tous les poids possibles et les geler\n",
    "print(\"--- Transferring all possible weights ---\")\n",
    "trainer.transfer_weights_from(trained_trainer, freeze_transferred=True, List_not_freezing = ['core_model.output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Transférer uniquement les modules 'te' et 'core_model' et les geler\n",
    "print(\"\\n\\n--- Transferring specific modules ('te' and 'core_model') ---\")\n",
    "modules_to_transfer = ['te', 'core_model']\n",
    "trainer.transfer_weights_from(\n",
    "    trained_trainer, \n",
    "    modules_to_transfer=modules_to_transfer, \n",
    "    freeze_transferred=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
