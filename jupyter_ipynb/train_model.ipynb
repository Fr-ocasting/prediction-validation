{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Hyper-parameter tuning with Ray is not possible\n",
      ">>>>Model: ASTGCN; K_fold = 6; Loss function: MSE \n",
      ">>>>Model: ASTGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "T_subway_out:  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "subway_ds.U_valid torch.Size([940, 40, 7])\n",
      "NetMob_ds.U_valid torch.Size([940, 40, 7])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 2821 940 940\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "T_subway_out:  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "subway_ds.U_valid torch.Size([941, 40, 7])\n",
      "NetMob_ds.U_valid torch.Size([941, 40, 7])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 1059 941 939\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "T_subway_out:  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "subway_ds.U_valid torch.Size([941, 40, 7])\n",
      "NetMob_ds.U_valid torch.Size([941, 40, 7])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 1059 941 939\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 52357\n",
      "number of trainable parameters: 52357\n",
      "\n",
      "start training\n",
      "\n",
      "x entry: \n",
      "nan in x:  tensor(False, device='cuda:0')\n",
      "\n",
      "x start block_i:\n",
      "nan in x:  tensor(False, device='cuda:0')\n",
      "nan in x after TAt:  tensor(True, device='cuda:0')\n",
      "nan in x after matmul reshape:  tensor(True, device='cuda:0')\n",
      "nan in x after SAt :  tensor(True, device='cuda:0')\n",
      "nan in x after cheb_conv_SAt :  tensor(True, device='cuda:0')\n",
      "nan in x after time_conv :  tensor(True, device='cuda:0')\n",
      "nan in x after residual_conv :  tensor(False, device='cuda:0')\n",
      "nan in x after ln(F(ReLU)) :  tensor(True, device='cuda:0')\n",
      "\n",
      "x start block_i:\n",
      "nan in x:  tensor(True, device='cuda:0')\n",
      "nan in x after TAt:  tensor(True, device='cuda:0')\n",
      "nan in x after matmul reshape:  tensor(True, device='cuda:0')\n",
      "nan in x after SAt :  tensor(True, device='cuda:0')\n",
      "nan in x after cheb_conv_SAt :  tensor(True, device='cuda:0')\n",
      "nan in x after time_conv :  tensor(True, device='cuda:0')\n",
      "nan in x after residual_conv :  tensor(True, device='cuda:0')\n",
      "nan in x after ln(F(ReLU)) :  tensor(True, device='cuda:0')\n",
      "\n",
      "x after blocks: \n",
      "nan in x:  tensor(True, device='cuda:0')\n",
      "\n",
      "x after final_conv: \n",
      "nan in x:  tensor(True, device='cuda:0')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'blabla' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 72\u001b[0m\n\u001b[1;32m     65\u001b[0m args \u001b[38;5;241m=\u001b[39m local_get_args(model_name,\n\u001b[1;32m     66\u001b[0m                     args_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     67\u001b[0m                     dataset_names\u001b[38;5;241m=\u001b[39mdataset_names,\n\u001b[1;32m     68\u001b[0m                     dataset_for_coverage\u001b[38;5;241m=\u001b[39mdataset_for_coverage,\n\u001b[1;32m     69\u001b[0m                     modification \u001b[38;5;241m=\u001b[39m modification)\n\u001b[1;32m     71\u001b[0m training_mode_to_visualise \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;66;03m# ['test','valid','train']\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m (trainer,ds,ds_no_shuffle,args) \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_init\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mstation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43mtraining_mode_to_visualise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_mode_to_visualise\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/prediction-validation/examples/train_and_visu_non_recurrent.py:54\u001b[0m, in \u001b[0;36mevaluate_config\u001b[0;34m(args_init, modification, fold_to_evaluate, training_mode_to_visualise, station, transfer_modes, type_POIs, spatial_units, apps, POI_or_stations, expanded, individual_poi, sum_ts_pois)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_config\u001b[39m(args_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     31\u001b[0m                     modification \u001b[38;5;241m=\u001b[39m {},\n\u001b[1;32m     32\u001b[0m                     fold_to_evaluate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     sum_ts_pois \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     43\u001b[0m                     ):\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    args: \u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03m    type_POIs : list of type of POIs.                         >>> ['stadium','nightclub']\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    expanded: '' if we look at the intensity of netmob consumption at the POI. '_expanded' if we look also one square around.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     trainer,ds,args,trial_id,df_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_the_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodification\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfold_to_evaluate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m     trainer,ds_no_shuffle \u001b[38;5;241m=\u001b[39m get_ds_without_shuffling_on_train_set(trainer,modification,args_init,fold_to_evaluate)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m training_mode \u001b[38;5;129;01min\u001b[39;00m training_mode_to_visualise:\n",
      "File \u001b[0;32m~/prediction-validation/examples/train_and_visu_non_recurrent.py:74\u001b[0m, in \u001b[0;36mtrain_the_config\u001b[0;34m(args_init, modification, fold_to_evaluate)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_the_config\u001b[39m(args_init,modification,fold_to_evaluate):\n\u001b[1;32m     73\u001b[0m     ds,args,trial_id,save_folder,df_loss \u001b[38;5;241m=\u001b[39m get_ds(modification\u001b[38;5;241m=\u001b[39mmodification,args_init\u001b[38;5;241m=\u001b[39margs_init,fold_to_evaluate\u001b[38;5;241m=\u001b[39mfold_to_evaluate)\n\u001b[0;32m---> 74\u001b[0m     trainer,df_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_ds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrial_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdf_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer,ds,args,trial_id,df_loss\n",
      "File \u001b[0;32m~/prediction-validation/examples/benchmark.py:70\u001b[0m, in \u001b[0;36mtrain_on_ds\u001b[0;34m(ds, args, trial_id, save_folder, df_loss)\u001b[0m\n\u001b[1;32m     68\u001b[0m optimizer,scheduler,loss_function \u001b[38;5;241m=\u001b[39m load_optimizer_and_scheduler(model,args)\n\u001b[1;32m     69\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(ds,model,args,optimizer,loss_function,scheduler \u001b[38;5;241m=\u001b[39m scheduler,show_figure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,trial_id \u001b[38;5;241m=\u001b[39m trial_id, fold\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,save_folder \u001b[38;5;241m=\u001b[39m save_folder)\n\u001b[0;32m---> 70\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmod_plot\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m     71\u001b[0m df_loss[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_train_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain_loss\n\u001b[1;32m     72\u001b[0m df_loss[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_valid_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mvalid_loss\n",
      "File \u001b[0;32m~/prediction-validation/trainer.py:236\u001b[0m, in \u001b[0;36mTrainer.train_and_valid\u001b[0;34m(self, normalizer, df_verif_test, mod, mod_plot, station)\u001b[0m\n\u001b[1;32m    234\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Train and Valid each epoch \u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_valid_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;66;03m# Save best model (only if it's not a ray tuning)\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_valid) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;129;01mnot\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mray)):\n",
      "File \u001b[0;32m~/prediction-validation/trainer.py:146\u001b[0m, in \u001b[0;36mTrainer.train_valid_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()   \u001b[38;5;66;03m#Activate Dropout \u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()   \u001b[38;5;66;03m# Desactivate Dropout \u001b[39;00m\n",
      "File \u001b[0;32m~/prediction-validation/trainer.py:424\u001b[0m, in \u001b[0;36mTrainer.loop_epoch\u001b[0;34m(self, track_loss)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_mode\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    423\u001b[0m     loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_loader()\n\u001b[0;32m--> 424\u001b[0m     Preds,Y_true,T_labels,nb_samples,loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_through_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_tracking()\n",
      "File \u001b[0;32m~/prediction-validation/trainer.py:397\u001b[0m, in \u001b[0;36mTrainer.loop_through_batches\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    394\u001b[0m     contextual_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    396\u001b[0m x_b,y_b,contextual_b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_to_device(x_b,y_b,contextual_b)\n\u001b[0;32m--> 397\u001b[0m pred,y_b,t_label,nb_samples,loss_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcontextual_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnb_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m Preds\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[1;32m    400\u001b[0m Y_true\u001b[38;5;241m.\u001b[39mappend(y_b)\n",
      "File \u001b[0;32m~/prediction-validation/trainer.py:354\u001b[0m, in \u001b[0;36mTrainer.loop_batch\u001b[0;34m(self, x_b, y_b, contextual_b, nb_samples, loss_epoch)\u001b[0m\n\u001b[1;32m    352\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x_b,contextual_b)\n\u001b[1;32m    353\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(pred\u001b[38;5;241m.\u001b[39mfloat(),y_b)\n\u001b[0;32m--> 354\u001b[0m     \u001b[43mblabla\u001b[49m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;66;03m#print('\\npred: ', pred.size(), 'y_b: ', y_b.size())\u001b[39;00m\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m#print('loss: ',loss)\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m#print('\\nloss: ',loss) \u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# Back propagation (after each mini-batch)\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \n",
      "\u001b[0;31mNameError\u001b[0m: name 'blabla' is not defined"
     ]
    }
   ],
   "source": [
    "# GET PARAMETERS\n",
    "import os \n",
    "import sys\n",
    "import torch \n",
    "# Get Parent folder : \n",
    "\n",
    "current_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from examples.train_and_visu_non_recurrent import evaluate_config\n",
    "from plotting.plotting import error_per_station_calendar_pattern  \n",
    "from examples.benchmark import local_get_args\n",
    "# Init:\n",
    "dataset_names = [\"subway_in\",\"subway_out\"] # ['subway_in','netmob_POIs_per_station'],[\"subway_in\",\"subway_out\"],[\"subway_in\",\"calendar\"] # [\"subway_in\"] # ['data_bidon'] # ['METR_LA'] # ['PEMS_BAY']\n",
    "dataset_for_coverage = ['subway_in','netmob_image_per_station'] #  ['data_bidon','netmob'] #  ['subway_in','netmob']  # ['METR_LA'] # ['PEMS_BAY']\n",
    "model_name = 'ASTGCN' # 'STGCN', 'ASTGCN'\n",
    "station = ['BEL','PAR','AMP','SAN','FLA']   # 'BON'  #'GER'\n",
    "# ...\n",
    "\n",
    "# Modif \n",
    "modification = {'epochs' : 1, #100\n",
    "                'lr':5e-5,# 4e-4,\n",
    "                'weight_decay':0.05,\n",
    "                'dropout':0.15,\n",
    "                #'set_spatial_units':  station,   \n",
    "                #  \n",
    "                'scheduler':None,\n",
    "                #'scheduler':True,\n",
    "                #'torch_scheduler_milestone': 5,\n",
    "                #'torch_scheduler_gamma':0.997,\n",
    "                #'torch_scheduler_lr_start_factor':1,\n",
    "\n",
    "                'temporal_graph_transformer_encoder': False,\n",
    "                #'TGE_num_layers' : 4, #2\n",
    "                #'TGE_num_heads' :  1, #IMPOSSIBLE > 1 CAR DOIT DIVISER L = 7\n",
    "                #'TGE_FC_hdim' :  32, #32\n",
    "\n",
    "                #'NetMob_only_epsilon': True,    # True # False\n",
    "                #'NetMob_selected_apps': ['Apple_iMessage','Web_Ads'],# ['Apple_iMessage','Web_Ads'], #,'Deezer','WhatsApp','Twitter'] #['Google_Maps']# ['Instagram','Google_Maps','Twitter']\n",
    "                #'NetMob_transfer_mode' :  ['DL'], #,'UL'] # ['DL'] # ['UL'] #['DL','UL']\n",
    "                #'NetMob_selected_tags' : ['station_epsilon100'],#['iris','stadium','station','university']#['park','stadium','university','station','shop','nightclub','parkings','theatre','iris','transit','public_transport']\n",
    "                #'NetMob_expanded' : '', # '' # '_expanded'\n",
    "                'stacked_contextual': True, # True # False\n",
    "\n",
    "                'learnable_adj_matrix' : True,\n",
    "                'graph_conv_type': 'graph_conv', # 'cheb_graph_conv', 'graph_conv'\n",
    "                'learnable_adj_top_k': 10,\n",
    "                'learnable_adj_embd_dim': 16, \n",
    "                \n",
    "                #'vision_num_heads':6,\n",
    "                #\"vision_grn_out_dim\":48,\n",
    "                #'vision_model_name': 'VariableSelectionNetwork',\n",
    "                #'vision_concatenation_early':True,   \n",
    "                #'vision_concatenation_late':True,\n",
    "\n",
    "                'compute_node_attr_with_attn' : False, # True ??\n",
    "                #'adj_type':'corr'\n",
    "                           }\n",
    "# ...\n",
    "#1038945\n",
    "\n",
    "# Training and visu: \n",
    "args = local_get_args(model_name,\n",
    "                    args_init = None,\n",
    "                    dataset_names=dataset_names,\n",
    "                    dataset_for_coverage=dataset_for_coverage,\n",
    "                    modification = modification)\n",
    "\n",
    "training_mode_to_visualise = ['test'] # ['test','valid','train']\n",
    "(trainer,ds,ds_no_shuffle,args) = evaluate_config(args_init = args,\n",
    "                                                   station=station,modification=modification,\n",
    "                                                   training_mode_to_visualise=training_mode_to_visualise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigs\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "L = (pd.DataFrame(np.random.rand(10,10))*10)\n",
    "\n",
    "\n",
    "lambda_max = eigs(L.values , k=1, which='LR')[0].real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'match_period_coverage_with_netmob' from 'utils.utilities_DL' (/home/rrochas/prediction-validation/utils/utilities_DL.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, working_dir)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Personnal import \u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutilities_DL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m match_period_coverage_with_netmob\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_args,update_modif\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconstants\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpaths\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FOLDER_PATH,FILE_NAME,SAVE_DIRECTORY\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'match_period_coverage_with_netmob' from 'utils.utilities_DL' (/home/rrochas/prediction-validation/utils/utilities_DL.py)"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtenir le chemin du dossier parent\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "# current_path = os.path.dirname()\n",
    "working_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "\n",
    "# Ajouter le dossier parent au chemin de recherche des modules\n",
    "if working_dir not in sys.path:\n",
    "    sys.path.insert(0, working_dir)\n",
    "\n",
    "# Personnal import \n",
    "from utils.utilities_DL import match_period_coverage_with_netmob\n",
    "from constants.config import get_args,update_modif\n",
    "from constants.paths import FOLDER_PATH,FILE_NAME,SAVE_DIRECTORY\n",
    "from K_fold_validation.K_fold_validation import KFoldSplitter\n",
    "from trainer import Trainer\n",
    "from high_level_DL_method import load_model,load_optimizer_and_scheduler\n",
    "from plotting.plotting_bokeh import plot_bokeh\n",
    "\n",
    "\n",
    "# Load config\n",
    "model_name = 'STGCN' #'CNN'\n",
    "dataset_names = ['subway_in','netmob']\n",
    "args = get_args(model_name,dataset_names)\n",
    "\n",
    "# Modification : \n",
    "args.K_fold = 5\n",
    "\n",
    "args.ray = False\n",
    "args.W = 0  # IMPORTANT AVEC NETMOB\n",
    "\n",
    "args.epochs = 100\n",
    "args.loss_function_type = 'MSE' # 'quantile'\n",
    "\n",
    "# optimization:\n",
    "args.mixed_precision = True\n",
    "\n",
    "args = update_modif(args)\n",
    "\n",
    "# Coverage Period : \n",
    "small_ds = False\n",
    "coverage = match_period_coverage_with_netmob(FILE_NAME,dataset_names=['subway_in','netmob'])\n",
    "\n",
    "# Choose DataSet and VisionModel if needed: \n",
    "dataset_names = ['netmob','subway_in'] # ['calendar','netmob'] #['subway_in','netmob','calendar']\n",
    "vision_model_name = 'FeatureExtractor_ResNetInspired'  # 'ImageAvgPooling'  #'FeatureExtractor_ResNetInspired' #'MinimalFeatureExtractor',\n",
    "\n",
    "# Train and Evaluate Model: \n",
    "mod_plot = 1 # bokeh plotting every epoch \n",
    "\n",
    "# Load K-fold subway-ds \n",
    "folds = [0] # Here we use the first fold for HP-tuning. \n",
    "\n",
    "# In case we need to compute the Sliding K-fold validation:\n",
    "# folds = np.arange(1,args.K_fold)\n",
    "\n",
    "K_fold_splitter = KFoldSplitter(args,folds)\n",
    "K_subway_ds,args = K_fold_splitter.split_k_fold()\n",
    "subway_ds = K_subway_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model, trainer, and train it:\n",
    "model = load_model(args,dic_class2rpz)\n",
    "optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model,args)\n",
    "trainer = Trainer(subway_ds,model,args,optimizer,loss_function,scheduler = scheduler,dic_class2rpz = dic_class2rpz,show_figure = True)# Ajoute dans trainer, if calibration_prop is not None .... et on modifie le dataloader en ajoutant un clabration set\n",
    "trainer.train_and_valid(mod = 1000,mod_plot = None)  # Récupère les conformity scores sur I1, avec les estimations faites precedemment \n",
    "\n",
    "# Plotting: \n",
    "pi,pi_cqr = plot_bokeh(trainer,subway_ds.normalizer,subway_ds.tensor_limits_keeper.df_verif_test,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model, trainer, and train it:\n",
    "model = load_model(args,dic_class2rpz)\n",
    "optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model,args)\n",
    "trainer = Trainer(subway_ds,model,args,optimizer,loss_function,scheduler = scheduler,dic_class2rpz = dic_class2rpz,show_figure = True)# Ajoute dans trainer, if calibration_prop is not None .... et on modifie le dataloader en ajoutant un clabration set\n",
    "trainer.train_and_valid(mod = 1000,mod_plot = None)  # Récupère les conformity scores sur I1, avec les estimations faites precedemment \n",
    "\n",
    "# Plotting: \n",
    "pi,pi_cqr = plot_bokeh(trainer,subway_ds.normalizer,subway_ds.tensor_limits_keeper.df_verif_test,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init tensor:  tensor([2.2318e+09])\n",
      "Init feature vect:  tensor([7.0868e+09])\n",
      "\n",
      "block1:\n",
      "s_conv:  tensor(3.0692e+08) tconv:  tensor(1.2277e+09)\n",
      "\n",
      "block2:\n",
      "s_conv:  tensor(1.5548e+09) tconv:  tensor(1.2098e+09)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "netmob_init = torch.Tensor([7392*4*263*287])\n",
    "netmob_tensor = torch.Tensor([2934*4*263*287*8])\n",
    "\n",
    "print('Init tensor: ',netmob_init)\n",
    "print('Init feature vect: ',netmob_tensor)\n",
    "\n",
    "print('\\nblock1:')\n",
    "sconv = torch.prod(torch.Tensor([64, 32, 131, 143, 8]))\n",
    "tconv = torch.prod(torch.Tensor([64, 128, 131, 143, 8]))\n",
    "print('s_conv: ',sconv, 'tconv: ',tconv)\n",
    "\n",
    "print('\\nblock2:')\n",
    "sconv = torch.prod(torch.Tensor([64, 658, 65, 71, 8]))\n",
    "tconv = torch.prod(torch.Tensor([64, 512, 65, 71, 8]))\n",
    "print('s_conv: ',sconv, 'tconv: ',tconv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
