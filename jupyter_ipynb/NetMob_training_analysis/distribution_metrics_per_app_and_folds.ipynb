{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "working_dir = os.path.abspath(os.path.join(current_path, '..','..'))\n",
    "if working_dir not in sys.path:\n",
    "    sys.path.insert(0, working_dir)\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from argparse import Namespace\n",
    "import re \n",
    "L_Apps = ['Apple_Video','Google_Play_Store','Google_Maps','Web_Clothes','Uber', 'Twitter',\n",
    "        'Microsoft_Mail', 'Microsoft_Store', 'Apple_Music', 'Microsoft_Office', 'Pokemon_GO', 'Clash_of_Clans', 'Yahoo_Mail', 'PlayStation',\n",
    "        'Wikipedia', 'Apple_Web_Services', 'Pinterest', 'Web_Ads', 'Google_Mail', 'Google_Meet',\n",
    "        'Apple_Siri', 'Web_Adult', 'Spotify', 'Deezer', 'Waze', 'Web_Games', 'Apple_App_Store', 'Microsoft_Skydrive', 'Google_Docs', 'Microsoft_Web_Services',\n",
    "        'Molotov', 'YouTube', 'Apple_iTunes', 'Apple_iMessage', 'DailyMotion', 'Netflix', 'Web_Transportation',\n",
    "        'Web_Downloads', 'SoundCloud', 'TeamViewer', 'Google_Web_Services', 'Facebook', 'EA_Games', 'Tor', 'Amazon_Web_Services',\n",
    "        'Web_e-Commerce', 'Telegram', 'Apple_Mail','Dropbox', 'Web_Food', 'Apple_iCloud', 'Skype', 'Facebook_Messenger', 'Twitch', 'Microsoft_Azure',\n",
    "        'Instagram', 'Facebook_Live', 'Web_Streaming', 'Orange_TV', 'Periscope', 'Snapchat' ,'Web_Finance' ,'WhatsApp', 'Web_Weather','Google_Drive','LinkedIn','Yahoo','Fortnite']\n",
    "\n",
    "\n",
    "def get_df_results(trial_id,model_args,L_Apps,split_key = 'eps100_'):\n",
    "    df = pd.DataFrame(columns = ['mse','mae','mape','fold','id','trial_num'])\n",
    "    for app in L_Apps:\n",
    "        best_model_names = [name for name in model_args['model'].keys() if (f\"{trial_id}_{app}_f\" in name) or (f\"{trial_id}_{app}_1_f\" in name) or (f\"{trial_id}_{app}_2_f\" in name)]\n",
    "\n",
    "        if len(best_model_names)>5:\n",
    "            print(best_model_names)\n",
    "            best_model_names = best_model_names[:5]\n",
    "\n",
    "        for k,selected_model_name in enumerate(best_model_names):\n",
    "            model_metrics = model_args['model'][selected_model_name]['performance']['test_metrics']\n",
    "            app_num = best_model_names[0].split(split_key)[-1].split('_f')[0]\n",
    "            if (not '_1' in app_num ) and (not '_2' in app_num):\n",
    "                app_num = app_num+ '_1'\n",
    "            name_id = '_'.join(app_num.split('_')[:-1])\n",
    "            trial_num = app_num.split('_')[-1]\n",
    "\n",
    "            df.loc[len(df)] = [model_metrics['mse'],model_metrics['mae'],model_metrics['mape'],k,name_id,trial_num]\n",
    "    return df \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_f0', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_f1', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_f2', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_f3', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_fcomplete_dataset', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_2_f0', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_2_f1', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_2_f2', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_2_f3', 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100_Apple_Video_2_fcomplete_dataset']\n"
     ]
    }
   ],
   "source": [
    "folder_name = 're_validation_epsilon100'\n",
    "save_path = f'save/K_fold_validation/training_with_HP_tuning/{folder_name}/best_models'\n",
    "model_args = pickle.load(open(f'{current_path}/{save_path}/model_args.pkl','rb'))\n",
    "trial_id = 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100'\n",
    "\n",
    "df1 = get_df_results(trial_id,model_args,L_Apps)\n",
    "\n",
    "folder_name = 're_validation'\n",
    "save_path = f'save/K_fold_validation/training_with_HP_tuning/{folder_name}/best_models'\n",
    "model_args = pickle.load(open(f'{current_path}/{save_path}/model_args.pkl','rb'))\n",
    "trial_id = 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100'\n",
    "\n",
    "df2 = get_df_results(trial_id,model_args,L_Apps)\n",
    "df = pd.concat([df1,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>fold</th>\n",
       "      <th>id</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1365.452881</td>\n",
       "      <td>21.565752</td>\n",
       "      <td>43.349380</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329.773315</td>\n",
       "      <td>21.960958</td>\n",
       "      <td>36.967972</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1264.973877</td>\n",
       "      <td>20.838892</td>\n",
       "      <td>30.041185</td>\n",
       "      <td>2</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1233.327148</td>\n",
       "      <td>20.747341</td>\n",
       "      <td>29.113092</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1296.285156</td>\n",
       "      <td>20.662750</td>\n",
       "      <td>28.951359</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mse        mae       mape  fold           id trial_num\n",
       "0  1365.452881  21.565752  43.349380     0  Apple_Video         2\n",
       "1  1329.773315  21.960958  36.967972     1  Apple_Video         2\n",
       "2  1264.973877  20.838892  30.041185     2  Apple_Video         2\n",
       "3  1233.327148  20.747341  29.113092     3  Apple_Video         2\n",
       "4  1296.285156  20.662750  28.951359     4  Apple_Video         2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"ff36d324-d07f-4101-9f23-052ba721d5fc\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"ff36d324-d07f-4101-9f23-052ba721d5fc\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"ff36d324-d07f-4101-9f23-052ba721d5fc\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"fbb1cfd8-1e18-4088-b8ae-a838c0e42121\" data-root-id=\"p3312\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"dee7de09-f0f1-41ad-9c00-ce21706482cc\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p3312\",\"attributes\":{\"width\":1200,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p3322\",\"attributes\":{\"factors\":[\"Web_Weather\",\"Microsoft_Web_Services\",\"Web_Downloads\",\"Web_Games\",\"Apple_iCloud\",\"Apple_Music\",\"Microsoft_Store\",\"Apple_iMessage\",\"Microsoft_Azure\",\"Fortnite\",\"Orange_TV\",\"Apple_Video\",\"Twitch\",\"Periscope\",\"PlayStation\",\"Amazon_Web_Services\",\"Google_Play_Store\",\"Skype\",\"Web_Adult\",\"Google_Docs\",\"Wikipedia\",\"SoundCloud\",\"Waze\",\"Yahoo_Mail\",\"Tor\",\"Microsoft_Skydrive\",\"Apple_Mail\",\"Google_Mail\",\"Web_Clothes\",\"Microsoft_Office\",\"EA_Games\",\"Pokemon_GO\",\"Apple_Web_Services\",\"Google_Meet\",\"Telegram\",\"Dropbox\",\"Uber\",\"Yahoo\",\"DailyMotion\",\"Web_Streaming\",\"Web_Transportation\",\"LinkedIn\",\"Deezer\",\"Pinterest\",\"Spotify\",\"Facebook_Messenger\",\"Google_Drive\",\"Web_Finance\",\"Google_Web_Services\",\"Web_Food\",\"Apple_App_Store\",\"Netflix\",\"Apple_Siri\",\"Clash_of_Clans\",\"Molotov\",\"WhatsApp\",\"Web_e-Commerce\",\"Microsoft_Mail\",\"YouTube\",\"Apple_iTunes\",\"Web_Ads\",\"TeamViewer\",\"Twitter\",\"Instagram\",\"Google_Maps\",\"Facebook\",\"Facebook_Live\",\"Snapchat\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p3314\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p3323\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p3324\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p3315\",\"attributes\":{\"text\":\"mase distribution per app and per folds\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3352\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p3306\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p3307\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p3308\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAAAAyAAAAMwAAADQAAAA1AAAANgAAADcAAAA4AAAAOQAAADoAAAA7AAAAPAAAAD0AAAA+AAAAPwAAAEAAAABBAAAAQgAAAEMAAAA=\"},\"shape\":[68],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Amazon_Web_Services\",\"Apple_App_Store\",\"Apple_Mail\",\"Apple_Music\",\"Apple_Siri\",\"Apple_Video\",\"Apple_Web_Services\",\"Apple_iCloud\",\"Apple_iMessage\",\"Apple_iTunes\",\"Clash_of_Clans\",\"DailyMotion\",\"Deezer\",\"Dropbox\",\"EA_Games\",\"Facebook\",\"Facebook_Live\",\"Facebook_Messenger\",\"Fortnite\",\"Google_Docs\",\"Google_Drive\",\"Google_Mail\",\"Google_Maps\",\"Google_Meet\",\"Google_Play_Store\",\"Google_Web_Services\",\"Instagram\",\"LinkedIn\",\"Microsoft_Azure\",\"Microsoft_Mail\",\"Microsoft_Office\",\"Microsoft_Skydrive\",\"Microsoft_Store\",\"Microsoft_Web_Services\",\"Molotov\",\"Netflix\",\"Orange_TV\",\"Periscope\",\"Pinterest\",\"PlayStation\",\"Pokemon_GO\",\"Skype\",\"Snapchat\",\"SoundCloud\",\"Spotify\",\"TeamViewer\",\"Telegram\",\"Tor\",\"Twitch\",\"Twitter\",\"Uber\",\"Waze\",\"Web_Ads\",\"Web_Adult\",\"Web_Clothes\",\"Web_Downloads\",\"Web_Finance\",\"Web_Food\",\"Web_Games\",\"Web_Streaming\",\"Web_Transportation\",\"Web_Weather\",\"Web_e-Commerce\",\"WhatsApp\",\"Wikipedia\",\"Yahoo\",\"Yahoo_Mail\",\"YouTube\"],\"shape\":[68],\"dtype\":\"object\",\"order\":\"little\"}],[\"min_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAYLUU5D8AAACALYHkPwAAAEDKhuQ/AAAAIGJn5D8AAABAN5PkPwAAAODqnOQ/AAAAgNmJ5D8AAAAA/znkPwAAAMBqguQ/AAAAoHU85D8AAABAZnTkPwAAAAB9QeQ/AAAAgEk35D8AAAAAEYTkPwAAAOAkIuQ/AAAAQN2t5D8AAAAAV57kPwAAAODXMeQ/AAAAQNFH5D8AAADgLXLkPwAAAIBofeQ/AAAAgLA/5D8AAAAgKrXkPwAAAEAtSOQ/AAAAQBA25D8AAACgJFXkPwAAAEDrvOQ/AAAAoDeH5D8AAABAGQnkPwAAAMCAC+U/AAAAYBM65D8AAADATQ/kPwAAACCBBeQ/AAAAoE0M5D8AAADAVG7kPwAAACBJQ+Q/AAAAQFg05D8AAADA5e3jPwAAAGCCGOQ/AAAAQLsz5D8AAACgY+TjPwAAAOAlTOQ/AAAAAKtH5j8AAADA2nnkPwAAACBO7+M/AAAAAC2w5D8AAACAqHbkPwAAAAClheQ/AAAA4G0B5D8AAABAOI3kPwAAAMCeruQ/AAAAgHQS5D8AAACAsErkPwAAAACNQeQ/AAAA4GER5D8AAABA/RPkPwAAAMDNweQ/AAAAYKIZ5D8AAAAgrYPkPwAAAOACN+Q/AAAAgBBg5D8AAADAiULkPwAAAABtK+Q/AAAAICh05D8AAADAyT3kPwAAAIDmP+Q/AAAAQE9W5D8AAACgZb3kPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q1\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAC1z5D8AAABYnPnkPwAAADC9seQ/AAAA+PvH5D8AAAB4UvjkPwAAAOjBwOQ/AAAAAKPF5D8AAABwzqXkPwAAANDOCuU/AAAA0JjP5D8AAAA45crkPwAAALC7BuU/AAAACCr35D8AAACIT/TkPwAAAMgBwuQ/AAAA4CaB5T8AAACwJjvlPwAAANgH0+Q/AAAAaLC35D8AAAAAkxnlPwAAAAAl6+Q/AAAAuEul5D8AAAAovEXlPwAAANg9guQ/AAAA6GGk5D8AAAAYH7zkPwAAAMgGIeU/AAAAyFGy5D8AAABQEgvlPwAAABgpPOU/AAAAUEzA5D8AAACIS5fkPwAAACjDweQ/AAAA2BmS5D8AAACgJJvkPwAAAHDeIOU/AAAAaAzW5D8AAAAYGavkPwAAAPgtkOQ/AAAAEN/G5D8AAADgVvbkPwAAAJCAl+Q/AAAA4Bxe5j8AAAAosZXkPwAAALBQveQ/AAAAUGhk5T8AAABQ897kPwAAAOAOw+Q/AAAAyAut5D8AAABY3OzkPwAAAFhUF+U/AAAA4Lmy5D8AAACwGerkPwAAABB5hOQ/AAAAoLXX5D8AAACQAaTkPwAAAFgK3+Q/AAAAqFbm5D8AAABIgqfkPwAAAKj5yeQ/AAAAcEiP5D8AAAA4RXvkPwAAAIh3CeU/AAAAOC+05D8AAAA4QbvkPwAAAJi+0uQ/AAAAcPTP5D8AAABAmODkPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"median_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAwB915T8AAADgajflPwAAAJD7VOU/AAAAcEuH5T8AAAAwodflPwAAAOCNIuU/AAAAUDgd5T8AAAAAtfrkPwAAAKAmWeU/AAAAADQW5z8AAABwDyTmPwAAAHAZS+U/AAAA8F195T8AAABANWzlPwAAAMDsUOU/AAAAACKY5z8AAACwtCnmPwAAAABa3eU/AAAAUI6Q5T8AAABgZjflPwAAANCgceU/AAAAsDtZ5T8AAACw+a3lPwAAABAvS+U/AAAAIJJA5T8AAABQzeblPwAAAKAg7uU/AAAAgLRm5T8AAADwQDzlPwAAADBEhuU/AAAAIF4q5T8AAACgPFXlPwAAADCYUuU/AAAAQPz55D8AAACwO1PlPwAAABBiUuU/AAAAoFiZ5T8AAADwAZnlPwAAAPCXBuU/AAAAEOJp5T8AAADA6iPlPwAAAJBNE+U/AAAAcB3x5j8AAABACjjlPwAAABB1LuU/AAAA8Gih5j8AAABQHXflPwAAADAQT+U/AAAAkK5d5T8AAACw+PPlPwAAABBa1+U/AAAA8PEw5T8AAABQt3rlPwAAADB3BeU/AAAAsMIl5T8AAADgLi/lPwAAAMDyj+U/AAAAcI4v5T8AAADwc0jlPwAAAJDFReU/AAAAEELf5D8AAACw4gLlPwAAAOCcyeU/AAAAoAxY5T8AAABwdj3lPwAAAFDvDeU/AAAAAAZJ5T8AAACgeEHlPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q3\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAA+HrS5z8AAAA46CvoPwAAAPiimOc/AAAA+C1o5z8AAAA4u0foPwAAAODbO+c/AAAAgAOu5z8AAABQcLjnPwAAAEBuCec/AAAAYPf15z8AAACQWzroPwAAAMgkoec/AAAA2EsZ6D8AAAAwcE/nPwAAAEgYFOg/AAAAuK206D8AAABIwYTqPwAAAGjGIeg/AAAAoKA75z8AAAAoUGbnPwAAAFBOPeg/AAAAWKu05z8AAAAwGHrpPwAAAOg7SOg/AAAAAEbR5z8AAABYKe3nPwAAADifQOg/AAAAgHgJ6D8AAADQrz/nPwAAALh1Veg/AAAAuI7a5z8AAAD41dvnPwAAAGiKd+c/AAAAECWY5z8AAAB45qfoPwAAAFDhbOg/AAAAUF8r5z8AAAAIibXnPwAAANjgeeg/AAAAOFdV5z8AAAAIuK/nPwAAAMg8Fug/AAAASDhC6T8AAABA2pTnPwAAAJj8P+g/AAAAuHkM6D8AAACooZTnPwAAAIBw0Oc/AAAAoPlt5z8AAACw/47oPwAAAPjUmec/AAAAcNvb5z8AAABoW9foPwAAAHjhwec/AAAA+OQX6D8AAABwbpHnPwAAACgTL+g/AAAAkJ6L6D8AAACwfFrnPwAAAGDKI+g/AAAA8Hul6D8AAAAY3X7nPwAAAMBIO+g/AAAAsE3z6D8AAABAdcDnPwAAABi7S+g/AAAA+DyN5z8AAAB4DqfoPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"max_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAYIPM6D8AAAAgjovqPwAAAIAAmOk/AAAAYNSy5z8AAADg0DHpPwAAAIArc+g/AAAAAGXt6D8AAAAAz1PoPwAAAGCcHug/AAAA4E8x6T8AAABAV2npPwAAACD/Wek/AAAA4NEd6T8AAABgZsfpPwAAAGDijOg/AAAAYBet6T8AAABg+oHrPwAAAAC/+Og/AAAAwNFZ6D8AAAAg5JjoPwAAAKCGD+k/AAAAIKy86T8AAABAZLXqPwAAACDNsOg/AAAAgC9e6D8AAACAOMnpPwAAAEBBp+o/AAAAIE1S6T8AAAAAxhHoPwAAAODCXOk/AAAAAC/p6D8AAADgCNzoPwAAACDQv+g/AAAAgDSK6D8AAADg1S/qPwAAAIB6A+o/AAAAoE9h6D8AAADAbSTpPwAAACDAz+k/AAAA4EUz6T8AAAAAdnjpPwAAAOAvN+g/AAAA4EOB6j8AAADAQsvoPwAAAAAGIuo/AAAAICcw6T8AAACghMvoPwAAAOBaj+g/AAAAQPep6T8AAADgAjHqPwAAAGCz0+c/AAAAYI7N6D8AAADgNfzqPwAAACDPQOk/AAAAwGT66D8AAAAAOVDoPwAAACA63+g/AAAAgMia6T8AAACgpfDnPwAAAODgTuk/AAAAADRV6T8AAABgSLvnPwAAAMCruOk/AAAAAJZm6T8AAACgg6noPwAAAGAKTuk/AAAAwB/q6D8AAACAc13qPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3353\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3354\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3349\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3350\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3351\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3361\",\"attributes\":{\"data_source\":{\"id\":\"p3306\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3362\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3363\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3358\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3359\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3360\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3370\",\"attributes\":{\"data_source\":{\"id\":\"p3306\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3371\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3372\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3367\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3368\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3369\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3379\",\"attributes\":{\"data_source\":{\"id\":\"p3306\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3380\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3381\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3376\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3377\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3378\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3389\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p3309\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p3310\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p3311\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"mse\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mase\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mae\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAMizNUAAAABgBsk1QAAAAOBR4TRAAAAAIEwgNUAAAABgeaA0QAAAAID/oDVAAAAAYMTUNkAAAACAs8s0QAAAAGA1XzRAAAAAoHdxNUAAAADg9xE3QAAAAEAWkTZAAAAA4NtoNUAAAAAAGPA0QAAAAMDXRzVAAAAAAH+2NUAAAABg8a81QAAAAGBtxDRAAAAAABbmNEAAAADguO40QAAAAIB89zRAAAAAIB55NkAAAAAAWD01QAAAAKCLKTVAAAAAQAMUNUAAAADAuT43QAAAACDoEDdAAAAAwGiWNUAAAADAtKM0QAAAAGDCrjVAAAAAIGOBNUAAAACgpwY3QAAAAMBZxzRAAAAAwDxlNUAAAAAg91o1QAAAAIC/9zVAAAAAQOlMNkAAAACAuxo1QAAAAIBZGzRAAAAAgELANEAAAABgMgk1QAAAAAATGDZAAAAA4F9KNUAAAADg9eE0QAAAAABwyjRAAAAAQIINNUAAAADgl4o2QAAAAACWzjRAAAAA4PlONEAAAABgVq40QAAAAEAiNTVAAAAAwGHFNUAAAADA3bo0QAAAAGCCEjVAAAAAQD6QNEAAAACAhI42QAAAAKB74jZAAAAAANBrNUAAAABgN5M0QAAAAKD9HTVAAAAA4LsdNkAAAACgxY02QAAAACAi4jRAAAAAgKdsNEAAAADgXO80QAAAAADJSzVAAAAAYGSkNUAAAABAMxw1QAAAAGA2STRAAAAAoK/7NEAAAADAJVc1QAAAAECNSzZAAAAA4C7kNEAAAACAxI40QAAAAOC0xjRAAAAAgBv9NUAAAADgbio2QAAAAOCDfzRAAAAA4JCgNEAAAABA+KI0QAAAAAC4pjVAAAAAwK4cN0AAAABgHsM0QAAAAICaLjRAAAAAYNOZNEAAAACgO3c2QAAAAOAAHTZAAAAAwJNnNUAAAAAgmWE0QAAAAGDWEDVAAAAAgGZUNUAAAABAGkg4QAAAAEDGwzRAAAAAIEdVNEAAAADgg7k0QAAAAEDI6TVAAAAAALiaNkAAAACABBw1QAAAAOBMXjRAAAAAIIp5NEAAAABgSFw2QAAAAEDNYzdAAAAAIGCINUAAAADgKrU0QAAAAODpBzVAAAAAoJNUNUAAAAAApmk3QAAAAAAs4DRAAAAAwG64NEAAAADgy0Q0QAAAAKAw6DVAAAAA4GGHOEAAAAAgHxY1QAAAAGCkUTRAAAAAoIa3NEAAAAAAq2o1QAAAAEBfpDZAAAAAQPO5NEAAAABA4Ao1QAAAAODJAzVAAAAAoF2yNUAAAADAgmQ3QAAAAKBA0DRAAAAAYPImNEAAAABgGq00QAAAAADFPDVAAAAAYBHgNUAAAACA4gU1QAAAACD9mDRAAAAAQM/DNEAAAAAAuMI1QAAAAECY0DVAAAAAYDjCNEAAAAAAaKM0QAAAAAAC+DRAAAAAINZVNUAAAAAgsf01QAAAAADCDTVAAAAAQFaZNEAAAADAs9c0QAAAAAA6+zRAAAAAoBs6NkAAAACgx/A0QAAAAIBqRDVAAAAAYGYXNUAAAACgd8c1QAAAAMBRzzVAAAAAgM+GNEAAAABASbw0QAAAAAAzUzRAAAAAwCrrNUAAAADgnyY3QAAAACDJIDVAAAAA4CuENEAAAAAgipM0QAAAAMDIZjdAAAAAAPNwNkAAAABgWOU0QAAAAOAI0zRAAAAAgFPRNEAAAABglVw1QAAAAICvTTZAAAAAwH+BNEAAAADg9FI0QAAAAACv8TZAAAAAIDJTNUAAAAAA39o1QAAAAGD6SDVAAAAAwH/SNEAAAADACBg1QAAAACCqBTVAAAAAIIUiNkAAAABgrgI1QAAAAEBxWDRAAAAAQFZxNEAAAACgvrQ1QAAAAECSiThAAAAAQJbyNEAAAACgXVg0QAAAAOAhxTRAAAAAgINkNkAAAABAId42QAAAAMCLyDRAAAAAgD2nNEAAAADAJH80QAAAAICXlDVAAAAAgBvtNUAAAADglr00QAAAAEBzKTRAAAAAQD2oNEAAAABA1AE2QAAAAMBhNzZAAAAAYMPyNEAAAACgppk0QAAAAGAVfTRAAAAAoKxaNkAAAABAhEw3QAAAAGDxaTVAAAAAQOXFNEAAAADAs041QAAAACAoFzZAAAAA4Ar4NUAAAAAgf3s1QAAAAGCCbDRAAAAAgOG3NEAAAADgyck2QAAAAADh6zZAAAAAILOWNkAAAAAgpcQ0QAAAAECbvzhAAAAAwDRjNUAAAABg8ig3QAAAAMC4DDVAAAAA4Lc2NEAAAACgl7w0QAAAAOCexDRAAAAAYOgpN0AAAAAgV8I0QAAAAEA62TRAAAAAgAKMNEAAAADg0AI2QAAAACCMyzZAAAAAgNkUNUAAAAAA+3Q0QAAAAKDxgDRAAAAAYGG2NkAAAAAggAI3QAAAAEDO1jVAAAAAIHJgNEAAAACg73Q1QAAAAMDzATZAAAAAACtxNkAAAADgYJw1QAAAAMDV8DRAAAAAwI/aNEAAAACAnSU1QAAAAGDjIzhAAAAAYNMVNUAAAADg7MY0QAAAAOAnmjRAAAAAgMa8NEAAAADgI1E4QAAAAKAjDTVAAAAAYFabNEAAAAAAcvM0QAAAAEC23zVAAAAA4BDZN0AAAAAAdhc1QAAAAIDHGDVAAAAAQHWmNEAAAABgAS41QAAAAGBK8jZAAAAAABbKNEAAAADADE40QAAAAOCQtjRAAAAAAF5+NUAAAACgkJA2QAAAAIAZ1DRAAAAAYMFjNEAAAABAB4M0QAAAAEBC9zVAAAAAgMSNN0AAAACgTuo1QAAAAIBGSDRAAAAAwKYNNUAAAABgngk1QAAAAKAwTDZAAAAAgKLZNEAAAACggBc0QAAAAGAVqTRAAAAAQP9GNUAAAACgG/s1QAAAAIAsDzVAAAAAoKYdNEAAAABA0SU1QAAAAOAbpzdAAAAA4BfHNkAAAACAqeE1QAAAAEDM1jRAAAAAALkgNUAAAAAgLWc4QAAAACAzRzlAAAAAQCjuNUAAAAAAefo0QAAAAMBNozRAAAAAQOtvNUAAAABA/Lo2QAAAAADFeTRAAAAAwFNMNEAAAABARdY0QAAAAOCcRzVAAAAAoIBONUAAAABAIAQ1QAAAAGAnSjRAAAAAoC2yNEAAAAAAxms1QAAAAACVtzdAAAAAAFZSNUAAAACg8CI0QAAAAOB1qTRAAAAAQLvwNkAAAACANmQ3QAAAAIDZDDZAAAAAgB2dNkAAAACAPl83QAAAACBCEzZAAAAAwIijNkAAAADAvGE1QAAAAABn2jRAAAAAAIbeNEAAAADACSc2QAAAAMAq9TdAAAAAoCNsNUAAAACA0Y00QAAAAOAleTRAAAAAICIQNUAAAABA3jQ2QAAAAMDf5DRAAAAAIMRYNEAAAACgWHs0QAAAAIDDPjZAAAAAoMD0NkAAAACgUn80QAAAAKBRkjRAAAAAwLj9NEAAAADgqnk2QAAAAOBSkjZAAAAAQGroNEAAAAAgsZ00QAAAACA/zzRAAAAAADiyNUAAAABgUd43QAAAAGDdjTRAAAAAgA5uNEAAAACAMw41QAAAAADuPzVAAAAAoEm7NUAAAAAA3kw1QAAAAAAS5TRAAAAAAPmyNEAAAAAg1ZA1QAAAAGAB9jVAAAAAoMHWNEAAAADAUb80QAAAAACqqTRAAAAA4BcqNUAAAACgR2k2QAAAAMBTsDRAAAAAwMpONEAAAACAt400QAAAAIAqLTdAAAAAgM4wOUAAAABAEmI1QAAAAGDUZDVAAAAAoDC5NEAAAADgsCw2QAAAAMAaEzdAAAAAAKX5NEAAAABgWiY0QAAAACDOnTRAAAAA4FnlNEAAAAAgN1Q2QAAAAEB63jVAAAAAwH7ENEAAAABArSI1QAAAACBH1DVAAAAAAMZUOEAAAADA9L01QAAAAEAHszRAAAAAwD6xNEAAAACg8qE1QAAAAIDH6zdAAAAAwHnvNEAAAACAwyE1QAAAAGBIuDVAAAAAIECzNEAAAACA0y82QAAAAOCG+jRAAAAAoCI2NEAAAAAAwdc0QAAAACBB8jRAAAAAYFAHNkAAAACgyDM1QAAAAKA/fDRAAAAA4MtzNEAAAAAglck1QAAAAECffzdAAAAAYP34NEAAAACA6Xk0QAAAAACEBjVAAAAAYBibNkAAAAAgi2A3QAAAAOB+/zRAAAAAoBX5M0AAAADA5Pc0QAAAAAAg1jVAAAAA4FDJNkAAAACA4EY2QAAAAIDfiTRAAAAAoB2zNEAAAADgZOE1QAAAAODrMTVAAAAAQLshNUAAAADge9w0QAAAAACOjTRAAAAAYFxfNkAAAABgwCE2QAAAAEA2KDVAAAAAoBZkNEAAAACAdLk0QAAAAIDS4jVAAAAAAG9wNkAAAACgXQg1QAAAACD5zTRAAAAAYB5BNEAAAAAgXR82QAAAAOBiZDZAAAAAAMgiNUAAAADA1+Q0QAAAAACgyzRAAAAAwDtzNkAAAADArVg4QAAAAAB8vTRAAAAA4NylNEAAAABA+Y00QAAAAEBX4jZAAAAAgJRzOUAAAAAA1/w0QAAAAGA1fzRAAAAAAODiNEAAAAAA1TY1QAAAAMB/0DVAAAAAoEpgNUAAAACg84U0QAAAAMCpojRAAAAAwCumNUAAAAAARTw3QAAAAEAG7DRAAAAAAJJ/NEAAAAAAiKs0QAAAACDZjTVAAAAAwH7iNkAAAAAAl5Q1QAAAAKACCjVAAAAAYBCWNEAAAADgX2k2QAAAAOCNoTVAAAAAoDSeNEAAAABAuF80QAAAAIBYfjRAAAAAgEMxN0AAAABgYKo1QAAAACCclDRAAAAAIKoENEAAAABAWAI1QAAAAKDeyjVAAAAAAGSxN0AAAABAnbA1QAAAAACw6DRAAAAAoBc8NEAAAAAALDY1QAAAAGCEaDZAAAAAQLoDNUAAAAAgOkM0QAAAAACo0jRAAAAAAF/HNEAAAACAqpU2QAAAAIBf/DRAAAAAAOifNEAAAACA0aM0QAAAAICljjdAAAAAwCi/N0AAAABAC/I0QAAAAOCtmDRAAAAAANY5NUAAAACAVRA2QAAAAGCDCTdAAAAAIHsNNUAAAADgtyM0QAAAAKDMhjRAAAAAYMLUNUAAAAAAI5o1QAAAAICV7zRAAAAAIAWHNEAAAADAZOw0QAAAAGBbVTVAAAAAABVpNkAAAAAgL+E0QAAAAAB2ITRAAAAAIHSPNEAAAADgsmE2QAAAAOBbtDhAAAAAoLT2NEAAAADAE440QAAAACBCxDRAAAAAICBdNkAAAAAAR4Y3QAAAAEDfDzVAAAAA4HLXNEAAAAAA7xk1QAAAAEDHFzZAAAAAQB3tNUAAAABA96I0QAAAAOBQeDRAAAAAQGU1OUAAAAAgaWg1QAAAAIB4WjVAAAAAQBrBNEAAAACgHpg0QAAAAIB6JTVAAAAAYH4TNkAAAAAgjek3QAAAAID/vzRAAAAA4GZiNUAAAACA+Qo1QAAAAIDfuDVAAAAAQBz1NkAAAABg7SI1QAAAAKBaTjVAAAAAYF8eNUAAAABApf81QAAAACCW5DdAAAAAANdqNEAAAABgHnY0QAAAACDFkjRAAAAAIKIDNUAAAACgimI2QAAAAECKEjVAAAAA4OBVNEAAAABACKo0QAAAACDF8DRAAAAAgC7lNkAAAAAgAu80QAAAAOBCnzRAAAAAwDDANEAAAADAoXg1QAAAAKC7SDZAAAAAIPkkN0AAAADAcOU1QAAAAOBgxjRAAAAAAAxtNUAAAABgzVI4QAAAAMAXvzVAAAAAwA/JNEAAAACgGNo0QAAAAODU2TVAAAAA4NTgN0AAAAAAI4k2QAAAAICHBTVAAAAA4C8UNUAAAADgwFQ1QAAAAGCHvjZAAAAAoIwGNUAAAADAK840QAAAAOB94TRAAAAAQFJLNUAAAABANpg2QAAAAOCETTVAAAAAQMnXNEAAAADAzYg0QAAAAAATQzVAAAAAIN8ZNkAAAABg9EQ1QAAAAMBQKjRAAAAAYJZzNEAAAADgxtQ2QAAAAMACZjZAAAAAwM8mNUAAAABA/0I0QAAAAIBe7DRAAAAAAMHcNUAAAACA9aM1QAAAAOBkwTRAAAAAIJv9NEAAAABgwHk0QAAAAGDyQDVAAAAAwKieNUAAAADgJgU1QAAAAMAznTRAAAAAgBK+NEAAAADAc2M1QAAAAADq2DVAAAAAoNi5NEAAAADA0KE0QAAAAMCshzVAAAAAYHW5NkAAAADAl+A2QAAAAACpoDRAAAAAgL0wNEAAAABAHuo0QAAAACBGRzVAAAAAQP76NUAAAACgk540QAAAAOArpTRAAAAAQOakNEAAAADAuG01QAAAAIDk0zZAAAAAADWbNEAAAACA7nY0QAAAAOClEDVAAAAAAFukNUAAAADAyQo2QAAAAGAsPTVAAAAAwLLHNEAAAADArMU0QAAAAOCcxjZAAAAAYBiANUAAAACAVVI1QAAAAIAFgjRAAAAAYADFNEAAAAAgclw1QAAAAOASxzVAAAAAYH2/NEAAAADAxww1QAAAAKC8GzVAAAAAYIXtNkAAAAAADOg2QAAAAMABZzVAAAAAwH5FNUAAAADAZ8E0QAAAAKD/aThAAAAAQGg5OEAAAACAKtA1QAAAAKBgSTVAAAAAoFNeNUAAAAAgHqg1QAAAAMBi3zdAAAAAoOJUNUAAAACACgM1QAAAAIB0yzRAAAAAwH6iNUAAAACAcQk2QAAAAGAYgDVAAAAAoFG4NEAAAACA+m01QAAAAMB9ZzVAAAAAIIY3NUAAAADAvk41QAAAAGDUAjRAAAAAYCbANEAAAADAFY42QAAAACBbADlAAAAAQPAGNkAAAADAl2A2QAAAAKBzczZAAAAAwNvZNUAAAABg/d42QAAAAKBYLjVAAAAA4Dr+NEAAAACA8dU0QAAAACBLbzZAAAAAIFiAN0AAAAAg7Kw0QAAAACC7FDVAAAAAoFajNEAAAAAgYfU0QAAAACA9DDZAAAAAgHKTNEAAAAAgcGg0QAAAAIAgizRAAAAAoALINUAAAABA25U2QAAAAGB/eDVAAAAAoL05NUAAAAAAQek0QAAAACAj7jVAAAAAoFG1NkAAAADgSlY1QAAAAIDVvzRAAAAAwNyqNEAAAABgr101QAAAAIAa/TZAAAAAQM/KNEAAAAAAYlY0QAAAAMAI1jRAAAAAgJOcNUAAAACAMfo1QAAAAODsQzVAAAAAoPlcNEAAAABg/Zo0QA==\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mape\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"fold\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\"],\"shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}],[\"trial_num\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"fold_str\",{\"type\":\"ndarray\",\"array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shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3390\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3391\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3386\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mase\"},\"size\":{\"type\":\"value\",\"value\":7},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"type\":\"object\",\"name\":\"CategoricalColorMapper\",\"id\":\"p3382\",\"attributes\":{\"palette\":[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\"],\"factors\":{\"type\":\"ndarray\",\"array\":[\"0\",\"1\",\"2\",\"3\",\"4\"],\"shape\":[5],\"dtype\":\"object\",\"order\":\"little\"}}}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3387\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mase\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p3382\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3388\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mase\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p3382\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p3321\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p3335\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p3336\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p3337\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p3338\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p3343\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p3344\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p3345\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p3330\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p3331\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p3332\"},\"axis_label\":\"mase\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p3333\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p3325\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p3326\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p3327\"},\"axis_label\":\"App\",\"major_label_orientation\":1.5707963267948966,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p3328\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p3329\",\"attributes\":{\"axis\":{\"id\":\"p3325\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p3334\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p3330\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p3392\",\"attributes\":{\"title\":\"Fold\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3393\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"0\"},\"renderers\":[{\"id\":\"p3389\"}],\"index\":0}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3394\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"1\"},\"renderers\":[{\"id\":\"p3389\"}],\"index\":1}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3395\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"2\"},\"renderers\":[{\"id\":\"p3389\"}],\"index\":2}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3396\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"3\"},\"renderers\":[{\"id\":\"p3389\"}],\"index\":3}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3397\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"4\"},\"renderers\":[{\"id\":\"p3389\"}],\"index\":4}}]}}]}}]}};\n  const render_items = [{\"docid\":\"dee7de09-f0f1-41ad-9c00-ce21706482cc\",\"roots\":{\"p3312\":\"fbb1cfd8-1e18-4088-b8ae-a838c0e42121\"},\"root_ids\":[\"p3312\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p3312"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"b6f10339-c110-47ac-8894-2c74734e52bc\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"b6f10339-c110-47ac-8894-2c74734e52bc\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"b6f10339-c110-47ac-8894-2c74734e52bc\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"ae2e3daa-e1aa-4340-bd31-3f0d471cea77\" data-root-id=\"p3443\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"ba04f921-76bf-4802-833f-69baf62c7e89\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p3443\",\"attributes\":{\"width\":1200,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p3453\",\"attributes\":{\"factors\":[\"Web_Weather\",\"Microsoft_Web_Services\",\"Web_Downloads\",\"Apple_iCloud\",\"Web_Games\",\"Microsoft_Store\",\"Apple_Music\",\"Microsoft_Azure\",\"Apple_iMessage\",\"Fortnite\",\"Twitch\",\"Apple_Video\",\"Orange_TV\",\"Periscope\",\"PlayStation\",\"Amazon_Web_Services\",\"Web_Adult\",\"Skype\",\"Google_Play_Store\",\"Wikipedia\",\"Google_Docs\",\"SoundCloud\",\"Waze\",\"Yahoo_Mail\",\"Microsoft_Skydrive\",\"Tor\",\"Web_Clothes\",\"Google_Mail\",\"Apple_Mail\",\"Microsoft_Office\",\"Apple_Web_Services\",\"Pokemon_GO\",\"EA_Games\",\"Google_Meet\",\"Telegram\",\"Dropbox\",\"Uber\",\"Yahoo\",\"DailyMotion\",\"Web_Streaming\",\"Web_Transportation\",\"LinkedIn\",\"Spotify\",\"Pinterest\",\"Deezer\",\"Google_Drive\",\"Facebook_Messenger\",\"Web_Finance\",\"Google_Web_Services\",\"Web_Food\",\"Apple_App_Store\",\"Netflix\",\"Molotov\",\"Apple_Siri\",\"Clash_of_Clans\",\"WhatsApp\",\"Web_e-Commerce\",\"YouTube\",\"Microsoft_Mail\",\"Apple_iTunes\",\"Web_Ads\",\"TeamViewer\",\"Twitter\",\"Instagram\",\"Google_Maps\",\"Facebook\",\"Facebook_Live\",\"Snapchat\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p3445\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p3454\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p3455\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p3446\",\"attributes\":{\"text\":\"mae distribution per app and per folds\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3483\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p3437\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p3438\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p3439\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAAAAyAAAAMwAAADQAAAA1AAAANgAAADcAAAA4AAAAOQAAADoAAAA7AAAAPAAAAD0AAAA+AAAAPwAAAEAAAABBAAAAQgAAAEMAAAA=\"},\"shape\":[68],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Amazon_Web_Services\",\"Apple_App_Store\",\"Apple_Mail\",\"Apple_Music\",\"Apple_Siri\",\"Apple_Video\",\"Apple_Web_Services\",\"Apple_iCloud\",\"Apple_iMessage\",\"Apple_iTunes\",\"Clash_of_Clans\",\"DailyMotion\",\"Deezer\",\"Dropbox\",\"EA_Games\",\"Facebook\",\"Facebook_Live\",\"Facebook_Messenger\",\"Fortnite\",\"Google_Docs\",\"Google_Drive\",\"Google_Mail\",\"Google_Maps\",\"Google_Meet\",\"Google_Play_Store\",\"Google_Web_Services\",\"Instagram\",\"LinkedIn\",\"Microsoft_Azure\",\"Microsoft_Mail\",\"Microsoft_Office\",\"Microsoft_Skydrive\",\"Microsoft_Store\",\"Microsoft_Web_Services\",\"Molotov\",\"Netflix\",\"Orange_TV\",\"Periscope\",\"Pinterest\",\"PlayStation\",\"Pokemon_GO\",\"Skype\",\"Snapchat\",\"SoundCloud\",\"Spotify\",\"TeamViewer\",\"Telegram\",\"Tor\",\"Twitch\",\"Twitter\",\"Uber\",\"Waze\",\"Web_Ads\",\"Web_Adult\",\"Web_Clothes\",\"Web_Downloads\",\"Web_Finance\",\"Web_Food\",\"Web_Games\",\"Web_Streaming\",\"Web_Transportation\",\"Web_Weather\",\"Web_e-Commerce\",\"WhatsApp\",\"Wikipedia\",\"Yahoo\",\"Yahoo_Mail\",\"YouTube\"],\"shape\":[68],\"dtype\":\"object\",\"order\":\"little\"}],[\"min_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAwFAqNEAAAADgrZg0QAAAAOAnmjRAAAAA4MtzNEAAAABgEJY0QAAAAGB5oDRAAAAA4IN/NEAAAADADE40QAAAAKAemDRAAAAA4PRSNEAAAACA34k0QAAAAEBxWDRAAAAAoBc8NEAAAABgVps0QAAAAOC3NjRAAAAAIKXENEAAAADATaM0QAAAAIBGSDRAAAAAoPlcNEAAAAAgBYc0QAAAAKBSfzRAAAAAIEdVNEAAAACgMLk0QAAAAOBMXjRAAAAAwMpONEAAAABggmw0QAAAAMBnwTRAAAAAILGdNEAAAACgph00QAAAAMBZxzRAAAAA4PlONEAAAADgtyM0QAAAAIBZGzRAAAAAAHYhNEAAAADgK4Q0QAAAAKBdWDRAAAAAYCdKNEAAAABg1AI0QAAAAICaLjRAAAAAYDZJNEAAAACgFfkzQAAAAGDBYzRAAAAAQPAGNkAAAABgFX00QAAAACCqBDRAAAAAQOXFNEAAAABgwHk0QAAAAMDNiDRAAAAAoIAXNEAAAADAtKM0QAAAAMB+xDRAAAAAYPImNEAAAAAgmWE0QAAAAODLRDRAAAAAYFomNEAAAABAcyk0QAAAAIDx1TRAAAAAgL0wNEAAAAAg/Zg0QAAAAMBTTDRAAAAAANdqNEAAAAAgxFg0QAAAAED/QjRAAAAA4CV5NEAAAABgHkE0QAAAAABiVjRAAAAAgKdsNEAAAACAU9E0QA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q1\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAqPh3NEAAAAAYLc40QAAAABhJwDRAAAAAeFHQNEAAAAAQcAg1QAAAALgtxTRAAAAAMCKtNEAAAACo96Q0QAAAAADi4zRAAAAAoN2JNEAAAACg1c00QAAAADir0DRAAAAAeHbvNEAAAAAYlLo0QAAAAEgA0zRAAAAAIJlFNUAAAABgnU41QAAAAMAv2TRAAAAAQH+/NEAAAAAI4u80QAAAAPBe7jRAAAAASGCoNEAAAABgZk41QAAAAICPijRAAAAAkF6WNEAAAAD4Uc00QAAAAHDqKTVAAAAA6K/DNEAAAADwYA01QAAAAGgQMDVAAAAASGa2NEAAAACg7ag0QAAAALiAtjRAAAAAqPiINEAAAAAguJ80QAAAAIiI/TRAAAAASEXLNEAAAAAAIq80QAAAAMDVnDRAAAAASAPKNEAAAACAH8o0QAAAALASiTRAAAAAuE5lNkAAAABYfqc0QAAAAMBWnTRAAAAAKINVNUAAAABAIeA0QAAAABDpwjRAAAAAIBCwNEAAAACg3+s0QAAAADCe/jRAAAAA8OO1NEAAAADAXek0QAAAAIhPhjRAAAAAiNfMNEAAAAAAsKg0QAAAADhz5jRAAAAAgF+3NEAAAADw0Ks0QAAAALAozjRAAAAA2AyENEAAAACYSn80QAAAAND6+jRAAAAAALylNEAAAADwhcg0QAAAANgZnTRAAAAAcOXdNEAAAABA7No0QA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"median_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAQPYrNUAAAAAA7Bg1QAAAACB9DTVAAAAAwLn9NEAAAACgHIs1QAAAAADPADVAAAAA4M8DNUAAAABwU8A0QAAAAHA6NzVAAAAAUNmkNUAAAAAA+KA1QAAAANBRCDVAAAAAoMU6NUAAAADQSgA1QAAAALCiCTVAAAAAEOuPNkAAAABgKd81QAAAALDDcDVAAAAAcO1BNUAAAAAwUAk1QAAAAIAeWTVAAAAAoE39NEAAAAAg2GY1QAAAAGAFBDVAAAAAsOX6NEAAAACQRXQ1QAAAAKBVpDVAAAAAkFofNUAAAADwxiA1QAAAAPBPczVAAAAAsMD/NEAAAACQng01QAAAAPAj6TRAAAAAMLzONEAAAADgvgs1QAAAAACkODVAAAAAwA5LNUAAAABwIkM1QAAAADBNwDRAAAAAwDQiNUAAAACgAAk1QAAAALBf8jRAAAAAoJmVNkAAAACg4+80QAAAALA7DDVAAAAAQAmvNUAAAAAA/kw1QAAAAMCB2DRAAAAAcKDxNEAAAACQW7Y1QAAAAHAcJjVAAAAAIDHrNEAAAAAQNTw1QAAAAGBNzDRAAAAA8C70NEAAAACAnOA0QAAAALAKSDVAAAAAwB4YNUAAAABA3+E0QAAAAJD2KzVAAAAAoOS3NEAAAAAgKbw0QAAAAPDepTVAAAAAYG9ANUAAAABARvY0QAAAACAe8jRAAAAAEIwINUAAAAAg5xQ1QA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q3\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAwFnTNUAAAAAwIM01QAAAACgdOjVAAAAAELpENUAAAAAIXCo2QAAAAEgLqzVAAAAAuMwWNkAAAADw9EA1QAAAAOimWDVAAAAAcDVANkAAAACAm3w2QAAAAIA45zVAAAAASE7ENUAAAACAnn41QAAAAMiXXzVAAAAAOFvjNkAAAADou1s4QAAAAFgF9DVAAAAAIKaINUAAAADgtIQ1QAAAAEgTITZAAAAAmFFdNUAAAAB4v/E2QAAAACDh2DVAAAAAiB2VNUAAAAAYzuk1QAAAAPjO3zZAAAAA8MhWNkAAAABoFVc1QAAAAPCysjVAAAAAaJCaNUAAAABgutM1QAAAAIB+wDVAAAAAkPCqNUAAAADYEEQ2QAAAAEjXtzVAAAAA6JB7NUAAAADQM2I1QAAAANAaQDZAAAAAiD2ONUAAAADgUaE1QAAAALA0ejVAAAAAsJ1DN0AAAAAIEL41QAAAAJC82DVAAAAAYDBWNkAAAAAgjs41QAAAADj4TDVAAAAAqKd0NUAAAADgv8E2QAAAALAxtjVAAAAAOFGTNUAAAADwrGA2QAAAAFBPjjVAAAAAmNu0NUAAAAAwFHQ1QAAAAIjoBDZAAAAAmAWDNkAAAABgDC81QAAAAGgRmjVAAAAA8EtLNkAAAADgcQk1QAAAALhJojZAAAAAyDpdNkAAAABQ5781QAAAANgVnTVAAAAAoIa1NUAAAABI/ms2QA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"max_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAIIzLNkAAAADAKL83QAAAAGDjIzhAAAAAABMYNkAAAABAzWM3QAAAAGAB9jVAAAAA4GJkNkAAAABgSvI2QAAAAADf2jVAAAAAQGU1OUAAAACge+I2QAAAACCN6TdAAAAAAGSxN0AAAADgI1E4QAAAAGDyKDdAAAAAQJu/OEAAAAAgM0c5QAAAAIDEjTdAAAAAgDH6NUAAAACgGzo2QAAAAKDA9DZAAAAAQBpIOEAAAACAzjA5QAAAAABFPDdAAAAAYMTUNkAAAABgzVI4QAAAAOAbpzdAAAAAoFG1NkAAAACgG/s1QAAAAIDH6zdAAAAAQJ9/N0AAAABggwk3QAAAAEDpTDZAAAAAABVpNkAAAADgW7Q4QAAAAECSiThAAAAAgHEJNkAAAAAAlbc3QAAAAMCtWDhAAAAAYFxfNkAAAAAgi2A3QAAAAIDk0zZAAAAAIFsAOUAAAACALuU2QAAAAOBhhzhAAAAAQIRMN0AAAAAAK3E2QAAAAGDoKTdAAAAA4JzGNkAAAAAAxlQ4QAAAACAeeTZAAAAAwIJkN0AAAACAlHM5QAAAAACmaTdAAAAAwBoTN0AAAACgimI2QAAAAGD93jZAAAAA4BDZN0AAAACAqpU2QAAAAMBi3zdAAAAAIJbkN0AAAABA3jQ2QAAAACCAAjdAAAAAwCr1N0AAAAAAb3A2QAAAAGBR3jdAAAAAoMWNNkAAAAAAR4Y3QA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3484\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3485\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3480\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3481\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3482\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3492\",\"attributes\":{\"data_source\":{\"id\":\"p3437\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3493\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3494\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3489\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3490\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3491\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3501\",\"attributes\":{\"data_source\":{\"id\":\"p3437\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3502\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3503\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3498\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3499\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3500\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3510\",\"attributes\":{\"data_source\":{\"id\":\"p3437\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3511\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3512\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3507\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3508\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3509\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3520\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p3440\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p3441\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p3442\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"mse\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mase\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mae\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mape\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"fold\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\"],\"shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}],[\"trial_num\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"fold_str\",{\"type\":\"ndarray\",\"array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shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3521\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3522\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3517\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mae\"},\"size\":{\"type\":\"value\",\"value\":7},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"type\":\"object\",\"name\":\"CategoricalColorMapper\",\"id\":\"p3513\",\"attributes\":{\"palette\":[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\"],\"factors\":{\"type\":\"ndarray\",\"array\":[\"0\",\"1\",\"2\",\"3\",\"4\"],\"shape\":[5],\"dtype\":\"object\",\"order\":\"little\"}}}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3518\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mae\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p3513\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3519\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mae\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p3513\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p3452\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p3466\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p3467\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p3468\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p3469\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p3474\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p3475\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p3476\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p3461\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p3462\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p3463\"},\"axis_label\":\"mae\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p3464\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p3456\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p3457\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p3458\"},\"axis_label\":\"App\",\"major_label_orientation\":1.5707963267948966,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p3459\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p3460\",\"attributes\":{\"axis\":{\"id\":\"p3456\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p3465\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p3461\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p3523\",\"attributes\":{\"title\":\"Fold\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3524\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"0\"},\"renderers\":[{\"id\":\"p3520\"}],\"index\":0}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3525\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"1\"},\"renderers\":[{\"id\":\"p3520\"}],\"index\":1}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3526\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"2\"},\"renderers\":[{\"id\":\"p3520\"}],\"index\":2}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3527\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"3\"},\"renderers\":[{\"id\":\"p3520\"}],\"index\":3}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3528\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"4\"},\"renderers\":[{\"id\":\"p3520\"}],\"index\":4}}]}}]}}]}};\n  const render_items = [{\"docid\":\"ba04f921-76bf-4802-833f-69baf62c7e89\",\"roots\":{\"p3443\":\"ae2e3daa-e1aa-4340-bd31-3f0d471cea77\"},\"root_ids\":[\"p3443\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p3443"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"aee1e26f-84c5-4d9f-b318-f6ee40039c50\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"aee1e26f-84c5-4d9f-b318-f6ee40039c50\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"aee1e26f-84c5-4d9f-b318-f6ee40039c50\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"d360bdc3-4161-4829-8914-7492760e151a\" data-root-id=\"p3574\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"6b1332dc-9819-4935-b772-e87ea58ecc32\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p3574\",\"attributes\":{\"width\":1200,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p3584\",\"attributes\":{\"factors\":[\"Web_Downloads\",\"Web_Weather\",\"Microsoft_Store\",\"Apple_Music\",\"Microsoft_Web_Services\",\"Apple_iCloud\",\"Fortnite\",\"Web_Games\",\"Apple_Video\",\"Twitch\",\"Tor\",\"Amazon_Web_Services\",\"Google_Play_Store\",\"Yahoo_Mail\",\"Periscope\",\"Waze\",\"Orange_TV\",\"Pokemon_GO\",\"Web_Adult\",\"Wikipedia\",\"SoundCloud\",\"Microsoft_Azure\",\"Telegram\",\"Google_Docs\",\"Skype\",\"Web_Clothes\",\"PlayStation\",\"Google_Meet\",\"DailyMotion\",\"Microsoft_Skydrive\",\"Apple_iMessage\",\"Dropbox\",\"Apple_Mail\",\"Spotify\",\"Pinterest\",\"Web_Streaming\",\"Yahoo\",\"Google_Mail\",\"Apple_Web_Services\",\"EA_Games\",\"Deezer\",\"LinkedIn\",\"Google_Drive\",\"Microsoft_Office\",\"Netflix\",\"Web_Finance\",\"Web_Transportation\",\"Apple_App_Store\",\"WhatsApp\",\"Google_Web_Services\",\"Uber\",\"Facebook_Messenger\",\"Web_Food\",\"Web_e-Commerce\",\"Apple_Siri\",\"YouTube\",\"Clash_of_Clans\",\"Twitter\",\"Microsoft_Mail\",\"Molotov\",\"Web_Ads\",\"Google_Maps\",\"Apple_iTunes\",\"Instagram\",\"Facebook\",\"TeamViewer\",\"Snapchat\",\"Facebook_Live\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p3576\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p3585\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p3586\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p3577\",\"attributes\":{\"text\":\"mse distribution per app and per folds\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3614\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p3568\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p3569\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p3570\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAAAAyAAAAMwAAADQAAAA1AAAANgAAADcAAAA4AAAAOQAAADoAAAA7AAAAPAAAAD0AAAA+AAAAPwAAAEAAAABBAAAAQgAAAEMAAAA=\"},\"shape\":[68],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Amazon_Web_Services\",\"Apple_App_Store\",\"Apple_Mail\",\"Apple_Music\",\"Apple_Siri\",\"Apple_Video\",\"Apple_Web_Services\",\"Apple_iCloud\",\"Apple_iMessage\",\"Apple_iTunes\",\"Clash_of_Clans\",\"DailyMotion\",\"Deezer\",\"Dropbox\",\"EA_Games\",\"Facebook\",\"Facebook_Live\",\"Facebook_Messenger\",\"Fortnite\",\"Google_Docs\",\"Google_Drive\",\"Google_Mail\",\"Google_Maps\",\"Google_Meet\",\"Google_Play_Store\",\"Google_Web_Services\",\"Instagram\",\"LinkedIn\",\"Microsoft_Azure\",\"Microsoft_Mail\",\"Microsoft_Office\",\"Microsoft_Skydrive\",\"Microsoft_Store\",\"Microsoft_Web_Services\",\"Molotov\",\"Netflix\",\"Orange_TV\",\"Periscope\",\"Pinterest\",\"PlayStation\",\"Pokemon_GO\",\"Skype\",\"Snapchat\",\"SoundCloud\",\"Spotify\",\"TeamViewer\",\"Telegram\",\"Tor\",\"Twitch\",\"Twitter\",\"Uber\",\"Waze\",\"Web_Ads\",\"Web_Adult\",\"Web_Clothes\",\"Web_Downloads\",\"Web_Finance\",\"Web_Food\",\"Web_Games\",\"Web_Streaming\",\"Web_Transportation\",\"Web_Weather\",\"Web_e-Commerce\",\"WhatsApp\",\"Wikipedia\",\"Yahoo\",\"Yahoo_Mail\",\"YouTube\"],\"shape\":[68],\"dtype\":\"object\",\"order\":\"little\"}],[\"min_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAwCqzkkAAAABAqseSQAAAAMB8vZJAAAAAYOwMk0AAAADgcuqSQAAAAABPRZNAAAAAALfZkkAAAADARz+SQAAAAKBjEpNAAAAAgLW2kkAAAABARuSSQAAAAICRuZJAAAAAANt0k0AAAAAguOSSQAAAAADhA5NAAAAAwOKyk0AAAADgeTuTQAAAAGA7+JJAAAAAIMnxkkAAAABAqumSQAAAAECVA5NAAAAAAF6okkAAAACgiVKTQAAAACDWl5JAAAAAIOybkkAAAABAj8SSQAAAAACHmZNAAAAA4K0pk0AAAACgZUySQAAAAGAf65NAAAAAwAXckkAAAADAorSSQAAAAMD/UpJAAAAAoM0YkkAAAADgfgyTQAAAAOAMgJJAAAAAIGFekkAAAACgnSeSQAAAACBybpJAAAAA4J7IkkAAAACgrCWSQAAAAMBUopJAAAAAAEhblUAAAACg/g+TQAAAAIC4L5JAAAAAgICclEAAAACADz+TQAAAAMDuzJJAAAAA4KttkkAAAABgJCqTQAAAAIAK+JNAAAAAQLFrkkAAAADAbNKSQAAAAABPZZJAAAAA4M0+kkAAAADAHieSQAAAAEDmKJNAAAAAQLJAkkAAAADAjQaTQAAAACDimpJAAAAAgL/NkkAAAAAAKMWSQAAAAAB5xJJAAAAAoB/3kkAAAADADZmSQAAAAADCb5JAAAAAAOC5kkAAAACgrmiTQA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q1\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAwFi3k0AAAAC4ldyTQAAAABD+HpRAAAAA8JPXk0AAAAD4xzGUQAAAAPAP35NAAAAAwO+xk0AAAACIGNSTQAAAAKhSX5RAAAAAoPBsk0AAAADwtMGUQAAAANiBt5NAAAAAkH2Rk0AAAAB4vZ+TQAAAANCqIpRAAAAAeKwIlkAAAADYgqKUQAAAABg/PZRAAAAAkO/dk0AAAACwoR6UQAAAADgrApRAAAAAsHwUlEAAAACgpLyUQAAAAGAPx5NAAAAAkPqHk0AAAAAw2oaUQAAAACBRsJRAAAAAwOEwlEAAAAAQ4uCTQAAAAOBF0ZRAAAAAGKxFlEAAAABIZgaUQAAAABiDu5NAAAAAcJiDk0AAAABIYvWTQAAAAJAGRpRAAAAAMAcwlEAAAACgOjuUQAAAANgYQpNAAAAAWJU2lEAAAADAr9yTQAAAADhqw5NAAAAAaDKrlUAAAADIB+6TQAAAAEhDwpNAAAAAaJrClUAAAAD4i6aTQAAAAEj1u5NAAAAA0BgMlEAAAACoQXOUQAAAAGCWkpRAAAAA+Ls2lEAAAADYIeuTQAAAAFi8qZNAAAAAeOonlEAAAABg+fOTQAAAAODAaZRAAAAAcH+7k0AAAADYOPKTQAAAAJBFwJNAAAAA6MaDk0AAAABw05KTQAAAAOA1cJRAAAAAYE7gk0AAAAAQeu+TQAAAAGghvZNAAAAAgBr/k0AAAAAw7OCTQA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"median_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAMDB7lEAAAABg/1mUQAAAAACOb5RAAAAAQBFelEAAAACg8SuVQAAAAEC8YZRAAAAA4Oy5lEAAAACQB0aUQAAAAMAVu5RAAAAAMEAelUAAAABwRIaVQAAAAIC5LZRAAAAAYLmtlEAAAADwi/6TQAAAAGDb3pRAAAAAEEc7lkAAAADARtCVQAAAAEBVH5VAAAAAcP1SlEAAAAAAKYOUQAAAAGDAm5RAAAAAYDKZlEAAAACgnCWVQAAAAHAqKJRAAAAAkM5llEAAAABQVcSUQAAAAKC4epVAAAAA0HCJlEAAAABg/puUQAAAAJCWNpVAAAAAUEvGlEAAAABw2IaUQAAAAHBP85NAAAAAMPj3k0AAAAAARKqUQAAAAEDjzZRAAAAAUCKRlEAAAACwMIGUQAAAAHCMxZNAAAAAsGFVlEAAAADgO0GUQAAAAFBRkpRAAAAAkNKllkAAAABQu5uUQAAAADCtSJRAAAAAMM3vlkAAAACAdTeUQAAAAKA395NAAAAAoBU4lEAAAAAAclGVQAAAAPDN/ZRAAAAAoPZklEAAAACgTLmUQAAAAHAkAZRAAAAAwP9nlEAAAACQuiqUQAAAADB375RAAAAA8CizlEAAAADw2SGUQAAAAKBHmZRAAAAAEA0hlEAAAACQGfuTQAAAAJCiXJVAAAAAENFKlEAAAABwqZSUQAAAAHB3opRAAAAA4MgnlEAAAAAAX3mUQA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q3\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAuO/rlEAAAAAoCa2VQAAAADi8BJVAAAAA6Ll6lEAAAAC4ABCWQAAAADgFvZRAAAAAKFuzlUAAAAC4zAKVQAAAAOATE5VAAAAAWGo2lkAAAACoQlOWQAAAADjHwpRAAAAAaBiflUAAAABwTx+VQAAAAHjsM5VAAAAAoOeAl0AAAABYm3eZQAAAANCV35VAAAAAQH/hlEAAAACQoemUQAAAAJCRwJVAAAAAsAz1lEAAAAA4qc2WQAAAACC4QZVAAAAAiJB5lUAAAABIo22VQAAAANgST5ZAAAAAiKbzlUAAAABQelGVQAAAAEDFCZZAAAAA+NojlUAAAAC4pB2VQAAAAMgcPpVAAAAAQEA8lUAAAADw/q2WQAAAABh0zZVAAAAAAD0flUAAAAAALq6UQAAAAJgyHZZAAAAAkKkRlUAAAAC4gsyUQAAAAACuY5VAAAAAoOdPl0AAAABocPyUQAAAAFCrPJVAAAAAYA1El0AAAADYzRCVQAAAAFC3I5VAAAAAwCaUlEAAAABICtmVQAAAANBWdJVAAAAASBMDlUAAAAC4vV2WQAAAAPBIJpVAAAAAWHsBlUAAAABAuKeUQAAAACBuopVAAAAAIAgnlkAAAABIUySVQAAAAPDXN5VAAAAAMLRPlkAAAACYlmaUQAAAAKBZLJZAAAAAmK6ZlkAAAAAQwS+VQAAAAMgej5VAAAAAuLtnlUAAAADA5GeWQA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"max_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAIHcJlkAAAADgsB2YQAAAAGAsSphAAAAAwDNAlUAAAADA87aXQAAAAMDPVZVAAAAAYPK2lkAAAACgtHiWQAAAAMAjzpVAAAAAQGJHn0AAAABA/veWQAAAAKBuRJhAAAAAIDVMl0AAAACAJziZQAAAAEBP2pZAAAAA4CkkmUAAAAAgoQibQAAAAOA7yJdAAAAAgDx5lUAAAAAAYzyWQAAAAICk4pZAAAAAIDkLmUAAAAAAAomYQAAAAMBmgJdAAAAAYBwklkAAAAAgPfyYQAAAAABwI5lAAAAAgAdmlkAAAACgODGWQAAAACDqMpdAAAAAIDK0l0AAAAAgvsKWQAAAACDYw5VAAAAAYKv3lUAAAAAg/kCZQAAAAGCIFpdAAAAAIKf0lUAAAADgAAaYQAAAAECjHplAAAAA4MF3lkAAAAAAnAWXQAAAAOCc0pZAAAAA4IrWmEAAAAAgX7SVQAAAAICBkJhAAAAAwLFtmEAAAABA5tWWQAAAAOAr8JVAAAAAYE8cl0AAAAAgt0+YQAAAACDOa5ZAAAAAgERtlkAAAABgwBWbQAAAAOBwPZdAAAAAgKTDlkAAAADgYTqVQAAAAABaZ5ZAAAAAwB5UmEAAAABA+n6VQAAAAMDyLZhAAAAAQOXll0AAAAAA42CVQAAAAMDO85ZAAAAAYNuvl0AAAADA3aqVQAAAAGDDbJdAAAAAAGzolUAAAACgmhKYQA==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3615\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3616\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3611\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3612\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3613\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3623\",\"attributes\":{\"data_source\":{\"id\":\"p3568\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3624\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3625\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3620\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3621\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p3622\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3632\",\"attributes\":{\"data_source\":{\"id\":\"p3568\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3633\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3634\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3629\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3630\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3631\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3641\",\"attributes\":{\"data_source\":{\"id\":\"p3568\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3642\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3643\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3638\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.3}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3639\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p3640\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.2},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"line_width\":{\"type\":\"value\",\"value\":2},\"fill_color\":{\"type\":\"value\",\"value\":\"grey\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p3651\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p3571\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p3572\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p3573\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"mse\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mase\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mae\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mape\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"fold\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\"],\"shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}],[\"trial_num\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"fold_str\",{\"type\":\"ndarray\",\"array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shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p3652\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p3653\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3648\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mse\"},\"size\":{\"type\":\"value\",\"value\":7},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"type\":\"object\",\"name\":\"CategoricalColorMapper\",\"id\":\"p3644\",\"attributes\":{\"palette\":[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\"],\"factors\":{\"type\":\"ndarray\",\"array\":[\"0\",\"1\",\"2\",\"3\",\"4\"],\"shape\":[5],\"dtype\":\"object\",\"order\":\"little\"}}}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3649\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mse\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p3644\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p3650\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mse\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p3644\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p3583\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p3597\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p3598\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p3599\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p3600\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p3605\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p3606\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p3607\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p3592\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p3593\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p3594\"},\"axis_label\":\"mse\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p3595\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p3587\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p3588\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p3589\"},\"axis_label\":\"App\",\"major_label_orientation\":1.5707963267948966,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p3590\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p3591\",\"attributes\":{\"axis\":{\"id\":\"p3587\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p3596\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p3592\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p3654\",\"attributes\":{\"title\":\"Fold\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3655\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"0\"},\"renderers\":[{\"id\":\"p3651\"}],\"index\":0}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3656\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"1\"},\"renderers\":[{\"id\":\"p3651\"}],\"index\":1}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3657\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"2\"},\"renderers\":[{\"id\":\"p3651\"}],\"index\":2}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3658\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"3\"},\"renderers\":[{\"id\":\"p3651\"}],\"index\":3}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3659\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"4\"},\"renderers\":[{\"id\":\"p3651\"}],\"index\":4}}]}}]}}]}};\n  const render_items = [{\"docid\":\"6b1332dc-9819-4935-b772-e87ea58ecc32\",\"roots\":{\"p3574\":\"d360bdc3-4161-4829-8914-7492760e151a\"},\"root_ids\":[\"p3574\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p3574"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import ColumnDataSource, FactorRange\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.plotting import figure, show, output_file, save,output_notebook\n",
    "from bokeh.models import ColumnDataSource, Toggle, CustomJS,HoverTool, Legend\n",
    "from bokeh.layouts import layout,row,column\n",
    "\n",
    "\n",
    "def plot_boxplot_on_metric(df,metric_i='mse',save_path=f\"MSE_distribution_per_app_and_per_fold.html\"):\n",
    "    sdf = df.groupby(\"id\")[metric_i].mean().sort_values()\n",
    "    sdf_ids = sdf.index.tolist()\n",
    "\n",
    "    df[\"fold_str\"] = df[\"fold\"].astype(str)\n",
    "\n",
    "    grp = df.groupby(\"id\")[metric_i]\n",
    "    q1 = grp.quantile(0.25)\n",
    "    q2 = grp.quantile(0.50)\n",
    "    q3 = grp.quantile(0.75)\n",
    "    mn = grp.min()\n",
    "    mx = grp.max()\n",
    "    stats = pd.DataFrame({\n",
    "        \"id\": q1.index,\n",
    "        \"min_v\": mn.values,\n",
    "        \"q1\": q1.values,\n",
    "        \"median_v\": q2.values,\n",
    "        \"q3\": q3.values,\n",
    "        \"max_v\": mx.values\n",
    "    })\n",
    "    source_box = ColumnDataSource(stats)\n",
    "    source_points = ColumnDataSource(df)\n",
    "\n",
    "    sdf = df.groupby(\"id\")[metric_i].mean().sort_values()\n",
    "    sdf_ids = sdf.index.tolist()\n",
    "\n",
    "    p = figure(\n",
    "        x_range=sdf_ids, #sorted(df[\"id\"].unique()),\n",
    "        width=1200, height=400,\n",
    "        title=f\"{metric_i} distribution per app and per folds\"\n",
    "    )\n",
    "    box_width = 0.2\n",
    "\n",
    "    p.segment(\"id\",\"max_v\",\"id\",\"q3\", source=source_box, line_width=1,line_color = 'black')\n",
    "    p.segment(\"id\",\"min_v\",\"id\",\"q1\", source=source_box, line_width=1,line_color = 'black')\n",
    "    p.vbar(\"id\", box_width, \"median_v\", \"q3\", source=source_box, line_width=2,fill_color = 'grey',fill_alpha = 0.3,line_color = 'black')\n",
    "    p.vbar(\"id\", box_width, \"q1\", \"median_v\", source=source_box, line_width=2,fill_color = 'grey',fill_alpha = 0.3,line_color = 'black')\n",
    "    #p.rect(\"id\",\"median_v\", box_width, 0, source=source_box)\n",
    "\n",
    "    palette = Category10[len(df[\"fold_str\"].unique())]\n",
    "    p.circle(\n",
    "        x=\"id\", y=metric_i,\n",
    "        source=source_points,\n",
    "        size=7,\n",
    "        line_color=\"black\",\n",
    "        fill_color=factor_cmap(\"fold_str\", palette=palette, factors=df[\"fold_str\"].unique()),\n",
    "        legend_group=\"fold_str\"\n",
    "    )\n",
    "\n",
    "    p.xaxis.axis_label = \"App\"\n",
    "    p.yaxis.axis_label = metric_i\n",
    "    p.xaxis.major_label_orientation = np.pi/2\n",
    "    p.legend.title = \"Fold\"\n",
    "    output_notebook()\n",
    "    show(p)\n",
    "\n",
    "    if save_path is not None:\n",
    "        output_file(save_path)\n",
    "        save(p)\n",
    "\n",
    "#save_path=f\"MSE_distribution_per_app_and_per_fold.html\"\n",
    "save_path = f\"MASE_distribution_per_app_and_per_fold.html\"\n",
    "metric_i = 'mase'\n",
    "plot_boxplot_on_metric(csv_with_mase,metric_i,save_path)\n",
    "\n",
    "save_path = f\"MAE_distribution_per_app_and_per_fold.html\"\n",
    "metric_i = 'mae'\n",
    "plot_boxplot_on_metric(csv_with_mase,metric_i,save_path)\n",
    "\n",
    "save_path = f\"MSE_distribution_per_app_and_per_fold.html\"\n",
    "metric_i = 'mse'\n",
    "plot_boxplot_on_metric(csv_with_mase,metric_i,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BokehDeprecationWarning: 'circle() method with size value' was deprecated in Bokeh 3.4.0 and will be removed, use 'scatter(size=...) instead' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"cefc3fce-57c6-4e03-ab30-cacbe67a34b0\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"cefc3fce-57c6-4e03-ab30-cacbe67a34b0\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.1.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"cefc3fce-57c6-4e03-ab30-cacbe67a34b0\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"edf945b6-9d63-429c-b710-2111aec0a537\" data-root-id=\"p2919\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"e3d46867-32ad-45ee-8871-b2bedf8e02c9\":{\"version\":\"3.4.1\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p2919\",\"attributes\":{\"width\":1200,\"height\":400,\"x_range\":{\"type\":\"object\",\"name\":\"FactorRange\",\"id\":\"p2929\",\"attributes\":{\"factors\":[\"Web_Weather\",\"Microsoft_Web_Services\",\"Web_Downloads\",\"Web_Games\",\"Apple_iCloud\",\"Apple_Music\",\"Microsoft_Store\",\"Apple_iMessage\",\"Microsoft_Azure\",\"Fortnite\",\"Orange_TV\",\"Apple_Video\",\"Twitch\",\"Periscope\",\"PlayStation\",\"Amazon_Web_Services\",\"Google_Play_Store\",\"Skype\",\"Web_Adult\",\"Google_Docs\",\"Wikipedia\",\"SoundCloud\",\"Waze\",\"Yahoo_Mail\",\"Tor\",\"Microsoft_Skydrive\",\"Apple_Mail\",\"Google_Mail\",\"Web_Clothes\",\"Microsoft_Office\",\"EA_Games\",\"Pokemon_GO\",\"Apple_Web_Services\",\"Google_Meet\",\"Telegram\",\"Dropbox\",\"Uber\",\"Yahoo\",\"DailyMotion\",\"Web_Streaming\",\"Web_Transportation\",\"LinkedIn\",\"Deezer\",\"Pinterest\",\"Spotify\",\"Facebook_Messenger\",\"Google_Drive\",\"Web_Finance\",\"Google_Web_Services\",\"Web_Food\",\"Apple_App_Store\",\"Netflix\",\"Apple_Siri\",\"Clash_of_Clans\",\"Molotov\",\"WhatsApp\",\"Web_e-Commerce\",\"Microsoft_Mail\",\"YouTube\",\"Apple_iTunes\",\"Web_Ads\",\"TeamViewer\",\"Twitter\",\"Instagram\",\"Google_Maps\",\"Facebook\",\"Facebook_Live\",\"Snapchat\"]}},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p2921\"},\"x_scale\":{\"type\":\"object\",\"name\":\"CategoricalScale\",\"id\":\"p2930\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p2931\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p2922\",\"attributes\":{\"text\":\"mase distribution per app and per folds\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2959\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p2913\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p2914\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p2915\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAFAAAABgAAAAcAAAAIAAAACQAAAAoAAAALAAAADAAAAA0AAAAOAAAADwAAABAAAAARAAAAEgAAABMAAAAUAAAAFQAAABYAAAAXAAAAGAAAABkAAAAaAAAAGwAAABwAAAAdAAAAHgAAAB8AAAAgAAAAIQAAACIAAAAjAAAAJAAAACUAAAAmAAAAJwAAACgAAAApAAAAKgAAACsAAAAsAAAALQAAAC4AAAAvAAAAMAAAADEAAAAyAAAAMwAAADQAAAA1AAAANgAAADcAAAA4AAAAOQAAADoAAAA7AAAAPAAAAD0AAAA+AAAAPwAAAEAAAABBAAAAQgAAAEMAAAA=\"},\"shape\":[68],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Amazon_Web_Services\",\"Apple_App_Store\",\"Apple_Mail\",\"Apple_Music\",\"Apple_Siri\",\"Apple_Video\",\"Apple_Web_Services\",\"Apple_iCloud\",\"Apple_iMessage\",\"Apple_iTunes\",\"Clash_of_Clans\",\"DailyMotion\",\"Deezer\",\"Dropbox\",\"EA_Games\",\"Facebook\",\"Facebook_Live\",\"Facebook_Messenger\",\"Fortnite\",\"Google_Docs\",\"Google_Drive\",\"Google_Mail\",\"Google_Maps\",\"Google_Meet\",\"Google_Play_Store\",\"Google_Web_Services\",\"Instagram\",\"LinkedIn\",\"Microsoft_Azure\",\"Microsoft_Mail\",\"Microsoft_Office\",\"Microsoft_Skydrive\",\"Microsoft_Store\",\"Microsoft_Web_Services\",\"Molotov\",\"Netflix\",\"Orange_TV\",\"Periscope\",\"Pinterest\",\"PlayStation\",\"Pokemon_GO\",\"Skype\",\"Snapchat\",\"SoundCloud\",\"Spotify\",\"TeamViewer\",\"Telegram\",\"Tor\",\"Twitch\",\"Twitter\",\"Uber\",\"Waze\",\"Web_Ads\",\"Web_Adult\",\"Web_Clothes\",\"Web_Downloads\",\"Web_Finance\",\"Web_Food\",\"Web_Games\",\"Web_Streaming\",\"Web_Transportation\",\"Web_Weather\",\"Web_e-Commerce\",\"WhatsApp\",\"Wikipedia\",\"Yahoo\",\"Yahoo_Mail\",\"YouTube\"],\"shape\":[68],\"dtype\":\"object\",\"order\":\"little\"}],[\"min_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAYLUU5D8AAACALYHkPwAAAEDKhuQ/AAAAIGJn5D8AAABAN5PkPwAAAODqnOQ/AAAAgNmJ5D8AAAAA/znkPwAAAMBqguQ/AAAAoHU85D8AAABAZnTkPwAAAAB9QeQ/AAAAgEk35D8AAAAAEYTkPwAAAOAkIuQ/AAAAQN2t5D8AAAAAV57kPwAAAODXMeQ/AAAAQNFH5D8AAADgLXLkPwAAAIBofeQ/AAAAgLA/5D8AAAAgKrXkPwAAAEAtSOQ/AAAAQBA25D8AAACgJFXkPwAAAEDrvOQ/AAAAoDeH5D8AAABAGQnkPwAAAMCAC+U/AAAAYBM65D8AAADATQ/kPwAAACCBBeQ/AAAAoE0M5D8AAADAVG7kPwAAACBJQ+Q/AAAAQFg05D8AAADA5e3jPwAAAGCCGOQ/AAAAQLsz5D8AAACgY+TjPwAAAOAlTOQ/AAAAAKtH5j8AAADA2nnkPwAAACBO7+M/AAAAAC2w5D8AAACAqHbkPwAAAAClheQ/AAAA4G0B5D8AAABAOI3kPwAAAMCeruQ/AAAAgHQS5D8AAACAsErkPwAAAACNQeQ/AAAA4GER5D8AAABA/RPkPwAAAMDNweQ/AAAAYKIZ5D8AAAAgrYPkPwAAAOACN+Q/AAAAgBBg5D8AAADAiULkPwAAAABtK+Q/AAAAICh05D8AAADAyT3kPwAAAIDmP+Q/AAAAQE9W5D8AAACgZb3kPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q1\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAC1z5D8AAABYnPnkPwAAADC9seQ/AAAA+PvH5D8AAAB4UvjkPwAAAOjBwOQ/AAAAAKPF5D8AAABwzqXkPwAAANDOCuU/AAAA0JjP5D8AAAA45crkPwAAALC7BuU/AAAACCr35D8AAACIT/TkPwAAAMgBwuQ/AAAA4CaB5T8AAACwJjvlPwAAANgH0+Q/AAAAaLC35D8AAAAAkxnlPwAAAAAl6+Q/AAAAuEul5D8AAAAovEXlPwAAANg9guQ/AAAA6GGk5D8AAAAYH7zkPwAAAMgGIeU/AAAAyFGy5D8AAABQEgvlPwAAABgpPOU/AAAAUEzA5D8AAACIS5fkPwAAACjDweQ/AAAA2BmS5D8AAACgJJvkPwAAAHDeIOU/AAAAaAzW5D8AAAAYGavkPwAAAPgtkOQ/AAAAEN/G5D8AAADgVvbkPwAAAJCAl+Q/AAAA4Bxe5j8AAAAosZXkPwAAALBQveQ/AAAAUGhk5T8AAABQ897kPwAAAOAOw+Q/AAAAyAut5D8AAABY3OzkPwAAAFhUF+U/AAAA4Lmy5D8AAACwGerkPwAAABB5hOQ/AAAAoLXX5D8AAACQAaTkPwAAAFgK3+Q/AAAAqFbm5D8AAABIgqfkPwAAAKj5yeQ/AAAAcEiP5D8AAAA4RXvkPwAAAIh3CeU/AAAAOC+05D8AAAA4QbvkPwAAAJi+0uQ/AAAAcPTP5D8AAABAmODkPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"median_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAwB915T8AAADgajflPwAAAJD7VOU/AAAAcEuH5T8AAAAwodflPwAAAOCNIuU/AAAAUDgd5T8AAAAAtfrkPwAAAKAmWeU/AAAAADQW5z8AAABwDyTmPwAAAHAZS+U/AAAA8F195T8AAABANWzlPwAAAMDsUOU/AAAAACKY5z8AAACwtCnmPwAAAABa3eU/AAAAUI6Q5T8AAABgZjflPwAAANCgceU/AAAAsDtZ5T8AAACw+a3lPwAAABAvS+U/AAAAIJJA5T8AAABQzeblPwAAAKAg7uU/AAAAgLRm5T8AAADwQDzlPwAAADBEhuU/AAAAIF4q5T8AAACgPFXlPwAAADCYUuU/AAAAQPz55D8AAACwO1PlPwAAABBiUuU/AAAAoFiZ5T8AAADwAZnlPwAAAPCXBuU/AAAAEOJp5T8AAADA6iPlPwAAAJBNE+U/AAAAcB3x5j8AAABACjjlPwAAABB1LuU/AAAA8Gih5j8AAABQHXflPwAAADAQT+U/AAAAkK5d5T8AAACw+PPlPwAAABBa1+U/AAAA8PEw5T8AAABQt3rlPwAAADB3BeU/AAAAsMIl5T8AAADgLi/lPwAAAMDyj+U/AAAAcI4v5T8AAADwc0jlPwAAAJDFReU/AAAAEELf5D8AAACw4gLlPwAAAOCcyeU/AAAAoAxY5T8AAABwdj3lPwAAAFDvDeU/AAAAAAZJ5T8AAACgeEHlPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"q3\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAA+HrS5z8AAAA46CvoPwAAAPiimOc/AAAA+C1o5z8AAAA4u0foPwAAAODbO+c/AAAAgAOu5z8AAABQcLjnPwAAAEBuCec/AAAAYPf15z8AAACQWzroPwAAAMgkoec/AAAA2EsZ6D8AAAAwcE/nPwAAAEgYFOg/AAAAuK206D8AAABIwYTqPwAAAGjGIeg/AAAAoKA75z8AAAAoUGbnPwAAAFBOPeg/AAAAWKu05z8AAAAwGHrpPwAAAOg7SOg/AAAAAEbR5z8AAABYKe3nPwAAADifQOg/AAAAgHgJ6D8AAADQrz/nPwAAALh1Veg/AAAAuI7a5z8AAAD41dvnPwAAAGiKd+c/AAAAECWY5z8AAAB45qfoPwAAAFDhbOg/AAAAUF8r5z8AAAAIibXnPwAAANjgeeg/AAAAOFdV5z8AAAAIuK/nPwAAAMg8Fug/AAAASDhC6T8AAABA2pTnPwAAAJj8P+g/AAAAuHkM6D8AAACooZTnPwAAAIBw0Oc/AAAAoPlt5z8AAACw/47oPwAAAPjUmec/AAAAcNvb5z8AAABoW9foPwAAAHjhwec/AAAA+OQX6D8AAABwbpHnPwAAACgTL+g/AAAAkJ6L6D8AAACwfFrnPwAAAGDKI+g/AAAA8Hul6D8AAAAY3X7nPwAAAMBIO+g/AAAAsE3z6D8AAABAdcDnPwAAABi7S+g/AAAA+DyN5z8AAAB4DqfoPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}],[\"max_v\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAYIPM6D8AAAAgjovqPwAAAIAAmOk/AAAAYNSy5z8AAADg0DHpPwAAAIArc+g/AAAAAGXt6D8AAAAAz1PoPwAAAGCcHug/AAAA4E8x6T8AAABAV2npPwAAACD/Wek/AAAA4NEd6T8AAABgZsfpPwAAAGDijOg/AAAAYBet6T8AAABg+oHrPwAAAAC/+Og/AAAAwNFZ6D8AAAAg5JjoPwAAAKCGD+k/AAAAIKy86T8AAABAZLXqPwAAACDNsOg/AAAAgC9e6D8AAACAOMnpPwAAAEBBp+o/AAAAIE1S6T8AAAAAxhHoPwAAAODCXOk/AAAAAC/p6D8AAADgCNzoPwAAACDQv+g/AAAAgDSK6D8AAADg1S/qPwAAAIB6A+o/AAAAoE9h6D8AAADAbSTpPwAAACDAz+k/AAAA4EUz6T8AAAAAdnjpPwAAAOAvN+g/AAAA4EOB6j8AAADAQsvoPwAAAAAGIuo/AAAAICcw6T8AAACghMvoPwAAAOBaj+g/AAAAQPep6T8AAADgAjHqPwAAAGCz0+c/AAAAYI7N6D8AAADgNfzqPwAAACDPQOk/AAAAwGT66D8AAAAAOVDoPwAAACA63+g/AAAAgMia6T8AAACgpfDnPwAAAODgTuk/AAAAADRV6T8AAABgSLvnPwAAAMCruOk/AAAAAJZm6T8AAACgg6noPwAAAGAKTuk/AAAAwB/q6D8AAACAc13qPw==\"},\"shape\":[68],\"dtype\":\"float64\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2960\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2961\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p2956\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p2957\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p2958\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"max_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q3\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2968\",\"attributes\":{\"data_source\":{\"id\":\"p2913\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2969\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2970\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p2965\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p2966\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Segment\",\"id\":\"p2967\",\"attributes\":{\"x0\":{\"type\":\"field\",\"field\":\"id\"},\"y0\":{\"type\":\"field\",\"field\":\"min_v\"},\"x1\":{\"type\":\"field\",\"field\":\"id\"},\"y1\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2977\",\"attributes\":{\"data_source\":{\"id\":\"p2913\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2978\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2979\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p2974\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.1},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p2975\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.1},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p2976\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.1},\"bottom\":{\"type\":\"field\",\"field\":\"q3\"},\"top\":{\"type\":\"field\",\"field\":\"median_v\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2986\",\"attributes\":{\"data_source\":{\"id\":\"p2913\"},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2987\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2988\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p2983\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.1},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p2984\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.1},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"VBar\",\"id\":\"p2985\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"width\":{\"type\":\"value\",\"value\":0.1},\"bottom\":{\"type\":\"field\",\"field\":\"median_v\"},\"top\":{\"type\":\"field\",\"field\":\"q1\"},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"value\",\"value\":\"#1f77b4\"},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p2996\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p2916\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p2917\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p2918\"},\"data\":{\"type\":\"map\",\"entries\":[[\"index\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"mse\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mase\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mae\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"mape\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"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\"},\"shape\":[680],\"dtype\":\"float64\",\"order\":\"little\"}],[\"fold\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAAAAAAAAQAAAAIAAAADAAAABAAAAAAAAAABAAAAAgAAAAMAAAAEAAAAAAAAAAEAAAACAAAAAwAAAAQAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"id\",{\"type\":\"ndarray\",\"array\":[\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Apple_Video\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Play_Store\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Google_Maps\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Web_Clothes\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Uber\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Twitter\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Mail\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Microsoft_Store\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Apple_Music\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Microsoft_Office\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Pokemon_GO\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Clash_of_Clans\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"Yahoo_Mail\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"PlayStation\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Wikipedia\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Apple_Web_Services\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Pinterest\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Web_Ads\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Mail\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Google_Meet\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Apple_Siri\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Web_Adult\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Spotify\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Deezer\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Waze\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Web_Games\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Apple_App_Store\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Microsoft_Skydrive\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Google_Docs\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Microsoft_Web_Services\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"Molotov\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"YouTube\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iTunes\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"Apple_iMessage\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"DailyMotion\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Netflix\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Transportation\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"Web_Downloads\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"SoundCloud\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"TeamViewer\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Google_Web_Services\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"Facebook\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"EA_Games\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Tor\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Amazon_Web_Services\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Web_e-Commerce\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Telegram\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Apple_Mail\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Dropbox\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Web_Food\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Apple_iCloud\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Skype\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Facebook_Messenger\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Twitch\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Microsoft_Azure\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Instagram\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Facebook_Live\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Web_Streaming\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Orange_TV\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Periscope\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Snapchat\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"Web_Finance\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"WhatsApp\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Web_Weather\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"Google_Drive\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"LinkedIn\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Yahoo\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\",\"Fortnite\"],\"shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}],[\"trial_num\",{\"type\":\"ndarray\",\"array\":{\"type\":\"bytes\",\"data\":\"AQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAEAAAABAAAAAQAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAACAAAAAgAAAAIAAAA=\"},\"shape\":[680],\"dtype\":\"int32\",\"order\":\"little\"}],[\"fold_str\",{\"type\":\"ndarray\",\"array\":[\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\",\"0\",\"1\",\"2\",\"3\",\"4\"],\"shape\":[680],\"dtype\":\"object\",\"order\":\"little\"}]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p2997\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p2998\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2993\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mase\"},\"size\":{\"type\":\"value\",\"value\":7},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"type\":\"object\",\"name\":\"CategoricalColorMapper\",\"id\":\"p2989\",\"attributes\":{\"palette\":[\"#1f77b4\",\"#ff7f0e\",\"#2ca02c\",\"#d62728\",\"#9467bd\"],\"factors\":{\"type\":\"ndarray\",\"array\":[\"0\",\"1\",\"2\",\"3\",\"4\"],\"shape\":[5],\"dtype\":\"object\",\"order\":\"little\"}}}}}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2994\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mase\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.1},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p2989\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.1},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.1}}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Scatter\",\"id\":\"p2995\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"id\"},\"y\":{\"type\":\"field\",\"field\":\"mase\"},\"size\":{\"type\":\"value\",\"value\":7},\"line_alpha\":{\"type\":\"value\",\"value\":0.2},\"fill_color\":{\"type\":\"field\",\"field\":\"fold_str\",\"transform\":{\"id\":\"p2989\"}},\"fill_alpha\":{\"type\":\"value\",\"value\":0.2},\"hatch_alpha\":{\"type\":\"value\",\"value\":0.2}}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p2928\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p2942\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p2943\",\"attributes\":{\"renderers\":\"auto\"}},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p2944\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p2945\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left\":{\"type\":\"number\",\"value\":\"nan\"},\"right\":{\"type\":\"number\",\"value\":\"nan\"},\"top\":{\"type\":\"number\",\"value\":\"nan\"},\"bottom\":{\"type\":\"number\",\"value\":\"nan\"},\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"top_units\":\"canvas\",\"bottom_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p2950\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p2951\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p2952\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p2937\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p2938\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p2939\"},\"axis_label\":\"mase\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p2940\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"CategoricalAxis\",\"id\":\"p2932\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"CategoricalTicker\",\"id\":\"p2933\"},\"formatter\":{\"type\":\"object\",\"name\":\"CategoricalTickFormatter\",\"id\":\"p2934\"},\"axis_label\":\"App\",\"major_label_orientation\":1.5707963267948966,\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p2935\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p2936\",\"attributes\":{\"axis\":{\"id\":\"p2932\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p2941\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p2937\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p2999\",\"attributes\":{\"title\":\"Fold\",\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3000\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"0\"},\"renderers\":[{\"id\":\"p2996\"}],\"index\":0}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3001\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"1\"},\"renderers\":[{\"id\":\"p2996\"}],\"index\":1}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3002\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"2\"},\"renderers\":[{\"id\":\"p2996\"}],\"index\":2}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3003\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"3\"},\"renderers\":[{\"id\":\"p2996\"}],\"index\":3}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p3004\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"4\"},\"renderers\":[{\"id\":\"p2996\"}],\"index\":4}}]}}]}}]}};\n  const render_items = [{\"docid\":\"e3d46867-32ad-45ee-8871-b2bedf8e02c9\",\"roots\":{\"p2919\":\"edf945b6-9d63-429c-b710-2111aec0a537\"},\"root_ids\":[\"p2919\"]}];\n  void root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p2919"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avancement:  0.014705882352941176\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.029411764705882353\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.04411764705882353\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.058823529411764705\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.07352941176470588\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.08823529411764706\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.10294117647058823\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.11764705882352941\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.1323529411764706\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.14705882352941177\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.16176470588235295\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.17647058823529413\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.19117647058823528\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.20588235294117646\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.22058823529411764\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.23529411764705882\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.25\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.2647058823529412\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.27941176470588236\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.29411764705882354\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.3088235294117647\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.3235294117647059\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.3382352941176471\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.35294117647058826\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.36764705882352944\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.38235294117647056\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.39705882352941174\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.4117647058823529\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.4264705882352941\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.4411764705882353\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.45588235294117646\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.47058823529411764\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.4852941176470588\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5147058823529411\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5294117647058824\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5441176470588235\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5588235294117647\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5735294117647058\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.5882352941176471\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6029411764705882\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6176470588235294\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6323529411764706\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6470588235294118\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6617647058823529\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6764705882352942\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.6911764705882353\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.7058823529411765\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.7205882352941176\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.7352941176470589\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.75\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.7647058823529411\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.7794117647058824\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.7941176470588235\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8088235294117647\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8235294117647058\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8382352941176471\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8529411764705882\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8676470588235294\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8823529411764706\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.8970588235294118\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.9117647058823529\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.9264705882352942\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.9411764705882353\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.9558823529411765\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.9705882352941176\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  0.9852941176470589\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "avancement:  1.0\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([7392, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([4597, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  481\n",
      "Netmob_T.size():  torch.Size([5069, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  485\n",
      "Netmob_T.size():  torch.Size([5549, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  559\n",
      "Netmob_T.size():  torch.Size([6179, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "Considered Spatial-Unit:  Index(['AMP', 'BEL', 'BRO', 'COR', 'CUI', 'CUS', 'FLA', 'GOR', 'BLA', 'GRA',\n",
      "       'GUI', 'GIL', 'HEN', 'HOT', 'LAE', 'MAS', 'MER', 'LUM', 'PRY', 'PER',\n",
      "       'SAN', 'SAX', 'VMY', 'JEA', 'BON', 'CHA', 'VAI', 'VEN', 'MAC', 'GAR',\n",
      "       'FOC', 'REP', 'GER', 'DEB', 'JAU', 'CPA', 'CRO', 'PAR', 'SOI', 'OGA'],\n",
      "      dtype='object', name='COD_TRG')\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "nb subway_in invalid dates:  776\n",
      "Netmob_T.size():  torch.Size([6944, 40])\n",
      "vision_input_type POIs\n",
      "vision_model_name None\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n",
      "\n",
      "NetMob Vision is NONE\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 65665\n",
      "number of trainable parameters: 65665\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pickle \n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "working_dir = os.path.abspath(os.path.join(current_path, '..','..'))\n",
    "if working_dir not in sys.path:\n",
    "    sys.path.insert(0, working_dir)\n",
    "    \n",
    "from high_level_DL_method import load_model,load_optimizer_and_scheduler\n",
    "from trainer import Trainer\n",
    "from examples.train_and_visu_non_recurrent import get_multi_ds\n",
    "from utils.metrics import evaluate_metrics\n",
    "\n",
    "# Init \n",
    "\n",
    "if False:\n",
    "    folder_name = 're_validation_epsilon100'\n",
    "\n",
    "if True:\n",
    "    folder_name = 're_validation'\n",
    "    \n",
    "save_path = f'save/K_fold_validation/training_with_HP_tuning/{folder_name}/best_models'\n",
    "model_args = pickle.load(open(f'{current_path}/{save_path}/model_args.pkl','rb'))\n",
    "trial_id = 'subway_in_subway_out_STGCN_MSELoss_2025_02_19_00_05_19271NETMOB_eps100'\n",
    "\n",
    "\n",
    "def load_trained_model(selected_model_path,ds,model_fold_i):\n",
    "    model_param = torch.load(selected_model_path)\n",
    "    args = model_args['model'][model_fold_i]['args']\n",
    "    args = Namespace(**args)\n",
    "    model = load_model(ds, args)\n",
    "    model.load_state_dict(model_param['state_dict'])\n",
    "    optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model,args)\n",
    "    trainer = Trainer(ds,model,args,optimizer,loss_function,scheduler = scheduler)\n",
    "    return trainer \n",
    "\n",
    "def get_metrics_from_test(trainer,ds,metric_list = ['mse','mae','mape','mase']):\n",
    "    Preds,Y_true,T_labels = trainer.testing(ds.normalizer)\n",
    "    dic_pred_metrics = evaluate_metrics(Preds,Y_true,metric_list)\n",
    "    return dic_pred_metrics\n",
    "\n",
    "pandas_total_results = pd.DataFrame()\n",
    "for app_ind,app in enumerate(L_Apps):\n",
    "    print('avancement: ',(app_ind+1)/len(L_Apps))\n",
    "    best_model_names = [name for name in model_args['model'].keys() if (f\"{trial_id}_{app}_f\" in name) or (f\"{trial_id}_{app}_1_f\" in name) or (f\"{trial_id}_{app}_2_f\" in name)]\n",
    "    if len(best_model_names)>5:\n",
    "        best_model_names=best_model_names[:5]\n",
    "\n",
    "    ## Load datasets: \n",
    "    # Load Args \n",
    "    # Use information from first fold to get the inputs (which app, which train/valid/test prop...):\n",
    "    args_0 = model_args['model'][best_model_names[0]]['args']\n",
    "    args_0 = Namespace(**args_0)\n",
    "    args_with_contextual,K_subway_ds = get_multi_ds(args_0.model_name, args_0.dataset_names,args_0.dataset_for_coverage,args_init = args_0,fold_to_evaluate = np.arange(args_0.K_fold))\n",
    "    # ...\n",
    "    ## ====\n",
    "\n",
    "    # With the already load ds, load now the trained model. And ds is ready for the evaluation:\n",
    "    for k_fold,model_fold_i in enumerate(best_model_names):\n",
    "        # Load trained param: \n",
    "        ds = K_subway_ds[k_fold]\n",
    "        selected_model_path = f\"{current_path}/{save_path}/{model_fold_i}.pkl\"\n",
    "        \n",
    "        # Model :\n",
    "        trainer = load_trained_model(selected_model_path,ds,model_fold_i)\n",
    "\n",
    "        # get metrics : \n",
    "        dic_pred_metrics = get_metrics_from_test(trainer,ds,metric_list = ['mse','mae','mape','mase'])\n",
    "\n",
    "        pd_local_results = pd.DataFrame(dict(mse = [dic_pred_metrics['mse']],mase = [dic_pred_metrics['mase']],mae = [dic_pred_metrics['mae']], mape = [dic_pred_metrics['mape']],\n",
    "                                            fold = [k_fold], id = [app], trial_num = [2] if 'eps' in folder_name else [1]))\n",
    "        pandas_total_results = pd.concat([pandas_total_results,pd_local_results])\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mase</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>fold</th>\n",
       "      <th>id</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1349.168945</td>\n",
       "      <td>0.764059</td>\n",
       "      <td>21.702271</td>\n",
       "      <td>44.978340</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1319.700439</td>\n",
       "      <td>0.721664</td>\n",
       "      <td>21.785254</td>\n",
       "      <td>36.126171</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1292.140625</td>\n",
       "      <td>0.661125</td>\n",
       "      <td>20.880156</td>\n",
       "      <td>29.489262</td>\n",
       "      <td>2</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1237.414062</td>\n",
       "      <td>0.657570</td>\n",
       "      <td>21.126162</td>\n",
       "      <td>30.085606</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1312.582520</td>\n",
       "      <td>0.644155</td>\n",
       "      <td>20.626852</td>\n",
       "      <td>30.769630</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356.251343</td>\n",
       "      <td>0.760964</td>\n",
       "      <td>21.611626</td>\n",
       "      <td>41.249344</td>\n",
       "      <td>0</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1346.689209</td>\n",
       "      <td>0.728087</td>\n",
       "      <td>21.977318</td>\n",
       "      <td>35.015217</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1304.612793</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>21.265333</td>\n",
       "      <td>30.248672</td>\n",
       "      <td>2</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1212.446411</td>\n",
       "      <td>0.633767</td>\n",
       "      <td>20.363184</td>\n",
       "      <td>26.443586</td>\n",
       "      <td>3</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278.229736</td>\n",
       "      <td>0.643553</td>\n",
       "      <td>20.605429</td>\n",
       "      <td>26.881651</td>\n",
       "      <td>4</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>680 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mse      mase        mae       mape  fold           id  trial_num\n",
       "0   1349.168945  0.764059  21.702271  44.978340     0  Apple_Video          1\n",
       "0   1319.700439  0.721664  21.785254  36.126171     1  Apple_Video          1\n",
       "0   1292.140625  0.661125  20.880156  29.489262     2  Apple_Video          1\n",
       "0   1237.414062  0.657570  21.126162  30.085606     3  Apple_Video          1\n",
       "0   1312.582520  0.644155  20.626852  30.769630     4  Apple_Video          1\n",
       "..          ...       ...        ...        ...   ...          ...        ...\n",
       "0   1356.251343  0.760964  21.611626  41.249344     0     Fortnite          2\n",
       "0   1346.689209  0.728087  21.977318  35.015217     1     Fortnite          2\n",
       "0   1304.612793  0.673325  21.265333  30.248672     2     Fortnite          2\n",
       "0   1212.446411  0.633767  20.363184  26.443586     3     Fortnite          2\n",
       "0   1278.229736  0.643553  20.605429  26.881651     4     Fortnite          2\n",
       "\n",
       "[680 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_with_mase = pd.concat([pandas_total_results,pandas_total_results_2])\n",
    "csv_with_mase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_with_mase.to_csv('training_netmob_metric_tabs_concat.csv')\n",
    "#pandas_total_results.to_csv('training_netmob_metric_tabs_1.csv')\n",
    "#pandas_total_results.to_csv('training_netmob_metric_tabs_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mase</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>fold</th>\n",
       "      <th>id</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1365.452881</td>\n",
       "      <td>0.759169</td>\n",
       "      <td>21.565752</td>\n",
       "      <td>43.349380</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1329.773315</td>\n",
       "      <td>0.727521</td>\n",
       "      <td>21.960958</td>\n",
       "      <td>36.967972</td>\n",
       "      <td>1</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1264.973877</td>\n",
       "      <td>0.659811</td>\n",
       "      <td>20.838892</td>\n",
       "      <td>30.041185</td>\n",
       "      <td>2</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1233.327148</td>\n",
       "      <td>0.645517</td>\n",
       "      <td>20.747341</td>\n",
       "      <td>29.113092</td>\n",
       "      <td>3</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1296.285156</td>\n",
       "      <td>0.645276</td>\n",
       "      <td>20.662750</td>\n",
       "      <td>28.951359</td>\n",
       "      <td>4</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1356.251343</td>\n",
       "      <td>0.760964</td>\n",
       "      <td>21.611626</td>\n",
       "      <td>41.249344</td>\n",
       "      <td>0</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1346.689209</td>\n",
       "      <td>0.728087</td>\n",
       "      <td>21.977318</td>\n",
       "      <td>35.015217</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1304.612793</td>\n",
       "      <td>0.673325</td>\n",
       "      <td>21.265333</td>\n",
       "      <td>30.248672</td>\n",
       "      <td>2</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1212.446411</td>\n",
       "      <td>0.633767</td>\n",
       "      <td>20.363184</td>\n",
       "      <td>26.443586</td>\n",
       "      <td>3</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1278.229736</td>\n",
       "      <td>0.643553</td>\n",
       "      <td>20.605429</td>\n",
       "      <td>26.881651</td>\n",
       "      <td>4</td>\n",
       "      <td>Fortnite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mse      mase        mae       mape  fold           id  trial_num\n",
       "0   1365.452881  0.759169  21.565752  43.349380     0  Apple_Video          2\n",
       "0   1329.773315  0.727521  21.960958  36.967972     1  Apple_Video          2\n",
       "0   1264.973877  0.659811  20.838892  30.041185     2  Apple_Video          2\n",
       "0   1233.327148  0.645517  20.747341  29.113092     3  Apple_Video          2\n",
       "0   1296.285156  0.645276  20.662750  28.951359     4  Apple_Video          2\n",
       "..          ...       ...        ...        ...   ...          ...        ...\n",
       "0   1356.251343  0.760964  21.611626  41.249344     0     Fortnite          2\n",
       "0   1346.689209  0.728087  21.977318  35.015217     1     Fortnite          2\n",
       "0   1304.612793  0.673325  21.265333  30.248672     2     Fortnite          2\n",
       "0   1212.446411  0.633767  20.363184  26.443586     3     Fortnite          2\n",
       "0   1278.229736  0.643553  20.605429  26.881651     4     Fortnite          2\n",
       "\n",
       "[340 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_total_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>mase</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>fold</th>\n",
       "      <th>id</th>\n",
       "      <th>trial_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1365.452881</td>\n",
       "      <td>0.759169</td>\n",
       "      <td>21.565752</td>\n",
       "      <td>43.34938</td>\n",
       "      <td>0</td>\n",
       "      <td>Apple_Video</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mse      mase        mae      mape  fold           id  trial_num\n",
       "0  1365.452881  0.759169  21.565752  43.34938     0  Apple_Video          2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_local_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(dict(pred= Preds[:,0,0],true = Y_true[:,0,0])).plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
