{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET PARAMETERS\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "# Get Parent folder : \n",
    "current_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from examples.train_and_visu_non_recurrent import evaluate_config,get_ds,train_the_config,get_ds_without_shuffling_on_train_set\n",
    "from plotting.plotting import error_per_station_calendar_pattern,gain_between_models\n",
    "from examples.train_model_on_k_fold_validation import load_configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> Load best CONFIG\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 2821 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 1059 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n"
     ]
    }
   ],
   "source": [
    "from high_level_DL_method import load_model,load_optimizer_and_scheduler\n",
    "from trainer import Trainer\n",
    "import torch \n",
    "\n",
    "save_folder = 'save/K_fold_validation/training_with_HP_tuning'\n",
    "add_name_id = ''\n",
    "trial_id1 ='subway_in_STGCN_MSELoss_2025_01_20_14_27_20569'\n",
    "\n",
    "args1,_ = load_configuration(trial_id1,load_config=True)\n",
    "\n",
    "fold_to_evaluate = [args1.K_fold-1]\n",
    "modification = {'shuffle':False,\n",
    "                'data_augmentation':False }\n",
    "\n",
    "\n",
    "# Load Data and Init Model:\n",
    "ds1,_,_,_,_ =  get_ds(args_init=args1,modification = modification,fold_to_evaluate=fold_to_evaluate)\n",
    "model1 = load_model(ds1, args1)\n",
    "\n",
    "\n",
    "# Load Trained Weights \n",
    "model_param1 = torch.load(f\"{save_folder}/best_models/{trial_id1}{add_name_id}_F{args1.K_fold}_fcomplete_dataset.pkl\")\n",
    "model1.load_state_dict(model_param1['state_dict'],strict=True)\n",
    "\n",
    "\n",
    "# Load Trainer : \n",
    "optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model1,args1)\n",
    "trainer1 = Trainer(ds1,model1,args1,optimizer,loss_function,scheduler = scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Metrics from trained model. Compared consistency with saved one : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>mse_complete_ds</th>\n",
       "      <th>mae_complete_ds</th>\n",
       "      <th>mape_complete_ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid</td>\n",
       "      <td>1232.723193</td>\n",
       "      <td>20.924171</td>\n",
       "      <td>36.295816</td>\n",
       "      <td>1154.631104</td>\n",
       "      <td>20.133240</td>\n",
       "      <td>33.492840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1342.555347</td>\n",
       "      <td>21.619902</td>\n",
       "      <td>34.936220</td>\n",
       "      <td>1339.509766</td>\n",
       "      <td>20.983244</td>\n",
       "      <td>31.023258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0          mse        mae       mape  mse_complete_ds  \\\n",
       "0      valid  1232.723193  20.924171  36.295816      1154.631104   \n",
       "1       test  1342.555347  21.619902  34.936220      1339.509766   \n",
       "\n",
       "   mae_complete_ds  mape_complete_ds  \n",
       "0        20.133240         33.492840  \n",
       "1        20.983244         31.023258  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE errror on test by loading trained model : 1552.68\n"
     ]
    }
   ],
   "source": [
    "training_mode = 'test'\n",
    "full_predict1,Y_true,_ = trainer1.testing(ds1.normalizer, training_mode =training_mode)\n",
    "Y_true= Y_true.detach().clone().reshape(-1)    \n",
    "full_predict1= full_predict1.detach().clone().reshape(-1)    \n",
    "error_pred1 = ((Y_true - full_predict1)**2).mean()\n",
    "\n",
    "\n",
    "df_metrics1 = pd.read_csv(f\"{save_folder}/METRICS_{trial_id1}.csv\")\n",
    "display(df_metrics1)\n",
    "print(f\"MSE errror on {training_mode} by loading trained model : {'{:.2f}'.format(error_pred1.item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problème dans les sauvegarde. On relance un test, epochs validation = 2, et on voit ce qu'on peut en re-tirer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Hyper-parameter tuning with Ray is not possible\n"
     ]
    }
   ],
   "source": [
    "# GET PARAMETERS\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "# Get Parent folder : \n",
    "current_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "    \n",
    "from examples.train_model_on_k_fold_validation import train_model_on_k_fold_validation,load_configuration\n",
    "from high_level_DL_method import load_model,load_optimizer_and_scheduler\n",
    "from trainer import Trainer\n",
    "import torch \n",
    "from constants.paths import SAVE_DIRECTORY\n",
    "from examples.train_and_visu_non_recurrent import get_ds\n",
    "\n",
    "trial_id1 ='subway_in_STGCN_MSELoss_2025_01_20_14_27_20569'\n",
    "save_folder = 'K_fold_validation/training_with_HP_tuning/re_validation'\n",
    "add_name_id = 'TEST'\n",
    "training_mode = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> Load best CONFIG\n",
      "\n",
      ">>>> Load best CONFIG\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "2821 train samples had been added thank to Data Augmentation\n",
      "calendar_dayofweek data augmented by dupplication but not modified\n",
      "calendar_hour data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([5642, 40, 7]) torch.Size([5642, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 5642 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "1059 train samples had been added thank to Data Augmentation\n",
      "calendar_dayofweek data augmented by dupplication but not modified\n",
      "calendar_hour data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2118, 40, 7]) torch.Size([2118, 40, 1])\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 2118 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 481\n",
      "\n",
      "Init Dataset: 'torch.Size([5069, 40]) with 202760 Total nb of elements and 0 Nan values\n",
      "1412 train samples had been added thank to Data Augmentation\n",
      "calendar_dayofweek data augmented by dupplication but not modified\n",
      "calendar_hour data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([2824, 40, 7]) torch.Size([2824, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3292, 40, 7])/torch.Size([3292, 40, 1]) Train/Valid/Test 2824 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 485\n",
      "\n",
      "Init Dataset: 'torch.Size([5549, 40]) with 221960 Total nb of elements and 0 Nan values\n",
      "1765 train samples had been added thank to Data Augmentation\n",
      "calendar_dayofweek data augmented by dupplication but not modified\n",
      "calendar_hour data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([3530, 40, 7]) torch.Size([3530, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3645, 40, 7])/torch.Size([3645, 40, 1]) Train/Valid/Test 3530 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 559\n",
      "\n",
      "Init Dataset: 'torch.Size([6179, 40]) with 247160 Total nb of elements and 0 Nan values\n",
      "2117 train samples had been added thank to Data Augmentation\n",
      "calendar_dayofweek data augmented by dupplication but not modified\n",
      "calendar_hour data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4234, 40, 7]) torch.Size([4234, 40, 1])\n",
      "Init U/Utarget size: torch.Size([3997, 40, 7])/torch.Size([3997, 40, 1]) Train/Valid/Test 4234 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([6944, 40]) with 277760 Total nb of elements and 0 Nan values\n",
      "2470 train samples had been added thank to Data Augmentation\n",
      "calendar_dayofweek data augmented by dupplication but not modified\n",
      "calendar_hour data augmented by dupplication but not modified\n",
      "Train/Target size:  torch.Size([4940, 40, 7]) torch.Size([4940, 40, 1])\n",
      "Init U/Utarget size: torch.Size([4350, 40, 7])/torch.Size([4350, 40, 1]) Train/Valid/Test 4940 940 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n",
      "\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.03\n",
      "Estimated time for training: 0.6min \n",
      "\n",
      "Training Throughput:896.65 sequences per seconds\n",
      ">>> Training complete in: 0:00:37.809617\n",
      ">>> Training performance time: min 0.013495922088623047 avg 0.018069028854370117 seconds (+/- 0.002043068455596163)\n",
      ">>> Loading performance time: min 0.0005567073822021484 avg 0.010502558170316471 seconds (+/- 0.022615982912647468)\n",
      ">>> Forward performance time: 0.00429779508932713 seconds (+/- 0.0005460696131662275)\n",
      ">>> Backward performance time: 0.007546288033024926 seconds (+/- 0.001547831227732689)\n",
      ">>> Plotting performance time: 7.792523032740542e-06 seconds (+/- 1.642914488779632e-05)\n",
      ">>> Saving performance time: 0.24022158980369568 seconds (+/- 0.09038678954815445)\n",
      ">>> PI-tracking performance time: 1.0553159211811267e-05 seconds (+/- 9.470901234644493e-06)\n",
      ">>> Scheduler-update performance time: 7.880361456620066e-06 seconds (+/- 7.031688394066297e-06)\n",
      ">>> Peak Power during training: 81.51 W)\n",
      ">>> Validation time: 0:00:00.122889\n",
      "Proportion of time consumed for Loading: 44.7%\n",
      "Proportion of time consumed for Forward: 18.2%\n",
      "Proportion of time consumed for Backward: 31.9%\n",
      "Proportion of time consumed for Plotting: 0.0%\n",
      "Proportion of time consumed for CheckPoint Saving: 5.2%\n",
      "Proportion of time consumed for Tracking PI: 0.0%\n",
      "Proportion of time consumed for Update Scheduler: 0.0%\n",
      "Proportion of time consumed for Read all data on GPU: 0.0%\n",
      "\n",
      "Max GPU memory allocated: 0.01694774627685547 GB\n",
      "Max GPU memory cached: 0.025390625 GB\n",
      "Max CPU memory allocated: 4.201789855957031 GB\n",
      "None\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n",
      "\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.04\n",
      "Estimated time for training: 0.9min \n",
      "\n",
      "Training Throughput:927.33 sequences per seconds\n",
      ">>> Training complete in: 0:00:44.418342\n",
      ">>> Training performance time: min 0.014087200164794922 avg 0.01671147346496582 seconds (+/- 0.0020255970241038726)\n",
      ">>> Loading performance time: min 0.0005526542663574219 avg 0.010167123705563176 seconds (+/- 0.020307791918753513)\n",
      ">>> Forward performance time: 0.004260956676976538 seconds (+/- 0.0005394626490966653)\n",
      ">>> Backward performance time: 0.0071504020433052 seconds (+/- 0.0014408783382229074)\n",
      ">>> Plotting performance time: 1.0942157946134868e-05 seconds (+/- 3.204700237192948e-05)\n",
      ">>> Saving performance time: 0.23545639855521067 seconds (+/- 0.09334045436063323)\n",
      ">>> PI-tracking performance time: 1.598659314607319e-05 seconds (+/- 1.4630693735239346e-05)\n",
      ">>> Scheduler-update performance time: 1.998951560572574e-05 seconds (+/- 2.6052216399488224e-05)\n",
      ">>> Peak Power during training: 82.095 W)\n",
      ">>> Validation time: 0:00:00.140539\n",
      "Proportion of time consumed for Loading: 45.4%\n",
      "Proportion of time consumed for Forward: 19.0%\n",
      "Proportion of time consumed for Backward: 31.8%\n",
      "Proportion of time consumed for Plotting: 0.0%\n",
      "Proportion of time consumed for CheckPoint Saving: 3.8%\n",
      "Proportion of time consumed for Tracking PI: 0.0%\n",
      "Proportion of time consumed for Update Scheduler: 0.0%\n",
      "Proportion of time consumed for Read all data on GPU: 0.0%\n",
      "\n",
      "Max GPU memory allocated: 0.01694774627685547 GB\n",
      "Max GPU memory cached: 0.025390625 GB\n",
      "Max CPU memory allocated: 4.20233154296875 GB\n",
      "None\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n",
      "\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.05\n",
      "Estimated time for training: 0.9min \n",
      "\n",
      "Training Throughput:934.79 sequences per seconds\n",
      ">>> Training complete in: 0:00:52.891652\n",
      ">>> Training performance time: min 0.013413190841674805 avg 0.016600847244262695 seconds (+/- 0.00207660926433654)\n",
      ">>> Loading performance time: min 0.0005495548248291016 avg 0.009522193109734579 seconds (+/- 0.01835093435561694)\n",
      ">>> Forward performance time: 0.0042358618474804665 seconds (+/- 0.0004805667000916732)\n",
      ">>> Backward performance time: 0.0070557327098351484 seconds (+/- 0.0015523833136680926)\n",
      ">>> Plotting performance time: 1.140644675806949e-05 seconds (+/- 3.099830147070302e-05)\n",
      ">>> Saving performance time: 0.25157668590545657 seconds (+/- 0.08415972240287378)\n",
      ">>> PI-tracking performance time: 2.029067591616982e-05 seconds (+/- 2.1719987616854353e-05)\n",
      ">>> Scheduler-update performance time: 7.466266029759457e-06 seconds (+/- 7.574712328844925e-06)\n",
      ">>> Peak Power during training: 82.388 W)\n",
      ">>> Validation time: 0:00:00.149971\n",
      "Proportion of time consumed for Loading: 43.6%\n",
      "Proportion of time consumed for Forward: 19.4%\n",
      "Proportion of time consumed for Backward: 32.2%\n",
      "Proportion of time consumed for Plotting: 0.0%\n",
      "Proportion of time consumed for CheckPoint Saving: 4.8%\n",
      "Proportion of time consumed for Tracking PI: 0.0%\n",
      "Proportion of time consumed for Update Scheduler: 0.0%\n",
      "Proportion of time consumed for Read all data on GPU: 0.0%\n",
      "\n",
      "Max GPU memory allocated: 0.01694774627685547 GB\n",
      "Max GPU memory cached: 0.025390625 GB\n",
      "Max CPU memory allocated: 4.202991485595703 GB\n",
      "None\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n",
      "\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.05\n",
      "Estimated time for training: 1.1min \n",
      "\n",
      "Training Throughput:898.51 sequences per seconds\n",
      ">>> Training complete in: 0:01:03.176730\n",
      ">>> Training performance time: min 0.013666152954101562 avg 0.018144607543945312 seconds (+/- 0.002128405469470878)\n",
      ">>> Loading performance time: min 0.0005404949188232422 avg 0.010043113704815138 seconds (+/- 0.018090985990894315)\n",
      ">>> Forward performance time: 0.004274247961299733 seconds (+/- 0.0006463589249604551)\n",
      ">>> Backward performance time: 0.007608835448677134 seconds (+/- 0.0015388414276688376)\n",
      ">>> Plotting performance time: 7.290589182000411e-06 seconds (+/- 1.8964366820576264e-05)\n",
      ">>> Saving performance time: 0.24574223431673917 seconds (+/- 0.07442759704199718)\n",
      ">>> PI-tracking performance time: 2.3440310829564143e-05 seconds (+/- 2.7832865656896602e-05)\n",
      ">>> Scheduler-update performance time: 1.662655880576686e-05 seconds (+/- 2.013113792418905e-05)\n",
      ">>> Peak Power during training: 82.199 W)\n",
      ">>> Validation time: 0:00:00.142788\n",
      "Proportion of time consumed for Loading: 44.0%\n",
      "Proportion of time consumed for Forward: 18.7%\n",
      "Proportion of time consumed for Backward: 33.2%\n",
      "Proportion of time consumed for Plotting: 0.0%\n",
      "Proportion of time consumed for CheckPoint Saving: 4.2%\n",
      "Proportion of time consumed for Tracking PI: 0.0%\n",
      "Proportion of time consumed for Update Scheduler: 0.0%\n",
      "Proportion of time consumed for Read all data on GPU: 0.0%\n",
      "\n",
      "Max GPU memory allocated: 0.01694774627685547 GB\n",
      "Max GPU memory cached: 0.025390625 GB\n",
      "Max CPU memory allocated: 4.203239440917969 GB\n",
      "None\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n",
      "\n",
      "start training\n",
      "epoch: 0 \n",
      " min\\epoch : 0.07\n",
      "Estimated time for training: 1.0min \n",
      "\n",
      "Training Throughput:904.48 sequences per seconds\n",
      ">>> Training complete in: 0:01:10.253801\n",
      ">>> Training performance time: min 0.013626337051391602 avg 0.017955303192138672 seconds (+/- 0.002127620045193375)\n",
      ">>> Loading performance time: min 0.0005548000335693359 avg 0.009946171482975096 seconds (+/- 0.01966959999481725)\n",
      ">>> Forward performance time: 0.004239295559031844 seconds (+/- 0.0005813467149311769)\n",
      ">>> Backward performance time: 0.007553493953013898 seconds (+/- 0.0015691226371949518)\n",
      ">>> Plotting performance time: 9.61203324167352e-06 seconds (+/- 2.769407228597636e-05)\n",
      ">>> Saving performance time: 0.24082854390144348 seconds (+/- 0.08775653527454447)\n",
      ">>> PI-tracking performance time: 1.2159347534179688e-05 seconds (+/- 8.553039711995525e-06)\n",
      ">>> Scheduler-update performance time: 7.077267295435856e-06 seconds (+/- 2.913919464305838e-06)\n",
      ">>> Peak Power during training: 84.878 W)\n",
      ">>> Validation time: 0:00:00.123589\n",
      "Proportion of time consumed for Loading: 44.5%\n",
      "Proportion of time consumed for Forward: 18.9%\n",
      "Proportion of time consumed for Backward: 33.7%\n",
      "Proportion of time consumed for Plotting: 0.0%\n",
      "Proportion of time consumed for CheckPoint Saving: 2.8%\n",
      "Proportion of time consumed for Tracking PI: 0.0%\n",
      "Proportion of time consumed for Update Scheduler: 0.0%\n",
      "Proportion of time consumed for Read all data on GPU: 0.0%\n",
      "\n",
      "Max GPU memory allocated: 0.01694774627685547 GB\n",
      "Max GPU memory cached: 0.025390625 GB\n",
      "Max CPU memory allocated: 4.203239440917969 GB\n",
      "None\n",
      "df metrics:                 mse        mae       mape       VAR_mse   VAR_mae   VAR_mape  \\\n",
      "valid  1355.812744  22.050191  37.273778  10327.583649  0.829619   7.010509   \n",
      "test   1441.176343  22.780031  35.824788   6613.209349  0.615906  25.654875   \n",
      "\n",
      "       mse_complete_ds  mae_complete_ds  mape_complete_ds  \n",
      "valid      1451.416382        22.981207         37.514351  \n",
      "test       1508.671997        22.972397         32.952045  \n"
     ]
    }
   ],
   "source": [
    "epochs_validation = 20\n",
    "# Re-train the model: \n",
    "args1,folds = load_configuration(trial_id1,True)\n",
    "\n",
    "modification ={'keep_best_weights':True,\n",
    "                'epochs':epochs_validation,\n",
    "                'device':torch.device(\"cuda:1\"),\n",
    "                }\n",
    "\n",
    "train_model_on_k_fold_validation(trial_id1,load_config =True,\n",
    "                                    save_folder=save_folder,\n",
    "                                    modification=modification,\n",
    "                                    add_name_id=add_name_id)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> Load best CONFIG\n",
      ">>>>Model: STGCN; K_fold = 6; Loss function: MSE \n",
      "Invalid dates within this fold: 776\n",
      "\n",
      "Init Dataset: 'torch.Size([7392, 40]) with 295680 Total nb of elements and 0 Nan values\n",
      "Init U/Utarget size: torch.Size([4702, 40, 7])/torch.Size([4702, 40, 1]) Train/Valid/Test 2821 940 940\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid dates within this fold: 481\n",
      "\n",
      "Init Dataset: 'torch.Size([4597, 40]) with 183880 Total nb of elements and 0 Nan values\n",
      "Init U/Utarget size: torch.Size([2940, 40, 7])/torch.Size([2940, 40, 1]) Train/Valid/Test 1059 941 939\n",
      "\n",
      " ===== ERROR WITH prefetch_factor====  \n",
      "ValueError: prefetch_factor option could only be specified in multiprocessing.let num_workers > 0 to enable multiprocessing\n",
      "Model size: 0.000GB\n",
      "number of total parameters: 71713\n",
      "number of trainable parameters: 71713\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mse</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>VAR_mse</th>\n",
       "      <th>VAR_mae</th>\n",
       "      <th>VAR_mape</th>\n",
       "      <th>mse_complete_ds</th>\n",
       "      <th>mae_complete_ds</th>\n",
       "      <th>mape_complete_ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>valid</td>\n",
       "      <td>1355.812744</td>\n",
       "      <td>22.050191</td>\n",
       "      <td>37.273778</td>\n",
       "      <td>10327.583649</td>\n",
       "      <td>0.829619</td>\n",
       "      <td>7.010509</td>\n",
       "      <td>1451.416382</td>\n",
       "      <td>22.981207</td>\n",
       "      <td>37.514351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>1441.176343</td>\n",
       "      <td>22.780031</td>\n",
       "      <td>35.824788</td>\n",
       "      <td>6613.209349</td>\n",
       "      <td>0.615906</td>\n",
       "      <td>25.654875</td>\n",
       "      <td>1508.671997</td>\n",
       "      <td>22.972397</td>\n",
       "      <td>32.952045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0          mse        mae       mape       VAR_mse   VAR_mae  \\\n",
       "0      valid  1355.812744  22.050191  37.273778  10327.583649  0.829619   \n",
       "1       test  1441.176343  22.780031  35.824788   6613.209349  0.615906   \n",
       "\n",
       "    VAR_mape  mse_complete_ds  mae_complete_ds  mape_complete_ds  \n",
       "0   7.010509      1451.416382        22.981207         37.514351  \n",
       "1  25.654875      1508.671997        22.972397         32.952045  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE errror on valid by loading trained model : 1451.42\n"
     ]
    }
   ],
   "source": [
    "### Once the model with this config is re-trained, load the saved parameter and check the consistency of the results:\n",
    "args1,_ = load_configuration(trial_id1,load_config=True)\n",
    "\n",
    "fold_to_evaluate = [args1.K_fold-1]\n",
    "modification = {'shuffle':False,\n",
    "                'data_augmentation':False }\n",
    "\n",
    "# Load Data and Init Model:\n",
    "ds1,_,_,_,_ =  get_ds(args_init=args1,modification = modification,fold_to_evaluate=fold_to_evaluate)\n",
    "model1 = load_model(ds1, args1)\n",
    "\n",
    "\n",
    "# Load Trained Weights \n",
    "model_param1 = torch.load(f\"{current_path}/{SAVE_DIRECTORY}/{save_folder}/best_models/{trial_id1}{add_name_id}_fcomplete_dataset.pkl\")\n",
    "model1.load_state_dict(model_param1['state_dict'],strict=True)\n",
    "\n",
    "# Load Trainer : \n",
    "optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model1,args1)\n",
    "trainer1 = Trainer(ds1,model1,args1,optimizer,loss_function,scheduler = scheduler)\n",
    "\n",
    "\n",
    "full_predict1,Y_true,_ = trainer1.testing(ds1.normalizer, training_mode =training_mode)\n",
    "Y_true= Y_true.detach().clone().reshape(-1)    \n",
    "full_predict1= full_predict1.detach().clone().reshape(-1)    \n",
    "error_pred1 = ((Y_true - full_predict1)**2).mean()\n",
    "\n",
    "\n",
    "df_metrics1 = pd.read_csv(f\"{current_path}/{SAVE_DIRECTORY}/{save_folder}/METRICS_{trial_id1}TEST.csv\")\n",
    "display(df_metrics1)\n",
    "print(f\"MSE errror on {training_mode} by loading trained model : {'{:.2f}'.format(error_pred1.item())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fold0</th>\n",
       "      <th>fold1</th>\n",
       "      <th>fold2</th>\n",
       "      <th>fold3</th>\n",
       "      <th>fold4</th>\n",
       "      <th>mean</th>\n",
       "      <th>complete_dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002472</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     fold0     fold1     fold2     fold3     fold4      mean  \\\n",
       "0           0  0.002939  0.002472  0.002494  0.002592  0.002877  0.002675   \n",
       "\n",
       "   complete_dataset  \n",
       "0          0.002877  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE errror on valid by loading trained model : 0.002877\n"
     ]
    }
   ],
   "source": [
    "training_mode = 'valid'\n",
    "full_predict1,Y_true,_ = trainer1.testing(None, training_mode =training_mode)\n",
    "Y_true= Y_true.detach().clone().reshape(-1)    \n",
    "full_predict1= full_predict1.detach().clone().reshape(-1)    \n",
    "error_pred1 = ((Y_true - full_predict1)**2).mean()\n",
    "\n",
    "\n",
    "df_metrics1 = pd.read_csv(f\"{current_path}/{SAVE_DIRECTORY}/{save_folder}/VALID_{trial_id1}TEST.csv\")\n",
    "display(df_metrics1)\n",
    "print(f\"MSE errror on {training_mode} by loading trained model : {'{:.6f}'.format(error_pred1.item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load l'entrainement, et vérifie que les métriques sont cohérentes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from high_level_DL_method import load_model,load_optimizer_and_scheduler\n",
    "from trainer import Trainer\n",
    "import torch \n",
    "\n",
    "args1,_ = load_configuration(trial_id1,load_config=True)\n",
    "fold_to_evaluate = [args1.K_fold-1]\n",
    "modification = {'shuffle':False,\n",
    "                'data_augmentation':False }\n",
    "\n",
    "ds1,_,_,_,_ =  get_ds(args_init=args1,modification = modification,fold_to_evaluate=fold_to_evaluate)\n",
    "model1 = load_model(ds1, args1)\n",
    "\n",
    "\n",
    "optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model1,args1)\n",
    "trainer1 = Trainer(ds1,model1,args1,optimizer,loss_function,scheduler = scheduler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_id = subway_in_STGCN_MSELoss_2025_01_20_14_40_26118_F6_fcomplete_dataset\n",
    "weights_id = 'subway_in_STGCN_MSELoss_2025_01_17_18_31_60147_F6_fcomplete_dataset'\n",
    "for weights_id in ['subway_in_STGCN_MSELoss_2025_01_17_18_31_60147_F6_fcomplete_dataset',\n",
    "                   'subway_in_STGCN_MSELoss_2025_01_20_14_40_26118_F6_fcomplete_dataset',\n",
    "                   'subway_in_STGCN_MSELoss_2025_01_17_15_14_85172_F6_fcomplete_dataset',\n",
    "                   'subway_in_STGCN_MSELoss_2025_01_06_08_04_25065_F6_fcomplete_dataset']:\n",
    "    \n",
    "    model_param1 = torch.load(f\"save/K_fold_validation/training_with_HP_tuning/best_models/{weights_id}.pkl\")\n",
    "    model1.load_state_dict(model_param1['state_dict'],strict=True)\n",
    "\n",
    "    optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model1,args1)\n",
    "    trainer1 = Trainer(ds1,model1,args1,optimizer,loss_function,scheduler = scheduler)\n",
    "\n",
    "    training_mode = 'test'\n",
    "    full_predict1,Y_true,_ = trainer1.testing(ds1.normalizer, training_mode =training_mode)\n",
    "    Y_true= Y_true.detach().clone().reshape(-1)    \n",
    "    full_predict1= full_predict1.detach().clone().reshape(-1)    \n",
    "    error_pred1 = ((Y_true - full_predict1)**2).mean()\n",
    "\n",
    "    print(error_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "training_mode_to_visualise = ['test']\n",
    "station = ['PAR','PER','GER','BON']\n",
    "for training_mode in training_mode_to_visualise:\n",
    "    min_flow = 20  # Minimal Flow considered for MAPE, otherwise set error = 0\n",
    "    limit_percentage_error = 200 # 300% plus mauvais que quand on se sert du previous \n",
    "    fig,axes = error_per_station_calendar_pattern(trainer,ds,training_mode,metrics = ['mse','mae','mape','previous_value'],\n",
    "                                                freq='1h',\n",
    "                                                min_flow=min_flow,\n",
    "                                                figsize = (30,5*len(station)),\n",
    "                                                limit_percentage_error = limit_percentage_error,\n",
    "                                                stations = station)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id2 ='subway_in_subway_out_STGCN_VariableSelectionNetwork_MSELoss_2025_01_20_05_38_87836' #Concate Early & Late\n",
    "\n",
    "args2,_ = load_configuration(trial_id2,load_config=True)\n",
    "\n",
    "fold_to_evaluate = [args2.K_fold-1]\n",
    "modification = {'shuffle':False,\n",
    "                'data_augmentation':False }\n",
    "\n",
    "ds2,_,_,_,_ =  get_ds(args_init=args2,modification = modification,fold_to_evaluate=fold_to_evaluate)\n",
    "model2 = load_model(ds2, args2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_id = 'subway_in_subway_out_STGCN_VariableSelectionNetwork_MSELoss_2025_01_20_07_23_40226_F6_fcomplete_dataset'\n",
    "model_param2 = torch.load(f\"save/K_fold_validation/training_with_HP_tuning/best_models/{weights_id}.pkl\")\n",
    "model2.load_state_dict(model_param2['state_dict'],strict=True)\n",
    "\n",
    "optimizer,scheduler,loss_function = load_optimizer_and_scheduler(model2,args2)\n",
    "trainer2 = Trainer(ds2,model2,args2,optimizer,loss_function,scheduler = scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain de Model2 par rapport à Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_mode = 'test'\n",
    "full_predict1,Y_true,_ = trainer1.testing(ds1.normalizer, training_mode =training_mode)\n",
    "full_predict2,_,_ = trainer2.testing(ds2.normalizer, training_mode =training_mode)\n",
    "\n",
    "Y_true= Y_true.detach().clone().reshape(-1)    \n",
    "full_predict1= full_predict1.detach().clone().reshape(-1)    \n",
    "full_predict2= full_predict2.detach().clone().reshape(-1)   \n",
    "\n",
    "error_pred1 = ((Y_true - full_predict1)**2).mean()\n",
    "error_pred2 = ((Y_true - full_predict2)**2).mean()\n",
    "\n",
    "print(error_pred1,error_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = list(ds.spatial_unit) #['PAR','PER','GER','BON']\n",
    "gain_between_models(trainer,trainer2,ds,ds2,training_mode,\n",
    "                         metrics = ['mse','mae','mape'],\n",
    "                        freq='1h',\n",
    "                        index_matshow = 'day_date',\n",
    "                        columns_matshow = 'hour',\n",
    "                        min_flow = 20,\n",
    "                        figsize = (30,5*len(station)),\n",
    "                        limit_percentage_error = 50,\n",
    "                        acceptable_error = 10,\n",
    "                        stations = station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = ['PAR','PER','GER','BON']\n",
    "gain_between_models(trainer,trainer2,ds,ds2,training_mode,\n",
    "                         metrics = ['mse','mae','mape'],\n",
    "                        freq='1h',\n",
    "                        index_matshow = 'day_date',\n",
    "                        columns_matshow = 'hour',\n",
    "                        min_flow = 20,\n",
    "                        figsize = (30,5*len(station)),\n",
    "                        limit_percentage_error = 50,\n",
    "                        acceptable_error = 10,\n",
    "                        stations = station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'subway_in_STGCN_MSELoss_2025_01_06_08_00_94523',\n",
    "#\"subway_in_netmob_POIs_STGCN_VariableSelectionNetwork_MSELoss_2025_01_09_07_54_72902\" # contient  Instagram, Google Maps, Deezer, WhatsApps, Twiteter, DL, UL\n",
    "trial_id ='subway_in_STGCN_MSELoss_2025_01_20_14_27_20569'\n",
    "args,_ = load_configuration(trial_id,load_config=True,epochs=None)\n",
    "\n",
    "fold_to_evaluate = [0,args.K_fold-1]\n",
    "modification = {'shuffle':False,\n",
    "                'data_augmentation':False }\n",
    "\n",
    "# Load Best Model of config 'trial_id':\n",
    "\n",
    "trainer,ds,args,trial_id,df_loss = train_the_config(args,modification,fold_to_evaluate)\n",
    "trainer,ds_no_shuffle = get_ds_without_shuffling_on_train_set(trainer,modification,args,fold_to_evaluate)\n",
    "\n",
    "station = ['BEL','PER','PAR','GER','CHA']   # 'BON'  #'GER'\n",
    "training_mode_to_visualise = ['test']#,'valid','train']\n",
    "modification ={'keep_best_weights':True,\n",
    "                'epochs':100,\n",
    "                'validation_split_method' : 'forward_chaining_cv',\n",
    "                'min_fold_size_proportion': 0.75,\n",
    "                'train_prop':0.6,\n",
    "                'valid_prop':0.2,\n",
    "                'test_prop':0.2,\n",
    "\n",
    "                'set_spatial_units':station,\n",
    "        \n",
    "                'data_augmentation': True, #True,  #False\n",
    "                'DA_method':'interpolation', # 'noise' # 'interpolation\n",
    "                'DA_moment_to_focus' : None, #[{'hours':[0,23],'weekdays':[1,3]}], # None\n",
    "                }\n",
    "if False:\n",
    "    ds,args_modif,trial_id,save_folder,df_loss = get_ds(args.model_name,args.dataset_names,args.dataset_for_coverage,\n",
    "                                                modification=modification,args_init=args,fold_to_evaluate=[args.K_fold-1])\n",
    "\n",
    "(trainer,ds,ds_no_shuffle,args) = evaluate_config(args_best_model.model_name,args_best_model.dataset_names,args_best_model.dataset_for_coverage,\n",
    "                                                station = station,\n",
    "                                                modification=modification,\n",
    "                                                training_mode_to_visualise=training_mode_to_visualise,\n",
    "                                                args_init =args_best_model,\n",
    "                                                fold_to_evaluate =[args_best_model.K_fold-1])\n",
    "\n",
    "# Init\n",
    "for training_mode in training_mode_to_visualise:\n",
    "    min_flow = 20  # Minimal Flow considered for MAPE, otherwise set error = 0\n",
    "    limit_percentage_error = 200 # 300% plus mauvais que quand on se sert du previous \n",
    "    fig,axes = error_per_station_calendar_pattern(trainer,ds,training_mode,metrics = ['mse','mae','mape','previous_value'],\n",
    "                                                freq='1h',\n",
    "                                                min_flow=min_flow,\n",
    "                                                figsize = (30,5*len(station)),\n",
    "                                                limit_percentage_error = limit_percentage_error,\n",
    "                                                stations = station)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET PARAMETERS\n",
    "import os \n",
    "import sys\n",
    "import torch \n",
    "# Get Parent folder : \n",
    "current_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from examples.train_model_on_k_fold_validation import train_model_on_k_fold_validation,load_configuration\n",
    "\n",
    "\n",
    "save_folder = 'K_fold_validation/training_with_HP_tuning/re_validation'\n",
    "trial_id = 'subway_in_STGCN_MSELoss_2025_01_20_14_27_20569'\n",
    "name_trial = 'TEST'\n",
    "epochs_validation = 1\n",
    "args,folds = load_configuration(trial_id,True)\n",
    "\n",
    "modification ={'keep_best_weights':True,\n",
    "                'epochs':epochs_validation,\n",
    "                'device':torch.device(\"cuda:1\"),\n",
    "                }\n",
    "\n",
    "\n",
    "config_diffs = {name_trial:{}}\n",
    "\n",
    "                \n",
    "for add_name_id,config_diff in config_diffs.items():\n",
    "    config_diff.update(modification)\n",
    "    train_model_on_k_fold_validation(trial_id,load_config =True,\n",
    "                                        save_folder=save_folder,\n",
    "                                        modification=config_diff,\n",
    "                                        add_name_id=add_name_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
