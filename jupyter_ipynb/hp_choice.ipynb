{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtenir le chemin du dossier parent\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "# current_path = os.path.dirname()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "\n",
    "# Ajouter le dossier parent au chemin de recherche des modules\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'pynvml' is not available on this environment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from utils.utilities_DL import get_MultiModel_loss_args_emb_opts,load_init_trainer,load_prediction\n",
    "from trainer import Trainer\n",
    "from constants.config import get_args,update_modif\n",
    "from constants.paths import folder_path,file_name,SAVE_DIRECTORY\n",
    "\n",
    "from HP_tuning.ray_search_space import get_search_space_ray \n",
    "from HP_tuning.ray_config import get_ray_config\n",
    "import ray \n",
    "from ray import tune \n",
    "import os \n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: STGCN, K_fold = 5\n",
      "!!! Loss function: MSE \n"
     ]
    }
   ],
   "source": [
    "from high_level_DL_method import load_everything \n",
    "from utils.utilities_DL import match_period_coverage_with_netmob,get_small_ds\n",
    "\n",
    "# Load config\n",
    "model_name = 'STGCN' #'CNN'\n",
    "args = get_args(model_name)\n",
    "\n",
    "# Modification : \n",
    "args.K_fold = 5\n",
    "args.ray = True\n",
    "args.W = 0  # IMPORTANT AVEC NETMOB\n",
    "args.epochs = 1\n",
    "args.loss_function_type = 'MSE' # 'quantile'\n",
    "args.mixed_precision = False\n",
    "args.torch_compile = False\n",
    "\n",
    "args = update_modif(args)\n",
    "\n",
    "# Coverage Period : \n",
    "small_ds = False\n",
    "coverage = match_period_coverage_with_netmob(file_name)\n",
    "(coverage,args) = get_small_ds(small_ds,coverage,args)\n",
    "\n",
    "# Choose DataSet and VisionModel if needed: \n",
    "dataset_names = ['netmob'] # ['calendar','netmob'] #['subway_in','netmob','calendar']\n",
    "vision_model_name = 'ImageAvgPooling'  # 'ImageAvgPooling'  #'FeatureExtractor_ResNetInspired' #'MinimalFeatureExtractor',\n",
    "\n",
    "# Train and Evaluate Model: \n",
    "mod_plot = 1 # bokeh plotting every epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold n°0\n",
      "Time-step per hour: 4.0\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-04-16 03:45:00\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2896, 40, 7]) Utarget size:  torch.Size([2896, 40, 1])\n",
      "U_train size:  torch.Size([2177, 40, 7]) Utarget_train size:  torch.Size([2177, 40, 1])\n",
      "U_valid size:  torch.Size([622, 40, 7]) Utarget_valid size:  torch.Size([622, 40, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(0.) U_valid max:  tensor(1.1906)\n",
      "Load des données NetMob .pt impossible. Création d'un random Tensor\n",
      "Init NetMob Dataset:  torch.Size([2992, 40, 2, 8, 8])\n",
      "Number of Nan Value:  tensor(0)\n",
      "Total Number of Elements:  15319040 \n",
      "\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2896, 40, 2, 8, 8, 7]) Utarget size:  torch.Size([2896, 40, 2, 8, 8, 1])\n",
      "U_train size:  torch.Size([2177, 40, 2, 8, 8, 7]) Utarget_train size:  torch.Size([2177, 40, 2, 8, 8, 1])\n",
      "U_valid size:  torch.Size([622, 40, 2, 8, 8, 7]) Utarget_valid size:  torch.Size([622, 40, 2, 8, 8, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(-0.1239) U_valid max:  tensor(1.0549)\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "Fold n°1\n",
      "Time-step per hour: 4.0\n",
      "coverage period: 2019-03-23 19:00:00 - 2019-04-23 22:45:00\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2860, 40, 7]) Utarget size:  torch.Size([2860, 40, 1])\n",
      "U_train size:  torch.Size([2149, 40, 7]) Utarget_train size:  torch.Size([2149, 40, 1])\n",
      "U_valid size:  torch.Size([614, 40, 7]) Utarget_valid size:  torch.Size([614, 40, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(0.) U_valid max:  tensor(1.4270)\n",
      "Load des données NetMob .pt impossible. Création d'un random Tensor\n",
      "Init NetMob Dataset:  torch.Size([2992, 40, 2, 8, 8])\n",
      "Number of Nan Value:  tensor(0)\n",
      "Total Number of Elements:  15319040 \n",
      "\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2860, 40, 2, 8, 8, 7]) Utarget size:  torch.Size([2860, 40, 2, 8, 8, 1])\n",
      "U_train size:  torch.Size([2149, 40, 2, 8, 8, 7]) Utarget_train size:  torch.Size([2149, 40, 2, 8, 8, 1])\n",
      "U_valid size:  torch.Size([614, 40, 2, 8, 8, 7]) Utarget_valid size:  torch.Size([614, 40, 2, 8, 8, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(-0.0739) U_valid max:  tensor(1.0818)\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "Fold n°2\n",
      "Time-step per hour: 4.0\n",
      "coverage period: 2019-03-31 14:00:00 - 2019-05-01 17:45:00\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2319, 40, 7]) Utarget size:  torch.Size([2319, 40, 1])\n",
      "U_train size:  torch.Size([1722, 40, 7]) Utarget_train size:  torch.Size([1722, 40, 1])\n",
      "U_valid size:  torch.Size([500, 40, 7]) Utarget_valid size:  torch.Size([500, 40, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(0.) U_valid max:  tensor(1.3063)\n",
      "Load des données NetMob .pt impossible. Création d'un random Tensor\n",
      "Init NetMob Dataset:  torch.Size([2992, 40, 2, 8, 8])\n",
      "Number of Nan Value:  tensor(0)\n",
      "Total Number of Elements:  15319040 \n",
      "\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2319, 40, 2, 8, 8, 7]) Utarget size:  torch.Size([2319, 40, 2, 8, 8, 1])\n",
      "U_train size:  torch.Size([1722, 40, 2, 8, 8, 7]) Utarget_train size:  torch.Size([1722, 40, 2, 8, 8, 1])\n",
      "U_valid size:  torch.Size([500, 40, 2, 8, 8, 7]) Utarget_valid size:  torch.Size([500, 40, 2, 8, 8, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(-0.0801) U_valid max:  tensor(1.0627)\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "Fold n°3\n",
      "Time-step per hour: 4.0\n",
      "coverage period: 2019-04-08 09:00:00 - 2019-05-09 12:45:00\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2319, 40, 7]) Utarget size:  torch.Size([2319, 40, 1])\n",
      "U_train size:  torch.Size([1722, 40, 7]) Utarget_train size:  torch.Size([1722, 40, 1])\n",
      "U_valid size:  torch.Size([500, 40, 7]) Utarget_valid size:  torch.Size([500, 40, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(0.) U_valid max:  tensor(1.2274)\n",
      "Load des données NetMob .pt impossible. Création d'un random Tensor\n",
      "Init NetMob Dataset:  torch.Size([2992, 40, 2, 8, 8])\n",
      "Number of Nan Value:  tensor(0)\n",
      "Total Number of Elements:  15319040 \n",
      "\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2319, 40, 2, 8, 8, 7]) Utarget size:  torch.Size([2319, 40, 2, 8, 8, 1])\n",
      "U_train size:  torch.Size([1722, 40, 2, 8, 8, 7]) Utarget_train size:  torch.Size([1722, 40, 2, 8, 8, 1])\n",
      "U_valid size:  torch.Size([500, 40, 2, 8, 8, 7]) Utarget_valid size:  torch.Size([500, 40, 2, 8, 8, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(-0.1011) U_valid max:  tensor(1.0689)\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "Fold n°4\n",
      "Time-step per hour: 4.0\n",
      "coverage period: 2019-04-16 04:00:00 - 2019-05-17 08:00:00\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2320, 40, 7]) Utarget size:  torch.Size([2320, 40, 1])\n",
      "U_train size:  torch.Size([1729, 40, 7]) Utarget_train size:  torch.Size([1729, 40, 1])\n",
      "U_valid size:  torch.Size([494, 40, 7]) Utarget_valid size:  torch.Size([494, 40, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(0.) U_valid max:  tensor(1.8409)\n",
      "Load des données NetMob .pt impossible. Création d'un random Tensor\n",
      "Init NetMob Dataset:  torch.Size([2993, 40, 2, 8, 8])\n",
      "Number of Nan Value:  tensor(0)\n",
      "Total Number of Elements:  15324160 \n",
      "\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([2320, 40, 2, 8, 8, 7]) Utarget size:  torch.Size([2320, 40, 2, 8, 8, 1])\n",
      "U_train size:  torch.Size([1729, 40, 2, 8, 8, 7]) Utarget_train size:  torch.Size([1729, 40, 2, 8, 8, 1])\n",
      "U_valid size:  torch.Size([494, 40, 2, 8, 8, 7]) Utarget_valid size:  torch.Size([494, 40, 2, 8, 8, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(-0.1031) U_valid max:  tensor(1.0611)\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n"
     ]
    }
   ],
   "source": [
    "from build_inputs.load_subway_in import load_subway_in\n",
    "from build_inputs.load_preprocessed_dataset import load_complete_ds\n",
    "from dataset import TensorDataset\n",
    "\n",
    "\n",
    "def add_U_test_and_Utarget_test(subway_ds_tmps,subway_ds):\n",
    "    ''' Tackle U_test and Utarget_test'''\n",
    "    U_test_tmps = TensorDataset(subway_ds.U_test, normalized = False, normalizer=subway_ds_tmps.normalizer)\n",
    "    U_test_tmps.normalize(feature_vect = True)\n",
    "\n",
    "    Utarget_test_tmps = TensorDataset(subway_ds.Utarget_test, normalized = False, normalizer=subway_ds_tmps.normalizer)\n",
    "    Utarget_test_tmps.normalize(feature_vect = True)\n",
    "\n",
    "    subway_ds_tmps.U_test = U_test_tmps.tensor\n",
    "    subway_ds_tmps.Utarget_test = Utarget_test_tmps.tensor\n",
    "    # ...\n",
    "    return (subway_ds_tmps)\n",
    "\n",
    "def add_contextual_U_test(subway_ds_tmps,subway_ds,NetMob_ds_tmps):\n",
    "    ''' Tackle contextual Test vector:''' \n",
    "    for name in subway_ds.contextual_tensors.keys():\n",
    "\n",
    "        if name == 'netmob':\n",
    "            U_context_tmps = TensorDataset(subway_ds.contextual_tensors[name]['test'], normalized = False, normalizer=NetMob_ds_tmps.normalizer)\n",
    "            U_context_tmps.normalize(feature_vect = True)\n",
    "            subway_ds_tmps.contextual_tensors[name]['test'] = U_context_tmps.tensor\n",
    "        elif 'calendar' in name:\n",
    "            subway_ds_tmps.contextual_tensors[name]['test'] = subway_ds.contextual_tensors[name]['test'] \n",
    "        else:\n",
    "            raise NotImplementedError(f'contextual data {name} has not been implemented')\n",
    "\n",
    "    return(subway_ds_tmps)\n",
    "\n",
    "# ========================================\n",
    "# ===== ===== SPLIT K FOLD ===== =====\n",
    "\n",
    "\n",
    "#(subway_ds,dataset,invalid_dates) = load_subway_in(file_name,args,coverage,normalize=False)\n",
    "subway_ds,NetMob_ds,positions,args,args_vision,args_embedding,dic_class2rpz = load_complete_ds(dataset_names,args,coverage,folder_path,file_name,vision_model_name, normalize = False)\n",
    "print(f\"U_test: {subway_ds.U_test.shape}\\nCalendar1: {subway_ds.contextual_tensors['calendar_1']['test'].shape} \\nNetmob-test: {subway_ds.contextual_tensors['netmob']['test'].shape}\")\n",
    "print('None of these tensor have been normalized.')\n",
    "\n",
    "K_subway_ds = []\n",
    "# Remove test-dates:\n",
    "first_test_date = subway_ds.tensor_limits_keeper.first_test_date\n",
    "coverage_without_test =  coverage[coverage<first_test_date]\n",
    "n = len(coverage_without_test)\n",
    "# ... \n",
    "\n",
    "# Adapt Valid and Train Prop (cause we want Test_prop = 0)\n",
    "train_prop_tmps = args.train_prop/(args.train_prop+args.valid_prop)\n",
    "valid_prop_tmps = args.valid_prop/(args.train_prop+args.valid_prop)\n",
    "\n",
    "args.train_prop = train_prop_tmps\n",
    "args.valid_prop = valid_prop_tmps\n",
    "args.test_prop = 0\n",
    "# ...\n",
    "\n",
    "# Découpe la dataframe en K_fold \n",
    "for k in range(args.K_fold):\n",
    "    # Slicing \n",
    "    print(f'\\nFold n°{k}')\n",
    "    if args.validation == 'sliding_window':\n",
    "        width_dataset = int(n/(1+(args.K_fold-1)*valid_prop_tmps))   # Stay constant. W = N/(1 + (K-1)*Pv/(Pv+Pt))\n",
    "        l_lim_pos = int(k*valid_prop_tmps*width_dataset)    # Shifting of (valid_prop/train_prop)% of the width of the window, at each iteration \n",
    "        if k == args.K_fold - 1:\n",
    "            u_lim_pos = n\n",
    "        else:\n",
    "            u_lim_pos = l_lim_pos + width_dataset\n",
    "        \n",
    "        # Get df_tmps and coverage_tmps:\n",
    "        coverage_tmps = coverage_without_test[l_lim_pos:u_lim_pos] \n",
    "\n",
    "    subway_ds_tmps,NetMob_ds_tmps,_,_,_,_,_ = load_complete_ds(dataset_names,args,coverage_tmps,folder_path,file_name,vision_model_name, normalize = True)\n",
    "\n",
    "    # Tackle U_test and Utarget_test (normalize U_test with normalizer from subway_ds_TMPS):\n",
    "    subway_ds_tmps = add_U_test_and_Utarget_test(subway_ds_tmps,subway_ds)\n",
    "\n",
    "    # Tackle contextual Test vector (normalize U_test_contextual with normalizer from NetMob_ds_TMPS):\n",
    "    subway_ds_tmps = add_contextual_U_test(subway_ds_tmps,subway_ds,NetMob_ds_tmps)\n",
    "\n",
    "    # Tackle dataloader: load dataloader again (call it 2 times so longer but easier to implement)\n",
    "    subway_ds_tmps.get_dataloader()\n",
    "    # ...\n",
    "    \n",
    "\n",
    "    K_subway_ds.append(subway_ds_tmps)\n",
    "\n",
    "# ========================================\n",
    "# ===== ===== SPLIT K FOLD ===== ====="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(K_subway_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute statistics through dimensions: [0] \n"
     ]
    }
   ],
   "source": [
    "subway_ds.warning()\n",
    "print(f'Compute statistics through dimensions: {subway_ds.dims} ')\n",
    "Datasets,DataLoader_list = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_init = subway_ds.clean_dataset_get_tensor_and_train_valid_test_split(self.df,subway_ds.invalid_dates,args.train_prop,args.valid_prop,args.test_prop, normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_init = \n",
    "dataset_init = split_normalize_load_feature_vect(dataset_init,invalid_dates,train_prop,valid_prop,test_prop,normalize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fait la 'Hold-Out' séparation, pour enlever les dernier mois de TesT\n",
    "df_hold_out = self.df[: dataset_init.first_test_date]  \n",
    "\n",
    "\n",
    "\n",
    "# Récupère la Taille de cette DataFrame\n",
    "n = len(df_hold_out)\n",
    "\n",
    "# Adapt Valid and Train Prop (cause we want Test_prop = 0)\n",
    "train_prop_tmps = args.train_prop/(args.train_prop+args.valid_prop)\n",
    "valid_prop_tmps = args.valid_prop/(args.train_prop+args.valid_prop)\n",
    "\n",
    "args.train_prop = train_prop_tmps\n",
    "args.valid_prop = valid_prop_tmps\n",
    "\n",
    "# Découpe la dataframe en K_fold \n",
    "for k in range(args.K_fold):\n",
    "    # Slicing \n",
    "    if args.validation == 'sliding_window':\n",
    "        width_dataset = int(n/(1+(args.K_fold-1)*valid_prop_tmps))   # Stay constant. W = N/(1 + (K-1)*Pv/(Pv+Pt))\n",
    "        l_lim_pos = int(k*valid_prop_tmps*width_dataset)    # Shifting of (valid_prop/train_prop)% of the width of the window, at each iteration \n",
    "        if k == args.K_fold - 1:\n",
    "            u_lim_pos = n\n",
    "        else:\n",
    "            u_lim_pos = l_lim_pos + width_dataset\n",
    "\n",
    "        # Get df_tmps and coverage_tmps:\n",
    "        coverage_tmps = coverage[l_lim_pos:u_lim_pos] \n",
    "        df_tmps = df_hold_out[l_lim_pos:u_lim_pos]       \n",
    "\n",
    "    # Traditionnal pre-process : \n",
    "    dataset_tmps = DataSet(df_tmps, Weeks = self.Weeks, Days = self.Days, historical_len= self.historical_len,\n",
    "                            step_ahead=self.step_ahead,time_step_per_hour=self.time_step_per_hour)\n",
    "    subway_ds_tmps = preprocess_subway_in(dataset_tmps,args,invalid_dates)   \n",
    "    subway_ds_tmps,positions,args,args_vision,args_embedding,dic_class2rpz = load_complete_ds(dataset_names,args,coverage_tmps,folder_path,file_name,vision_model_name,subway_ds = subway_ds_tmps, dataset = dataset_tmps, invalid_dates = invalid_dates)\n",
    "    # ...   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-step per hour: 4.0\n",
      "coverage period: 2019-03-16 00:00:00 - 2019-05-31 23:45:00\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Testing Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Testing Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([5662, 40, 8]) Utarget size:  torch.Size([5662, 40, 1])\n",
      "U_train size:  torch.Size([2934, 40, 8]) Utarget_train size:  torch.Size([2934, 40, 1])\n",
      "U_valid size:  torch.Size([978, 40, 8]) Utarget_valid size:  torch.Size([978, 40, 1])\n",
      "U_test size:  torch.Size([979, 40, 8]) Utarget_test size:  torch.Size([979, 40, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(0.) U_valid max:  tensor(1.7234)\n",
      "U_test min:  tensor(0.) U_test max:  tensor(1.3909)\n",
      "Load des données NetMob .pt impossible. Création d'un random Tensor\n",
      "Init NetMob Dataset:  torch.Size([7392, 40, 2, 8, 8])\n",
      "Number of Nan Value:  tensor(0)\n",
      "Total Number of Elements:  37847040 \n",
      "\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Testing Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Training Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Validation Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      " Tackling Testing Set\n",
      "Values with issues:  0.000%\n",
      "Regular Values that we have to set to 0:  0.000%\n",
      "\n",
      "U size:  torch.Size([5662, 40, 2, 8, 8, 8]) Utarget size:  torch.Size([5662, 40, 2, 8, 8, 1])\n",
      "U_train size:  torch.Size([2934, 40, 2, 8, 8, 8]) Utarget_train size:  torch.Size([2934, 40, 2, 8, 8, 1])\n",
      "U_valid size:  torch.Size([978, 40, 2, 8, 8, 8]) Utarget_valid size:  torch.Size([978, 40, 2, 8, 8, 1])\n",
      "U_test size:  torch.Size([979, 40, 2, 8, 8, 8]) Utarget_test size:  torch.Size([979, 40, 2, 8, 8, 1])\n",
      "U_train min:  tensor(0.) U_train max:  tensor(1.)\n",
      "U_valid min:  tensor(-0.0742) U_valid max:  tensor(1.0721)\n",
      "U_test min:  tensor(-0.0733) U_test max:  tensor(1.0814)\n",
      "\n",
      "PREDICTION WILL BE BASED SOLELY ON CONTEXTUAL DATA !\n",
      "\n",
      "number of total parameters: 223617\n",
      "number of trainable parameters: 223617\n"
     ]
    }
   ],
   "source": [
    "model,subway_ds,loss_function,optimizer,scheduler,args,args_embedding,args_vision,positions,dic_class2rpz = load_everything(dataset_names,folder_path,file_name,args,coverage,vision_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Tuning sur le Fold 0\n",
    "def load_trainer(config,folder_path,file_name,args):\n",
    "\n",
    "    for key, value in config.items():\n",
    "        if hasattr(args, key):\n",
    "            setattr(args, key, value)\n",
    "\n",
    "    Datasets,DataLoader_list,dic_class2rpz,nb_words_embedding,time_slots_labels,dic_rpz2class = load_init_trainer(folder_path,file_name,args)\n",
    "    (loss_function,Model_list,Optimizer_list,Scheduler_list,args_embedding) = get_MultiModel_loss_args_emb_opts(args,nb_words_embedding,dic_class2rpz,n_vertex = len(Datasets[0].columns))\n",
    "    dataset,dataloader,model,optimizer,scheduler = Datasets[0],DataLoader_list[0],Model_list[0],Optimizer_list[0],Scheduler_list[0]\n",
    "\n",
    "\n",
    "    trainer = Trainer(dataset,model,dataloader,\n",
    "                    args,optimizer,loss_function,scheduler = scheduler,\n",
    "                    args_embedding=args_embedding,dic_class2rpz=dic_class2rpz)\n",
    "    return(trainer)\n",
    "\n",
    "def Train_with_tune(config,folder_path,file_name,args):\n",
    "    trainer = load_trainer(config,folder_path,file_name,args)\n",
    "    result_df = trainer.train_and_valid()\n",
    "\n",
    "    \n",
    "def run_tuning_and_save_results(args,num_samples):\n",
    "    config = get_search_space_ray(args)\n",
    "    ray_scheduler,ray_search_alg,resources_per_trial,num_gpus,max_concurrent_trials,num_cpus = get_ray_config(args)\n",
    "    \n",
    "    def trainer(config):\n",
    "        return(Train_with_tune(config,folder_path,file_name,args))\n",
    "        \n",
    "    if ray.is_initialized:\n",
    "        ray.shutdown()\n",
    "        ray.init(num_gpus=num_gpus,num_cpus=num_cpus)\n",
    "\n",
    "        \n",
    "    analysis = tune.run(\n",
    "            trainer,\n",
    "            config=config,\n",
    "            num_samples=num_samples,  # Increase num_samples for more random combinations\n",
    "            resources_per_trial = resources_per_trial,\n",
    "            max_concurrent_trials = max_concurrent_trials,\n",
    "            scheduler = ray_scheduler,\n",
    "            search_alg = ray_search_alg,\n",
    "        )\n",
    "\n",
    "    name_save = f\"HyperparameterTuning/Htuning_ray_analysis_{args.model_name}_loss{args.loss_function_type}_TE_{args.time_embedding}\"\n",
    "    analysis.results_df.to_csv(f'{name_save}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== GET PARAMETERS ====\n",
    "# Load config\n",
    "model_name = 'STGCN'  #'CNN'\n",
    "args = get_args(model_name)\n",
    "\n",
    "# Classic Modification : \n",
    "args.epochs = 1\n",
    "args.loss_function_type = 'MSE' # 'quantile'\n",
    "# ...\n",
    "\n",
    "# Modification pour HyperParameterTuning:\n",
    "args.K_fold = 5\n",
    "args.ray = True\n",
    "# ...\n",
    "\n",
    "# Update Modif \n",
    "args = update_modif(args,name_gpu='cuda:0')\n",
    "# ...\n",
    "\n",
    "run_tuning_and_save_results(args,num_samples=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
