{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Hyper-parameter tuning with Ray is not possible\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle \n",
    "\n",
    "# GET PARAMETERS\n",
    "import os \n",
    "import sys\n",
    "# Get Parent folder : \n",
    "current_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from examples.train_model_on_k_fold_validation import load_configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load 'args' from a trial id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> Load best CONFIG\n",
      "Best args: \n",
      "Namespace(model_name='STGCN', dataset_names=['subway_in', 'netmob_POIs_per_station'], dataset_for_coverage=['subway_in', 'netmob_POIs'], device=device(type='cuda'), optimizer='adamw', single_station=False, loss_function_type='MSE', epsilon_clustering=0.05, freq='15min', contextual_positions={'netmob_POIs_per_station': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41]}, quick_vision=False, netmob_transfer_mode='DL', evaluate_complete_ds=True, train_valid_test_split_method='similar_length_method', set_spatial_units=None, hp_tuning_on_first_fold=True, keep_best_weights=False, num_workers=0, persistent_workers=False, pin_memory=True, prefetch_factor=2, drop_last=False, mixed_precision=False, non_blocking=True, torch_compile=False, backend='inductor', prefetch_all=False, NetMob_selected_apps=['Google_Maps', 'Deezer', 'Instagram'], NetMob_transfer_mode=['DL'], NetMob_selected_tags=['iris'], NetMob_expanded='', ray=False, ray_scheduler='ASHA', ray_search_alg=None, grace_period=20, HP_max_epochs=100, alpha=None, conformity_scores_type='max_residual', quantile_method='compute_quantile_by_class', calibration_calendar_class=0, type_calib='classic', data_augmentation=True, DA_moment_to_focus=None, DA_min_count=5, DA_method='rich_interpolation', DA_alpha=1, DA_prop=1, DA_noise_from='MSTL', H=6, W=0, D=1, step_ahead=1, L=7, shuffle=True, train_prop=0.6, calib_prop=None, valid_prop=0.2, test_prop=0.19999999999999996, track_pi=False, validation_split_method='forward_chaining_cv', min_fold_size_proportion=0.75, no_common_dates_between_set=False, K_fold=6, current_fold=0, abs_path='/home/rrochas/prediction-validation/', out_dim=1, vision_model_name=None, vision_input_type='POIs', stacked_contextual=True, temporal_graph_transformer_encoder=True, compute_node_attr_with_attn=True, Kt=3, stblock_num=2, Ks=2, graph_conv_type='graph_conv', gso_type='sym_norm_lap', enable_bias=True, adj_type='corr', enable_padding=True, threshold=0.3, act_func='glu', temporal_h_dim=32, spatial_h_dim=64, output_h_dim=16, TGE_num_layers=4, TGE_num_heads=8, TGE_FC_hdim=8, blocks=[[1], [32, 32, 32], [32, 32, 32], [64]], weight_decay=0.0886751159370831, batch_size=32, lr=0.0045, dropout=0.2274827950137636, epochs=100, scheduler=nan, n_vertex=40, C=3, args_embedding=Namespace(), args_vision=Namespace(), n_units_netmob_POIs_per_station_0=51, input_dim_netmob_POIs_per_station_0=7, n_units_netmob_POIs_per_station_1=63, input_dim_netmob_POIs_per_station_1=7, n_units_netmob_POIs_per_station_2=63, input_dim_netmob_POIs_per_station_2=7, n_units_netmob_POIs_per_station_3=72, input_dim_netmob_POIs_per_station_3=7, n_units_netmob_POIs_per_station_4=129, input_dim_netmob_POIs_per_station_4=7, n_units_netmob_POIs_per_station_5=36, input_dim_netmob_POIs_per_station_5=7, n_units_netmob_POIs_per_station_6=51, input_dim_netmob_POIs_per_station_6=7, n_units_netmob_POIs_per_station_7=78, input_dim_netmob_POIs_per_station_7=7, n_units_netmob_POIs_per_station_8=42, input_dim_netmob_POIs_per_station_8=7, n_units_netmob_POIs_per_station_9=93, input_dim_netmob_POIs_per_station_9=7, n_units_netmob_POIs_per_station_10=66, input_dim_netmob_POIs_per_station_10=7, n_units_netmob_POIs_per_station_11=75, input_dim_netmob_POIs_per_station_11=7, n_units_netmob_POIs_per_station_12=60, input_dim_netmob_POIs_per_station_12=7, n_units_netmob_POIs_per_station_13=78, input_dim_netmob_POIs_per_station_13=7, n_units_netmob_POIs_per_station_14=42, input_dim_netmob_POIs_per_station_14=7, n_units_netmob_POIs_per_station_15=63, input_dim_netmob_POIs_per_station_15=7, n_units_netmob_POIs_per_station_16=54, input_dim_netmob_POIs_per_station_16=7, n_units_netmob_POIs_per_station_17=63, input_dim_netmob_POIs_per_station_17=7, n_units_netmob_POIs_per_station_18=30, input_dim_netmob_POIs_per_station_18=7, n_units_netmob_POIs_per_station_19=60, input_dim_netmob_POIs_per_station_19=7, n_units_netmob_POIs_per_station_20=51, input_dim_netmob_POIs_per_station_20=7, n_units_netmob_POIs_per_station_21=69, input_dim_netmob_POIs_per_station_21=7, n_units_netmob_POIs_per_station_22=30, input_dim_netmob_POIs_per_station_22=7, n_units_netmob_POIs_per_station_23=57, input_dim_netmob_POIs_per_station_23=7, n_units_netmob_POIs_per_station_24=48, input_dim_netmob_POIs_per_station_24=7, n_units_netmob_POIs_per_station_25=60, input_dim_netmob_POIs_per_station_25=7, n_units_netmob_POIs_per_station_26=63, input_dim_netmob_POIs_per_station_26=7, n_units_netmob_POIs_per_station_27=129, input_dim_netmob_POIs_per_station_27=7, n_units_netmob_POIs_per_station_28=45, input_dim_netmob_POIs_per_station_28=7, n_units_netmob_POIs_per_station_29=57, input_dim_netmob_POIs_per_station_29=7, n_units_netmob_POIs_per_station_30=78, input_dim_netmob_POIs_per_station_30=7, n_units_netmob_POIs_per_station_31=72, input_dim_netmob_POIs_per_station_31=7, n_units_netmob_POIs_per_station_32=24, input_dim_netmob_POIs_per_station_32=7, n_units_netmob_POIs_per_station_33=33, input_dim_netmob_POIs_per_station_33=7, n_units_netmob_POIs_per_station_34=30, input_dim_netmob_POIs_per_station_34=7, n_units_netmob_POIs_per_station_35=75, input_dim_netmob_POIs_per_station_35=7, n_units_netmob_POIs_per_station_36=72, input_dim_netmob_POIs_per_station_36=7, n_units_netmob_POIs_per_station_37=72, input_dim_netmob_POIs_per_station_37=7, n_units_netmob_POIs_per_station_38=81, input_dim_netmob_POIs_per_station_38=7, n_units_netmob_POIs_per_station_39=102, input_dim_netmob_POIs_per_station_39=7, pos_netmob_POIs_per_station=[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], ds_which_need_spatial_attn=['netmob_POIs_per_station'], pos_node_attributes=[], dict_node_attr2dataset={}, node_attr_which_need_attn=[], torch_scheduler_milestone=nan, torch_scheduler_gamma=nan, torch_scheduler_lr_start_factor=nan)\n"
     ]
    }
   ],
   "source": [
    "trial_id = 'subway_in_netmob_POIs_per_station_STGCN_MSELoss_2025_02_18_03_38_83510'\n",
    "# \"subway_in_netmob_POIs_per_station_STGCN_MSELoss_2025_02_18_03_38_83510\" # NEW RIM ARCHITECTURE\n",
    "# 'subway_in_subway_out_STGCN_MSELoss_2025_02_14_16_03_71730' # NEW RIM ARCHITECTURE\n",
    "\n",
    "\n",
    "# \"subway_in_netmob_POIs_STGCN_VariableSelectionNetwork_MSELoss_2025_02_01_12_25_68609\"   #  Bug ????\n",
    "\n",
    "# \"subway_in_subway_out_STGCN_VariableSelectionNetwork_MSELoss_2025_01_06_02_04_17963\"\n",
    "# 'subway_in_netmob_POIs_STGCN_VariableSelectionNetwork_MSELoss_2025_01_07_05_04_80480'\n",
    "# \"subway_in_STGCN_MSELoss_2025_01_06_08_00_94523\"\n",
    "args,_ = load_configuration(trial_id,load_config=True)\n",
    "\n",
    "print('Best args: ')\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss_model</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>temporal_h_dim</th>\n",
       "      <th>spatial_h_dim</th>\n",
       "      <th>output_h_dim</th>\n",
       "      <th>TGE_num_layers</th>\n",
       "      <th>TGE_num_heads</th>\n",
       "      <th>TGE_FC_hdim</th>\n",
       "      <th>scheduler</th>\n",
       "      <th>torch_scheduler_milestone</th>\n",
       "      <th>torch_scheduler_gamma</th>\n",
       "      <th>torch_scheduler_lr_start_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.003790</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>0.088675</td>\n",
       "      <td>0.227483</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.00440</td>\n",
       "      <td>0.028245</td>\n",
       "      <td>0.314935</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>0.384157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.00420</td>\n",
       "      <td>0.032708</td>\n",
       "      <td>0.062799</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>0.798202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.004195</td>\n",
       "      <td>0.00320</td>\n",
       "      <td>0.031088</td>\n",
       "      <td>0.096899</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.00360</td>\n",
       "      <td>0.046775</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.00455</td>\n",
       "      <td>0.031197</td>\n",
       "      <td>0.029746</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.004265</td>\n",
       "      <td>0.00295</td>\n",
       "      <td>0.084675</td>\n",
       "      <td>0.293710</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.252173</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.996044</td>\n",
       "      <td>0.279328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.004353</td>\n",
       "      <td>0.00360</td>\n",
       "      <td>0.035557</td>\n",
       "      <td>0.174430</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.986423</td>\n",
       "      <td>0.919977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.062804</td>\n",
       "      <td>0.067637</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.987369</td>\n",
       "      <td>0.345359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.079327</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986936</td>\n",
       "      <td>0.189166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.004572</td>\n",
       "      <td>0.00265</td>\n",
       "      <td>0.046902</td>\n",
       "      <td>0.131928</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.00230</td>\n",
       "      <td>0.074137</td>\n",
       "      <td>0.043766</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.00310</td>\n",
       "      <td>0.062005</td>\n",
       "      <td>0.232374</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.081047</td>\n",
       "      <td>0.339041</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.009302</td>\n",
       "      <td>0.593582</td>\n",
       "      <td>256</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.986994</td>\n",
       "      <td>0.705512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.00180</td>\n",
       "      <td>0.075487</td>\n",
       "      <td>0.102801</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.00355</td>\n",
       "      <td>0.070555</td>\n",
       "      <td>0.339982</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.985189</td>\n",
       "      <td>0.836845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.00440</td>\n",
       "      <td>0.033326</td>\n",
       "      <td>0.621197</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Loss_model       lr  weight_decay   dropout  temporal_h_dim  \\\n",
       "286    0.003790  0.00450      0.088675  0.227483              32   \n",
       "293    0.003927  0.00440      0.028245  0.314935               8   \n",
       "2      0.004092  0.00205      0.092470  0.056249              32   \n",
       "300    0.004116  0.00420      0.032708  0.062799              32   \n",
       "166    0.004195  0.00320      0.031088  0.096899              16   \n",
       "7      0.004224  0.00360      0.046775  0.300000               8   \n",
       "107    0.004256  0.00455      0.031197  0.029746             256   \n",
       "203    0.004265  0.00295      0.084675  0.293710              32   \n",
       "398    0.004273  0.00290      0.042993  0.252173              64   \n",
       "485    0.004353  0.00360      0.035557  0.174430              64   \n",
       "126    0.004486  0.00460      0.062804  0.067637              32   \n",
       "152    0.004508  0.00195      0.055571  0.079327             256   \n",
       "467    0.004572  0.00265      0.046902  0.131928              32   \n",
       "123    0.004642  0.00230      0.074137  0.043766              16   \n",
       "57     0.004643  0.00310      0.062005  0.232374             128   \n",
       "422    0.004682  0.00490      0.081047  0.339041               8   \n",
       "333    0.004689  0.00390      0.009302  0.593582             256   \n",
       "352    0.004715  0.00180      0.075487  0.102801             128   \n",
       "276    0.004720  0.00355      0.070555  0.339982               8   \n",
       "61     0.004783  0.00440      0.033326  0.621197              16   \n",
       "\n",
       "     spatial_h_dim  output_h_dim  TGE_num_layers  TGE_num_heads  TGE_FC_hdim  \\\n",
       "286             64            16               4              8            8   \n",
       "293              8            64               2              2           32   \n",
       "2              128            16               4              4           16   \n",
       "300             16            64               3              8           32   \n",
       "166              8            16               2              2           16   \n",
       "7               16            64               2              2           64   \n",
       "107            256            32               2              4          256   \n",
       "203            128            64               8              4           16   \n",
       "398            256             8               1              4          256   \n",
       "485            256             8               3              8          128   \n",
       "126              8            16               4              4           16   \n",
       "152             64            32               4              1          128   \n",
       "467            256            16               4              8           32   \n",
       "123              8            16               4              1           16   \n",
       "57             256           128               4              8            8   \n",
       "422             16           256               1              8            8   \n",
       "333             32           256               4              1           64   \n",
       "352             16            32               4              4          256   \n",
       "276            256           128               4              2           32   \n",
       "61              64            16               4              8           16   \n",
       "\n",
       "    scheduler  torch_scheduler_milestone  torch_scheduler_gamma  \\\n",
       "286       NaN                        NaN                    NaN   \n",
       "293       NaN                        NaN                    NaN   \n",
       "2        True                        4.0               0.996072   \n",
       "300      True                        6.0               0.989870   \n",
       "166       NaN                        NaN                    NaN   \n",
       "7         NaN                        NaN                    NaN   \n",
       "107       NaN                        NaN                    NaN   \n",
       "203       NaN                        NaN                    NaN   \n",
       "398      True                       24.0               0.996044   \n",
       "485      True                       27.0               0.986423   \n",
       "126      True                        7.0               0.987369   \n",
       "152      True                        1.0               0.986936   \n",
       "467       NaN                        NaN                    NaN   \n",
       "123       NaN                        NaN                    NaN   \n",
       "57        NaN                        NaN                    NaN   \n",
       "422       NaN                        NaN                    NaN   \n",
       "333      True                        4.0               0.986994   \n",
       "352       NaN                        NaN                    NaN   \n",
       "276      True                       17.0               0.985189   \n",
       "61        NaN                        NaN                    NaN   \n",
       "\n",
       "     torch_scheduler_lr_start_factor  \n",
       "286                              NaN  \n",
       "293                              NaN  \n",
       "2                           0.384157  \n",
       "300                         0.798202  \n",
       "166                              NaN  \n",
       "7                                NaN  \n",
       "107                              NaN  \n",
       "203                              NaN  \n",
       "398                         0.279328  \n",
       "485                         0.919977  \n",
       "126                         0.345359  \n",
       "152                         0.189166  \n",
       "467                              NaN  \n",
       "123                              NaN  \n",
       "57                               NaN  \n",
       "422                              NaN  \n",
       "333                         0.705512  \n",
       "352                              NaN  \n",
       "276                         0.836845  \n",
       "61                               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hp_tuning =pd.read_csv(f'save/HyperparameterTuning/{trial_id}.csv')\n",
    "model_args = pickle.load(open(f'save/HyperparameterTuning/model_args.pkl','rb'))\n",
    "metric = '_metric/Loss_model'\n",
    "# Load common args through all tuning trials:\n",
    "args = model_args['model'][trial_id]['args']\n",
    "\n",
    "# Rename columns, remove useless ones: \n",
    "columns = [c for c in df_hp_tuning.columns if ('_metric/' in c) or ('config/' in c)]\n",
    "columns_rename = {c:c.split('/')[-1] for c in columns}\n",
    "df_best_configs = df_hp_tuning[columns].sort_values(metric).rename(columns = columns_rename)\n",
    "df_best_configs\n",
    "print('Best configs:')\n",
    "display(df_best_configs.iloc[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss_model</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>temporal_h_dim</th>\n",
       "      <th>spatial_h_dim</th>\n",
       "      <th>output_h_dim</th>\n",
       "      <th>TGE_num_layers</th>\n",
       "      <th>TGE_num_heads</th>\n",
       "      <th>TGE_FC_hdim</th>\n",
       "      <th>scheduler</th>\n",
       "      <th>torch_scheduler_milestone</th>\n",
       "      <th>torch_scheduler_gamma</th>\n",
       "      <th>torch_scheduler_lr_start_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.003555</td>\n",
       "      <td>0.00145</td>\n",
       "      <td>0.093438</td>\n",
       "      <td>0.017829</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.988059</td>\n",
       "      <td>0.600637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.00290</td>\n",
       "      <td>0.056935</td>\n",
       "      <td>0.205239</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.994082</td>\n",
       "      <td>0.494039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.00310</td>\n",
       "      <td>0.076135</td>\n",
       "      <td>0.209686</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.989726</td>\n",
       "      <td>0.609100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.003715</td>\n",
       "      <td>0.00260</td>\n",
       "      <td>0.015236</td>\n",
       "      <td>0.153810</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.986840</td>\n",
       "      <td>0.273233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.00265</td>\n",
       "      <td>0.056675</td>\n",
       "      <td>0.087503</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.987510</td>\n",
       "      <td>0.355194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.035155</td>\n",
       "      <td>0.013960</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.003740</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.119636</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.991411</td>\n",
       "      <td>0.928782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.061103</td>\n",
       "      <td>0.065937</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.989121</td>\n",
       "      <td>0.202832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>0.054753</td>\n",
       "      <td>0.018427</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.068777</td>\n",
       "      <td>0.034193</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.996067</td>\n",
       "      <td>0.284229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.014211</td>\n",
       "      <td>0.081243</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.990442</td>\n",
       "      <td>0.118727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.054041</td>\n",
       "      <td>0.098433</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.988635</td>\n",
       "      <td>0.583342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.036637</td>\n",
       "      <td>0.030435</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.00275</td>\n",
       "      <td>0.092835</td>\n",
       "      <td>0.403184</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.990460</td>\n",
       "      <td>0.763806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.150110</td>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.00050</td>\n",
       "      <td>0.064690</td>\n",
       "      <td>0.100757</td>\n",
       "      <td>128</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.985988</td>\n",
       "      <td>0.934420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>0.083737</td>\n",
       "      <td>0.249926</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.00470</td>\n",
       "      <td>0.083882</td>\n",
       "      <td>0.029246</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.990898</td>\n",
       "      <td>0.615597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.074290</td>\n",
       "      <td>0.092306</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.039979</td>\n",
       "      <td>0.038099</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.998195</td>\n",
       "      <td>0.959303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Loss_model       lr  weight_decay   dropout  temporal_h_dim  \\\n",
       "43     0.003555  0.00145      0.093438  0.017829             128   \n",
       "180    0.003558  0.00290      0.056935  0.205239               8   \n",
       "415    0.003686  0.00310      0.076135  0.209686             128   \n",
       "479    0.003715  0.00260      0.015236  0.153810              64   \n",
       "72     0.003723  0.00265      0.056675  0.087503              64   \n",
       "488    0.003726  0.00030      0.035155  0.013960              32   \n",
       "234    0.003740  0.00060      0.082800  0.119636              32   \n",
       "262    0.003776  0.00125      0.061103  0.065937              16   \n",
       "247    0.003781  0.00245      0.054753  0.018427              32   \n",
       "57     0.003792  0.00015      0.068777  0.034193             128   \n",
       "211    0.003794  0.00050      0.014211  0.081243              64   \n",
       "457    0.003797  0.00035      0.054041  0.098433              64   \n",
       "384    0.003813  0.00025      0.036637  0.030435              32   \n",
       "48     0.003814  0.00275      0.092835  0.403184             128   \n",
       "470    0.003815  0.00030      0.054945  0.150110              64   \n",
       "366    0.003841  0.00050      0.064690  0.100757             128   \n",
       "23     0.003846  0.00175      0.083737  0.249926               8   \n",
       "188    0.003846  0.00470      0.083882  0.029246               8   \n",
       "242    0.003848  0.00030      0.074290  0.092306              64   \n",
       "324    0.003861  0.00120      0.039979  0.038099              64   \n",
       "\n",
       "     spatial_h_dim  output_h_dim  TGE_num_layers  TGE_num_heads  TGE_FC_hdim  \\\n",
       "43              32            64               3              1            8   \n",
       "180            128            32               8              2           16   \n",
       "415             32            16               4              1           64   \n",
       "479             16           256               8              8           16   \n",
       "72             128            64               1              1            8   \n",
       "488             32           256               1              1          256   \n",
       "234            256           256               2              8           16   \n",
       "262             64            32               3              8           64   \n",
       "247            128             8               4              1           64   \n",
       "57               8           256               8              2          256   \n",
       "211              8            64               8              2          128   \n",
       "457             16             8               4              4          128   \n",
       "384             16            64               8              4            8   \n",
       "48             128             8               8              1           32   \n",
       "470              8           256               3              2           32   \n",
       "366              8            32               8              4           16   \n",
       "23              64           256               8              8           64   \n",
       "188              8             8               2              4          256   \n",
       "242            128            32               3              1           16   \n",
       "324             32            64               2              1           32   \n",
       "\n",
       "    scheduler  torch_scheduler_milestone  torch_scheduler_gamma  \\\n",
       "43       True                       29.0               0.988059   \n",
       "180      True                       16.0               0.994082   \n",
       "415      True                        6.0               0.989726   \n",
       "479      True                       21.0               0.986840   \n",
       "72       True                       13.0               0.987510   \n",
       "488       NaN                        NaN                    NaN   \n",
       "234      True                       14.0               0.991411   \n",
       "262      True                       13.0               0.989121   \n",
       "247       NaN                        NaN                    NaN   \n",
       "57       True                        6.0               0.996067   \n",
       "211      True                       15.0               0.990442   \n",
       "457      True                       16.0               0.988635   \n",
       "384       NaN                        NaN                    NaN   \n",
       "48       True                        5.0               0.990460   \n",
       "470       NaN                        NaN                    NaN   \n",
       "366      True                       12.0               0.985988   \n",
       "23        NaN                        NaN                    NaN   \n",
       "188      True                       26.0               0.990898   \n",
       "242       NaN                        NaN                    NaN   \n",
       "324      True                        6.0               0.998195   \n",
       "\n",
       "     torch_scheduler_lr_start_factor  \n",
       "43                          0.600637  \n",
       "180                         0.494039  \n",
       "415                         0.609100  \n",
       "479                         0.273233  \n",
       "72                          0.355194  \n",
       "488                              NaN  \n",
       "234                         0.928782  \n",
       "262                         0.202832  \n",
       "247                              NaN  \n",
       "57                          0.284229  \n",
       "211                         0.118727  \n",
       "457                         0.583342  \n",
       "384                              NaN  \n",
       "48                          0.763806  \n",
       "470                              NaN  \n",
       "366                         0.934420  \n",
       "23                               NaN  \n",
       "188                         0.615597  \n",
       "242                              NaN  \n",
       "324                         0.959303  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hp_tuning =pd.read_csv(f'save/HyperparameterTuning/{trial_id}.csv')\n",
    "model_args = pickle.load(open(f'save/HyperparameterTuning/model_args.pkl','rb'))\n",
    "metric = '_metric/Loss_model'\n",
    "# Load common args through all tuning trials:\n",
    "args = model_args['model'][trial_id]['args']\n",
    "\n",
    "# Rename columns, remove useless ones: \n",
    "columns = [c for c in df_hp_tuning.columns if ('_metric/' in c) or ('config/' in c)]\n",
    "columns_rename = {c:c.split('/')[-1] for c in columns}\n",
    "df_best_configs = df_hp_tuning[columns].sort_values(metric).rename(columns = columns_rename)\n",
    "df_best_configs\n",
    "print('Best configs:')\n",
    "display(df_best_configs.iloc[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best configs from a trial id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best configs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss_model</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>dropout</th>\n",
       "      <th>temporal_h_dim</th>\n",
       "      <th>spatial_h_dim</th>\n",
       "      <th>output_h_dim</th>\n",
       "      <th>scheduler</th>\n",
       "      <th>torch_scheduler_milestone</th>\n",
       "      <th>torch_scheduler_gamma</th>\n",
       "      <th>torch_scheduler_lr_start_factor</th>\n",
       "      <th>concatenation_early</th>\n",
       "      <th>concatenation_late</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>grn_out_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.005105</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>0.007052</td>\n",
       "      <td>0.278061</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.991593</td>\n",
       "      <td>0.752912</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.005124</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.065237</td>\n",
       "      <td>0.159976</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.005195</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.024583</td>\n",
       "      <td>0.134271</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.100491</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.995704</td>\n",
       "      <td>0.542937</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.00400</td>\n",
       "      <td>0.072955</td>\n",
       "      <td>0.068490</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.00260</td>\n",
       "      <td>0.017781</td>\n",
       "      <td>0.522119</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>0.005270</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.065677</td>\n",
       "      <td>0.287299</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>0.078816</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>256</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.998806</td>\n",
       "      <td>0.508260</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.005343</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>0.033701</td>\n",
       "      <td>0.385530</td>\n",
       "      <td>256</td>\n",
       "      <td>64</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.990168</td>\n",
       "      <td>0.132749</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.005344</td>\n",
       "      <td>0.00390</td>\n",
       "      <td>0.037983</td>\n",
       "      <td>0.313570</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.005351</td>\n",
       "      <td>0.00065</td>\n",
       "      <td>0.033816</td>\n",
       "      <td>0.181959</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.992630</td>\n",
       "      <td>0.845106</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.050364</td>\n",
       "      <td>0.430763</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.995901</td>\n",
       "      <td>0.119076</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.00045</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.155753</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.325044</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.00120</td>\n",
       "      <td>0.029603</td>\n",
       "      <td>0.495138</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.995623</td>\n",
       "      <td>0.672736</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.00040</td>\n",
       "      <td>0.043944</td>\n",
       "      <td>0.150495</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.987071</td>\n",
       "      <td>0.168373</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.185767</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.005560</td>\n",
       "      <td>0.00225</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.476864</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.00125</td>\n",
       "      <td>0.055266</td>\n",
       "      <td>0.551458</td>\n",
       "      <td>256</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.091786</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>True</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.989807</td>\n",
       "      <td>0.628288</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Loss_model       lr  weight_decay   dropout  temporal_h_dim  \\\n",
       "351    0.005105  0.00065      0.007052  0.278061             256   \n",
       "226    0.005124  0.00115      0.065237  0.159976              16   \n",
       "414    0.005195  0.00055      0.024583  0.134271              32   \n",
       "316    0.005217  0.00110      0.022065  0.100491             256   \n",
       "353    0.005256  0.00400      0.072955  0.068490              32   \n",
       "358    0.005258  0.00260      0.017781  0.522119              16   \n",
       "255    0.005270  0.00055      0.065677  0.287299             256   \n",
       "272    0.005285  0.00485      0.015913  0.078816              64   \n",
       "286    0.005343  0.00070      0.033701  0.385530             256   \n",
       "341    0.005344  0.00390      0.037983  0.313570             128   \n",
       "96     0.005351  0.00065      0.033816  0.181959             128   \n",
       "156    0.005357  0.00115      0.050364  0.430763             256   \n",
       "235    0.005379  0.00045      0.001352  0.155753              16   \n",
       "12     0.005411  0.00125      0.055817  0.325044              32   \n",
       "190    0.005427  0.00120      0.029603  0.495138             128   \n",
       "431    0.005466  0.00040      0.043944  0.150495             256   \n",
       "256    0.005518  0.00150      0.019312  0.185767               8   \n",
       "396    0.005560  0.00225      0.098100  0.476864              32   \n",
       "206    0.005569  0.00125      0.055266  0.551458             256   \n",
       "30     0.005572  0.00055      0.091786  0.052740               8   \n",
       "\n",
       "     spatial_h_dim  output_h_dim scheduler  torch_scheduler_milestone  \\\n",
       "351            256             8      True                       25.0   \n",
       "226              8             8       NaN                        NaN   \n",
       "414            256            16       NaN                        NaN   \n",
       "316             64            32      True                       28.0   \n",
       "353              8             8       NaN                        NaN   \n",
       "358              8           256       NaN                        NaN   \n",
       "255            256           128       NaN                        NaN   \n",
       "272             64           256      True                        2.0   \n",
       "286             64           128      True                        7.0   \n",
       "341             16            32       NaN                        NaN   \n",
       "96              16             8      True                       10.0   \n",
       "156            256            16      True                        9.0   \n",
       "235            128            16       NaN                        NaN   \n",
       "12             128           256       NaN                        NaN   \n",
       "190             32            32      True                       27.0   \n",
       "431            128           128      True                       18.0   \n",
       "256            256            16       NaN                        NaN   \n",
       "396             32           256       NaN                        NaN   \n",
       "206              8            16       NaN                        NaN   \n",
       "30              32           128      True                       17.0   \n",
       "\n",
       "     torch_scheduler_gamma  torch_scheduler_lr_start_factor  \\\n",
       "351               0.991593                         0.752912   \n",
       "226                    NaN                              NaN   \n",
       "414                    NaN                              NaN   \n",
       "316               0.995704                         0.542937   \n",
       "353                    NaN                              NaN   \n",
       "358                    NaN                              NaN   \n",
       "255                    NaN                              NaN   \n",
       "272               0.998806                         0.508260   \n",
       "286               0.990168                         0.132749   \n",
       "341                    NaN                              NaN   \n",
       "96                0.992630                         0.845106   \n",
       "156               0.995901                         0.119076   \n",
       "235                    NaN                              NaN   \n",
       "12                     NaN                              NaN   \n",
       "190               0.995623                         0.672736   \n",
       "431               0.987071                         0.168373   \n",
       "256                    NaN                              NaN   \n",
       "396                    NaN                              NaN   \n",
       "206                    NaN                              NaN   \n",
       "30                0.989807                         0.628288   \n",
       "\n",
       "     concatenation_early  concatenation_late  num_heads  grn_out_dim  \n",
       "351                 True               False          2           64  \n",
       "226                 True                True          4           32  \n",
       "414                 True                True          4           16  \n",
       "316                 True                True          1           16  \n",
       "353                 True               False          3           24  \n",
       "358                 True               False          1            8  \n",
       "255                 True               False          2            8  \n",
       "272                 True               False          2           32  \n",
       "286                 True                True          6           48  \n",
       "341                 True                True          3           24  \n",
       "96                  True                True          6           48  \n",
       "156                 True                True          1           16  \n",
       "235                 True                True          1           32  \n",
       "12                  True                True          6           24  \n",
       "190                 True                True          2           64  \n",
       "431                 True                True          3           12  \n",
       "256                 True                True          2           16  \n",
       "396                 True               False          4           16  \n",
       "206                 True                True          1           32  \n",
       "30                  True               False          1           16  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_hp_tuning =pd.read_csv(f'save/HyperparameterTuning/{trial_id}.csv')\n",
    "model_args = pickle.load(open(f'save/HyperparameterTuning/model_args.pkl','rb'))\n",
    "metric = '_metric/Loss_model'\n",
    "# Load common args through all tuning trials:\n",
    "args = model_args['model'][trial_id]['args']\n",
    "\n",
    "# Rename columns, remove useless ones: \n",
    "columns = [c for c in df_hp_tuning.columns if ('_metric/' in c) or ('config/' in c)]\n",
    "columns_rename = {c:c.split('/')[-1] for c in columns}\n",
    "df_best_configs = df_hp_tuning[columns].sort_values(metric).rename(columns = columns_rename)\n",
    "df_best_configs\n",
    "print('Best configs:')\n",
    "display(df_best_configs.iloc[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load `the` best config, with no rename: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw config of best model: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trial_id                                                                                       b9f67_00351\n",
       "time_this_iter_s                                                                                  4.243078\n",
       "done                                                                                                  True\n",
       "training_iteration                                                                                     100\n",
       "date                                                                                   2025-01-07_01-20-56\n",
       "timestamp                                                                                       1736209256\n",
       "time_total_s                                                                                    442.195914\n",
       "pid                                                                                                 144430\n",
       "hostname                                                                                 ticil2.ifsttar.fr\n",
       "node_ip                                                                                     137.121.170.69\n",
       "time_since_restore                                                                              442.195914\n",
       "iterations_since_restore                                                                               100\n",
       "experiment_tag                                           351_dropout=0.2781,lr=0.0007,output_h_dim=8,sc...\n",
       "_metric/Loss_model                                                                                0.005105\n",
       "config/lr                                                                                          0.00065\n",
       "config/weight_decay                                                                               0.007052\n",
       "config/dropout                                                                                    0.278061\n",
       "config/temporal_h_dim                                                                                  256\n",
       "config/spatial_h_dim                                                                                   256\n",
       "config/output_h_dim                                                                                      8\n",
       "config/scheduler/scheduler                                                                            True\n",
       "config/scheduler/torch_scheduler_milestone                                                            25.0\n",
       "config/scheduler/torch_scheduler_gamma                                                            0.991593\n",
       "config/scheduler/torch_scheduler_lr_start_factor                                                  0.752912\n",
       "config/vision_concatenation_order/concatenation_early                                                 True\n",
       "config/vision_concatenation_order/concatenation_late                                                 False\n",
       "config/vision_n_head_d_model/num_heads                                                                   2\n",
       "config/vision_n_head_d_model/grn_out_dim                                                                64\n",
       "Name: 351, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get best config :\n",
    "best_model = df_hp_tuning.sort_values(metric).iloc[0]\n",
    "print('raw config of best model: ')\n",
    "display(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
