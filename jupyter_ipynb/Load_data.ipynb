{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtenir le chemin du dossier parent\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "# current_path = os.path.dirname()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "\n",
    "# Ajouter le dossier parent au chemin de recherche des modules\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Personnal Import \n",
    "from utils.utilities import get_mode_date2path\n",
    "from build_inputs.load_raw_data import load_subway_15_min,load_CRITER,load_netmob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "- Validation individuelles, aggrégée **3min**\n",
    "- Metro (entrée/sortie)  **15 min**\n",
    "- Sensor, aggrégé **6 min**\n",
    "\n",
    "### Notes et questionnements\n",
    "- Un 'VAL_ARRET_CODE' peut être l'arrêt de plusieurs mêmes bus, voir d'un même bus et d'un même arrêt de métro. Où d'un même bus et d'un même arrêt de tram. Je dois donc nommer différement les VAL_ARRET_CODE de chacun des modes. Une proposition est de mettre le mode (B,S,T) devant les id. Comme ça on pourra regrouper sans soucis.\n",
    "- La moyenne des déplacement de la df_subway est de 5 trajet toute les 3 minutes, quelque soit la station et l'heure (d'ouverture) considéré. Max 88.\n",
    "- Ok on a aggrégé 3 min, mais est-ce qu'on peut recouper les sorties 3min avec les validation + Sortie de métro 15 min? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway 15 Min :                                   [J,F,M,A,M,J,J,A,S,O,N,D],[J,F,M,A,M,~, , ,~,~, , ],[J,F,M, , , , , , , , , ]\n",
    "# Validation Individuelles  Nov 2019 - Mai 2021     [ , , , , , , , , , ,N,D],[J,F,M,A,M,J,J,A,S,O,N,D],[J,F,M,A,M, , , , , , , ]\n",
    "# NetMob 15 Min :                                   [ , ,M,A,M, , , , , , , ],[ , , , , , , , , , , , ],[ , , , , , , , , , , , ]\n",
    "# Sensor 6 Min :  Janvier 2019 - Decembre 2020      [J,F,M,A,M,J,J,A,S,O,N,D],[J,F,M,A,M,J,J,A,S,O,N,D],[J,F,M,A,M,J,J,A,S,O,N,D]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Individuelles\n",
    "Load 3 df : df_sub, df_tram, df_bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108571/2947046094.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "/tmp/ipykernel_108571/2947046094.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "/tmp/ipykernel_108571/2947046094.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "/tmp/ipykernel_108571/2947046094.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n",
      "/tmp/ipykernel_108571/2947046094.py:9: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])\n"
     ]
    }
   ],
   "source": [
    "FOLDER_PATH = '../../../data/rrochas/raw_data/keolis_data_2019-2020/'\n",
    "valid_ind_path = f\"{FOLDER_PATH}Sub_Tram_11_2019_03_2020\"\n",
    "dates = ['11-2019','12-2019','1-2020','2-2020','3-2020']\n",
    "\n",
    "subway_paths, tramway_paths, bus_paths = sorted(glob.glob(os.path.join(valid_ind_path, \"*df_subway*.csv\"))),sorted(glob.glob(os.path.join(valid_ind_path, \"*df_tramway*.csv\"))),sorted(glob.glob(os.path.join(valid_ind_path, \"*df_bus*.csv\")))\n",
    "mode_month2path = get_mode_date2path([subway_paths,tramway_paths,bus_paths],['sub','tram','bus'])\n",
    "\n",
    "for name in ['sub','tram','bus']:\n",
    "    globals()[f'df_{name}'] = pd.concat([pd.read_csv(mode_month2path[name][d],index_col = 0) for d in dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_108571/3290188844.py:14: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  reindex = pd.date_range(start,end,freq = freq)\n",
      "/tmp/ipykernel_108571/3290188844.py:16: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df = df_i[['Flow','VAL_DATE','CRS_SENS_TRAJET','LIB_STA_SIFO']].groupby(['LIB_STA_SIFO',pd.Grouper(key='VAL_DATE',freq=freq)]).agg(Flow = ('Flow','sum'))\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../../../../data/rrochas/prediction_validation/agg_data/validation_individuelle/subway_indiv_1H'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m     df_corres \u001b[38;5;241m=\u001b[39m get_trigram_correspondance()\n\u001b[1;32m     20\u001b[0m     df\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {row\u001b[38;5;241m.\u001b[39mINDIV:row\u001b[38;5;241m.\u001b[39mCOD_TRG \u001b[38;5;28;01mfor\u001b[39;00m k,row \u001b[38;5;129;01min\u001b[39;00m df_corres\u001b[38;5;241m.\u001b[39miterrows()})\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msave_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/subway_indiv_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfreq\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/subway_indiv_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfreq\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtram\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not implemented yet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/pandas/core/generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3965\u001b[0m )\n\u001b[0;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/pandas/io/formats/format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/pandas/io/formats/csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    268\u001b[0m     )\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/root/anaconda3/envs/pytorch-2.0.1/lib/python3.10/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../../../../data/rrochas/prediction_validation/agg_data/validation_individuelle/subway_indiv_1H'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "from load_inputs.subway_in import get_trigram_correspondance\n",
    "\n",
    "start,end = datetime(2019,11,1),datetime(2020,4,1)\n",
    "freqs = ['2min','3min','5min','6min','10min','15min','30min','1H']\n",
    "freqs.reverse()\n",
    "\n",
    "save_path = '../../../../data/rrochas/prediction_validation/agg_data/validation_individuelle'\n",
    "\n",
    "for name in ['sub','tram','bus']:\n",
    "    df_i = globals()[f'df_{name}']\n",
    "    df_i.VAL_DATE = pd.to_datetime(df_i.VAL_DATE)\n",
    "    for freq in freqs:\n",
    "        reindex = pd.date_range(start,end,freq = freq)\n",
    "        if name == 'sub':\n",
    "            df = df_i[['Flow','VAL_DATE','CRS_SENS_TRAJET','LIB_STA_SIFO']].groupby(['LIB_STA_SIFO',pd.Grouper(key='VAL_DATE',freq=freq)]).agg(Flow = ('Flow','sum'))\n",
    "            df = df.reset_index()\n",
    "            df = df.pivot(index = 'VAL_DATE',columns='LIB_STA_SIFO',values ='Flow').fillna(0)\n",
    "            df_corres = get_trigram_correspondance()\n",
    "            df.rename(columns = {row.INDIV:row.COD_TRG for k,row in df_corres.iterrows()})\n",
    "            df.to_csv(f\"{save_path}/subway_indiv_{freq}/subway_indiv_{freq}.csv\")\n",
    "        elif name == 'tram':\n",
    "            raise NotImplementedError(f\"Mode {name} not implemented yet\")\n",
    "        elif name == 'bus':\n",
    "            raise NotImplementedError(f\"Mode {name} not implemented yet\")\n",
    "if False:\n",
    "    save_path = '../../../../data/rrochas/prediction_validation/agg_data/validation_individuelle'\n",
    "    for temp_agg in ['2min','3min','5min','10min','15min','30min','1H']:\n",
    "        df_emitted = df[['id_sortie','date_sortie','id_retour']].groupby(['id_sortie',pd.Grouper(freq=temp_agg,key='date_sortie')]).agg(volume = ('id_retour','count'))\n",
    "        df_attracted = df[['id_sortie','date_retour','id_retour']].groupby(['id_retour',pd.Grouper(freq=temp_agg,key='date_retour')]).agg(volume = ('id_sortie','count'))\n",
    "        df_emitted.to_csv(f\"{save_path}/velov_emitted_by_station{temp_agg}.csv\")\n",
    "        df_attracted.to_csv(f\"{save_path}/velov_attracted_by_station{temp_agg}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>LIB_STA_SIFO</th>\n",
       "      <th>AMP</th>\n",
       "      <th>BEL</th>\n",
       "      <th>BRO</th>\n",
       "      <th>CHA</th>\n",
       "      <th>COR</th>\n",
       "      <th>CPA</th>\n",
       "      <th>CRO</th>\n",
       "      <th>CUI</th>\n",
       "      <th>CUS</th>\n",
       "      <th>DEB</th>\n",
       "      <th>...</th>\n",
       "      <th>PER</th>\n",
       "      <th>GUI</th>\n",
       "      <th>JAU</th>\n",
       "      <th>REP</th>\n",
       "      <th>SAN</th>\n",
       "      <th>SAX</th>\n",
       "      <th>GER</th>\n",
       "      <th>VMY</th>\n",
       "      <th>SOI</th>\n",
       "      <th>JEA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VAL_DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <td>26.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>108.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 04:00:00</th>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 05:00:00</th>\n",
       "      <td>17.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>...</td>\n",
       "      <td>260.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 06:00:00</th>\n",
       "      <td>24.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>...</td>\n",
       "      <td>203.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 07:00:00</th>\n",
       "      <td>32.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>...</td>\n",
       "      <td>242.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 19:00:00</th>\n",
       "      <td>17.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 20:00:00</th>\n",
       "      <td>16.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 21:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 22:00:00</th>\n",
       "      <td>4.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-30 23:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3194 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "LIB_STA_SIFO          AMP    BEL   BRO    CHA    COR   CPA    CRO   CUI   CUS  \\\n",
       "VAL_DATE                                                                        \n",
       "2019-11-01 00:00:00  26.0  250.0  21.0   89.0  133.0  10.0   34.0   1.0   8.0   \n",
       "2019-11-01 04:00:00   2.0   60.0   9.0   34.0   14.0   0.0   10.0   3.0  27.0   \n",
       "2019-11-01 05:00:00  17.0  174.0  34.0  175.0   54.0  12.0   35.0  22.0  40.0   \n",
       "2019-11-01 06:00:00  24.0  142.0  31.0  205.0   91.0   7.0   47.0  28.0  50.0   \n",
       "2019-11-01 07:00:00  32.0  150.0  39.0  267.0   76.0   6.0  107.0  35.0  76.0   \n",
       "...                   ...    ...   ...    ...    ...   ...    ...   ...   ...   \n",
       "2020-03-30 19:00:00  17.0   79.0  21.0  122.0   28.0   3.0   32.0  16.0  23.0   \n",
       "2020-03-30 20:00:00  16.0   73.0  12.0   88.0   26.0   3.0   32.0   9.0  17.0   \n",
       "2020-03-30 21:00:00   4.0   33.0   6.0   63.0   11.0   2.0   11.0   7.0   7.0   \n",
       "2020-03-30 22:00:00   4.0   21.0   3.0   40.0    7.0   1.0    6.0   6.0  10.0   \n",
       "2020-03-30 23:00:00   1.0    6.0   1.0    2.0    3.0   0.0    0.0   0.0   2.0   \n",
       "\n",
       "LIB_STA_SIFO          DEB  ...    PER   GUI   JAU   REP   SAN    SAX    GER  \\\n",
       "VAL_DATE                   ...                                                \n",
       "2019-11-01 00:00:00  24.0  ...  108.0  20.0  23.0  18.0  65.0  103.0   10.0   \n",
       "2019-11-01 04:00:00  14.0  ...   68.0   5.0  15.0   4.0  16.0   15.0   25.0   \n",
       "2019-11-01 05:00:00  72.0  ...  260.0  29.0  85.0  41.0  43.0  128.0  134.0   \n",
       "2019-11-01 06:00:00  83.0  ...  203.0  25.0  91.0  84.0  50.0  149.0  129.0   \n",
       "2019-11-01 07:00:00  71.0  ...  242.0  26.0  95.0  72.0  93.0  187.0   56.0   \n",
       "...                   ...  ...    ...   ...   ...   ...   ...    ...    ...   \n",
       "2020-03-30 19:00:00  27.0  ...   69.0  30.0  37.0  24.0  28.0   88.0   15.0   \n",
       "2020-03-30 20:00:00  20.0  ...   52.0  16.0  28.0  23.0  15.0   48.0    3.0   \n",
       "2020-03-30 21:00:00   8.0  ...   31.0   8.0  10.0   4.0   7.0   34.0    3.0   \n",
       "2020-03-30 22:00:00   8.0  ...   16.0   6.0   3.0   7.0   4.0   17.0    7.0   \n",
       "2020-03-30 23:00:00   0.0  ...    0.0   2.0   2.0   0.0   0.0    6.0    0.0   \n",
       "\n",
       "LIB_STA_SIFO           VMY    SOI   JEA  \n",
       "VAL_DATE                                 \n",
       "2019-11-01 00:00:00   42.0    4.0  97.0  \n",
       "2019-11-01 04:00:00   10.0   27.0  20.0  \n",
       "2019-11-01 05:00:00  107.0   77.0  53.0  \n",
       "2019-11-01 06:00:00  102.0  158.0  68.0  \n",
       "2019-11-01 07:00:00  122.0  166.0  65.0  \n",
       "...                    ...    ...   ...  \n",
       "2020-03-30 19:00:00   47.0   57.0  20.0  \n",
       "2020-03-30 20:00:00   39.0   46.0   7.0  \n",
       "2020-03-30 21:00:00   21.0   34.0   7.0  \n",
       "2020-03-30 22:00:00   14.0   21.0   8.0  \n",
       "2020-03-30 23:00:00    0.0    0.0   0.0  \n",
       "\n",
       "[3194 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de Selection d'une période, avec aggregation temporelle, et sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>LIB_STA_SIFO</th>\n",
       "      <th>AMPERE</th>\n",
       "      <th>BELLECOUR</th>\n",
       "      <th>BROTTEAUX</th>\n",
       "      <th>CHARPENNES</th>\n",
       "      <th>CORDELIERS</th>\n",
       "      <th>CROIX PAQUET</th>\n",
       "      <th>CROIX ROUSSE</th>\n",
       "      <th>CUIRE</th>\n",
       "      <th>CUSSET</th>\n",
       "      <th>DEBOURG</th>\n",
       "      <th>...</th>\n",
       "      <th>PERRACHE</th>\n",
       "      <th>PLACE GUICHARD</th>\n",
       "      <th>PLACE JEAN JAURES</th>\n",
       "      <th>REPUBLIQUE</th>\n",
       "      <th>SANS SOUCI</th>\n",
       "      <th>SAXE GAMBETTA</th>\n",
       "      <th>STADE DE GERLAND</th>\n",
       "      <th>VALMY</th>\n",
       "      <th>VAULX-EN-VELIN LA SOIE</th>\n",
       "      <th>VIEUX LYON</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:00:00</th>\n",
       "      <td>20.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>89.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:15:00</th>\n",
       "      <td>6.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 00:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 23:15:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 23:30:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31 23:45:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14593 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "LIB_STA_SIFO         AMPERE  BELLECOUR  BROTTEAUX  CHARPENNES  CORDELIERS  \\\n",
       "2019-11-01 00:00:00    20.0      164.0       10.0        59.0        88.0   \n",
       "2019-11-01 00:15:00     6.0       82.0       11.0        30.0        43.0   \n",
       "2019-11-01 00:30:00     0.0        4.0        0.0         0.0         2.0   \n",
       "2019-11-01 00:45:00     0.0        0.0        0.0         0.0         0.0   \n",
       "2019-11-01 01:00:00     0.0        0.0        0.0         0.0         0.0   \n",
       "...                     ...        ...        ...         ...         ...   \n",
       "2020-03-31 23:00:00     0.0        0.0        0.0         0.0         0.0   \n",
       "2020-03-31 23:15:00     0.0        0.0        0.0         0.0         0.0   \n",
       "2020-03-31 23:30:00     0.0        0.0        0.0         0.0         0.0   \n",
       "2020-03-31 23:45:00     0.0        0.0        0.0         0.0         0.0   \n",
       "2020-04-01 00:00:00     0.0        0.0        0.0         0.0         0.0   \n",
       "\n",
       "LIB_STA_SIFO         CROIX PAQUET  CROIX ROUSSE  CUIRE  CUSSET  DEBOURG  ...  \\\n",
       "2019-11-01 00:00:00           5.0          20.0    1.0     5.0     21.0  ...   \n",
       "2019-11-01 00:15:00           3.0           8.0    0.0     2.0      3.0  ...   \n",
       "2019-11-01 00:30:00           2.0           6.0    0.0     1.0      0.0  ...   \n",
       "2019-11-01 00:45:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "2019-11-01 01:00:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "...                           ...           ...    ...     ...      ...  ...   \n",
       "2020-03-31 23:00:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "2020-03-31 23:15:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "2020-03-31 23:30:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "2020-03-31 23:45:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "2020-04-01 00:00:00           0.0           0.0    0.0     0.0      0.0  ...   \n",
       "\n",
       "LIB_STA_SIFO         PERRACHE  PLACE GUICHARD  PLACE JEAN JAURES  REPUBLIQUE  \\\n",
       "2019-11-01 00:00:00      89.0            13.0               16.0        12.0   \n",
       "2019-11-01 00:15:00      19.0             7.0                7.0         3.0   \n",
       "2019-11-01 00:30:00       0.0             0.0                0.0         3.0   \n",
       "2019-11-01 00:45:00       0.0             0.0                0.0         0.0   \n",
       "2019-11-01 01:00:00       0.0             0.0                0.0         0.0   \n",
       "...                       ...             ...                ...         ...   \n",
       "2020-03-31 23:00:00       0.0             0.0                0.0         0.0   \n",
       "2020-03-31 23:15:00       0.0             0.0                0.0         0.0   \n",
       "2020-03-31 23:30:00       0.0             0.0                0.0         0.0   \n",
       "2020-03-31 23:45:00       0.0             0.0                0.0         0.0   \n",
       "2020-04-01 00:00:00       0.0             0.0                0.0         0.0   \n",
       "\n",
       "LIB_STA_SIFO         SANS SOUCI  SAXE GAMBETTA  STADE DE GERLAND  VALMY  \\\n",
       "2019-11-01 00:00:00        49.0           68.0               8.0   23.0   \n",
       "2019-11-01 00:15:00        11.0           33.0               2.0   16.0   \n",
       "2019-11-01 00:30:00         5.0            2.0               0.0    3.0   \n",
       "2019-11-01 00:45:00         0.0            0.0               0.0    0.0   \n",
       "2019-11-01 01:00:00         0.0            0.0               0.0    0.0   \n",
       "...                         ...            ...               ...    ...   \n",
       "2020-03-31 23:00:00         0.0            0.0               0.0    0.0   \n",
       "2020-03-31 23:15:00         0.0            0.0               0.0    0.0   \n",
       "2020-03-31 23:30:00         0.0            0.0               0.0    0.0   \n",
       "2020-03-31 23:45:00         0.0            0.0               0.0    0.0   \n",
       "2020-04-01 00:00:00         0.0            0.0               0.0    0.0   \n",
       "\n",
       "LIB_STA_SIFO         VAULX-EN-VELIN LA SOIE  VIEUX LYON  \n",
       "2019-11-01 00:00:00                     3.0        59.0  \n",
       "2019-11-01 00:15:00                     0.0        38.0  \n",
       "2019-11-01 00:30:00                     1.0         0.0  \n",
       "2019-11-01 00:45:00                     0.0         0.0  \n",
       "2019-11-01 01:00:00                     0.0         0.0  \n",
       "...                                     ...         ...  \n",
       "2020-03-31 23:00:00                     0.0         0.0  \n",
       "2020-03-31 23:15:00                     0.0         0.0  \n",
       "2020-03-31 23:30:00                     0.0         0.0  \n",
       "2020-03-31 23:45:00                     0.0         0.0  \n",
       "2020-04-01 00:00:00                     0.0         0.0  \n",
       "\n",
       "[14593 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "\n",
    "time_step_per_hour = 4\n",
    "start,end = datetime(2019,11,1),datetime(2020,4,1)\n",
    "\n",
    "freq = f'{60/time_step_per_hour}min'\n",
    "reindex = pd.date_range(start,end,freq = freq)\n",
    "\n",
    "df_sub.VAL_DATE = pd.to_datetime(df_sub.VAL_DATE)\n",
    "df = df_sub[['Flow','VAL_DATE','CRS_SENS_TRAJET','LIB_STA_SIFO']].groupby(['LIB_STA_SIFO',pd.Grouper(key='VAL_DATE',freq=freq)]).agg(Flow = ('Flow','sum'))\n",
    "df = df.reset_index()\n",
    "df  =df.pivot(index = 'VAL_DATE',columns='LIB_STA_SIFO',values ='Flow').fillna(0)\n",
    "\n",
    "df = df.reindex(reindex,fill_value=0)\n",
    "#df.to_csv(f'data/subway{freq}_from_validation_individuelles_{start.month}_{start.year}_{end.month}_{end.year}.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Subway 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Station</th>\n",
       "      <th>Code ligne</th>\n",
       "      <th>in</th>\n",
       "      <th>out</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>Ampère Victor Hugo</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime             Station Code ligne  in  out\n",
       "0 2019-01-01 00:00:00  Ampère Victor Hugo          A   2  4.0\n",
       "1 2019-01-01 00:15:00  Ampère Victor Hugo          A   3  2.0\n",
       "2 2019-01-01 00:30:00  Ampère Victor Hugo          A   3  7.0\n",
       "3 2019-01-01 00:45:00  Ampère Victor Hugo          A   1  9.0\n",
       "4 2019-01-01 01:00:00  Ampère Victor Hugo          A   0  0.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_path = \"Métro 15 minutes 2019 2020.txt\"\n",
    "\n",
    "df_metro_funi_2019_2020 = load_subway_15_min(f\"{FOLDER_PATH}{txt_path}\")\n",
    "df_metro_funi_2019_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Velo'V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length df:  15586007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_sortie</th>\n",
       "      <th>nom_sortie</th>\n",
       "      <th>date_sortie</th>\n",
       "      <th>id_retour</th>\n",
       "      <th>nom_retour</th>\n",
       "      <th>date_retour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6005</td>\n",
       "      <td>6005 - PLACE EDGAR QUINET</td>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>2024 - RÉPUBLIQUE / MAUPIN</td>\n",
       "      <td>2019-01-01 00:20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10072</td>\n",
       "      <td>10072 - JACQUES BREL</td>\n",
       "      <td>2019-01-01 00:01:00</td>\n",
       "      <td>4012.0</td>\n",
       "      <td>4012 - PLACE ADRIEN GODIEN</td>\n",
       "      <td>2019-01-01 00:09:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6037</td>\n",
       "      <td>6037 - CITÉ INTERNATIONALE / INTERPOL</td>\n",
       "      <td>2019-01-01 00:02:00</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>10025 - TOTEM</td>\n",
       "      <td>2019-01-01 00:32:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3012</td>\n",
       "      <td>3012 - PLACE DU CHÂTEAU</td>\n",
       "      <td>2019-01-01 00:06:00</td>\n",
       "      <td>7002.0</td>\n",
       "      <td>7002 - UNIVERSITÉS LYON III / LYON II</td>\n",
       "      <td>2019-01-01 00:26:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002</td>\n",
       "      <td>1002 - OPÉRA</td>\n",
       "      <td>2019-01-01 00:07:00</td>\n",
       "      <td>7056.0</td>\n",
       "      <td>7056 - PLACE RASPAIL</td>\n",
       "      <td>2019-01-01 00:22:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_sortie                             nom_sortie         date_sortie  \\\n",
       "0       6005              6005 - PLACE EDGAR QUINET 2019-01-01 00:00:00   \n",
       "1      10072                   10072 - JACQUES BREL 2019-01-01 00:01:00   \n",
       "2       6037  6037 - CITÉ INTERNATIONALE / INTERPOL 2019-01-01 00:02:00   \n",
       "3       3012                3012 - PLACE DU CHÂTEAU 2019-01-01 00:06:00   \n",
       "4       1002                           1002 - OPÉRA 2019-01-01 00:07:00   \n",
       "\n",
       "   id_retour                             nom_retour         date_retour  \n",
       "0     2024.0             2024 - RÉPUBLIQUE / MAUPIN 2019-01-01 00:20:00  \n",
       "1     4012.0             4012 - PLACE ADRIEN GODIEN 2019-01-01 00:09:00  \n",
       "2    10025.0                          10025 - TOTEM 2019-01-01 00:32:00  \n",
       "3     7002.0  7002 - UNIVERSITÉS LYON III / LYON II 2019-01-01 00:26:00  \n",
       "4     7056.0                   7056 - PLACE RASPAIL 2019-01-01 00:22:00  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import sys \n",
    "import pandas as pd\n",
    "import chardet\n",
    "import json \n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "def get_velov_data(year,quarter,folder_path):\n",
    "    ''' Return shared bike dataframe from \"Lyon Velov\"  \n",
    "    'year' in [2019,2020]\n",
    "    'quarter' in ['T1','T2','T3','T4']\n",
    "    '''\n",
    "    # usefull to get the \"encoding\" of the csv, so that \"pd.read_csv\" can work well\n",
    "    pathway = f'{folder_path}/Trajets VELOV {year}/VELOV_TRAJETS_{str(year)}_{quarter}.csv'\n",
    "    with open(pathway, 'rb') as rawdata:\n",
    "        result = chardet.detect(rawdata.read(100000))      \n",
    "    # ...\n",
    "    \n",
    "    df_velov = pd.read_csv(pathway, encoding = result['encoding'], sep = \";\")\n",
    "    df_velov.columns=['id_sortie','nom_sortie','date_sortie','id_retour','nom_retour','date_retour']\n",
    "    df_velov.date_sortie = pd.to_datetime(df_velov.date_sortie)\n",
    "    df_velov.date_retour = pd.to_datetime(df_velov.date_retour)\n",
    "    return(df_velov)\n",
    "\n",
    "\n",
    "\n",
    "FOLDER_PATH = '../../../data/rrochas/raw_data/VELO-LYON'\n",
    "df = pd.concat([get_velov_data(year,Ti,FOLDER_PATH) for year in [2019,2020] for Ti in ['T1','T2','T3','T4']]) \n",
    "print('length df: ',len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_save_path = 'velov_map.html'\n",
    "json_path = 'locations/pvo_patrimoine_voirie.pvostationvelov.json'\n",
    "stations_json = json.load(open(f\"{FOLDER_PATH}/{json_path}\",'rb'))\n",
    "\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    [\n",
    "        {**feat['properties'],\n",
    "         'geometry': Point(*feat['geometry']['coordinates'])}\n",
    "        for feat in stations_json['features']\n",
    "    ],\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save:\n",
    "if False:\n",
    "    save_path = '../../../../data/rrochas/prediction_validation/agg_data/velov'\n",
    "    for temp_agg in ['2min','3min','5min','10min','15min','30min','1H']:\n",
    "        df_emitted = df[['id_sortie','date_sortie','id_retour']].groupby(['id_sortie',pd.Grouper(freq=temp_agg,key='date_sortie')]).agg(volume = ('id_retour','count'))\n",
    "        df_attracted = df[['id_sortie','date_retour','id_retour']].groupby(['id_retour',pd.Grouper(freq=temp_agg,key='date_retour')]).agg(volume = ('id_sortie','count'))\n",
    "        df_emitted.to_csv(f\"{save_path}/velov_emitted_by_station{temp_agg}.csv\")\n",
    "        df_attracted.to_csv(f\"{save_path}/velov_attracted_by_station{temp_agg}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NetMob 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PATH = '../../Data/NetMob/'\n",
    "apps = [app for app in os.listdir(FOLDER_PATH) if ((app != 'Lyon.geojson') and (not app.startswith('.'))) ]   # Avoid hidden folder and Lyon.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Data/NetMob//Apple_Video/20190504/Lyon_Apple_Video_20190504_DL.txt',\n",
       " '../../Data/NetMob//Apple_Video/20190504/Lyon_Apple_Video_20190504_UL.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = apps[0]\n",
    "folder_days = [day for day in os.listdir(f'{FOLDER_PATH}/{app}') if (not day.startswith('.')) ] \n",
    "day = folder_days[0]\n",
    "txt_paths = sorted(glob.glob(os.path.join(f'{FOLDER_PATH}/{app}/{day}', \"*.txt\")))\n",
    "txt_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00:00</th>\n",
       "      <th>00:15</th>\n",
       "      <th>00:30</th>\n",
       "      <th>00:45</th>\n",
       "      <th>01:00</th>\n",
       "      <th>01:15</th>\n",
       "      <th>01:30</th>\n",
       "      <th>01:45</th>\n",
       "      <th>02:00</th>\n",
       "      <th>02:15</th>\n",
       "      <th>...</th>\n",
       "      <th>21:30</th>\n",
       "      <th>21:45</th>\n",
       "      <th>22:00</th>\n",
       "      <th>22:15</th>\n",
       "      <th>22:30</th>\n",
       "      <th>22:45</th>\n",
       "      <th>23:00</th>\n",
       "      <th>23:15</th>\n",
       "      <th>23:30</th>\n",
       "      <th>23:45</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1834</td>\n",
       "      <td>1596</td>\n",
       "      <td>1378</td>\n",
       "      <td>1575</td>\n",
       "      <td>637</td>\n",
       "      <td>421</td>\n",
       "      <td>203</td>\n",
       "      <td>1366</td>\n",
       "      <td>547</td>\n",
       "      <td>254</td>\n",
       "      <td>...</td>\n",
       "      <td>4114</td>\n",
       "      <td>2992</td>\n",
       "      <td>2887</td>\n",
       "      <td>3297</td>\n",
       "      <td>4634</td>\n",
       "      <td>4208</td>\n",
       "      <td>4886</td>\n",
       "      <td>2095</td>\n",
       "      <td>2066</td>\n",
       "      <td>919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>2000</td>\n",
       "      <td>1687</td>\n",
       "      <td>1357</td>\n",
       "      <td>1548</td>\n",
       "      <td>764</td>\n",
       "      <td>484</td>\n",
       "      <td>195</td>\n",
       "      <td>2492</td>\n",
       "      <td>591</td>\n",
       "      <td>407</td>\n",
       "      <td>...</td>\n",
       "      <td>4673</td>\n",
       "      <td>3288</td>\n",
       "      <td>3156</td>\n",
       "      <td>3778</td>\n",
       "      <td>5123</td>\n",
       "      <td>4400</td>\n",
       "      <td>5300</td>\n",
       "      <td>2187</td>\n",
       "      <td>2176</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>1621</td>\n",
       "      <td>1540</td>\n",
       "      <td>1258</td>\n",
       "      <td>1381</td>\n",
       "      <td>490</td>\n",
       "      <td>375</td>\n",
       "      <td>94</td>\n",
       "      <td>1131</td>\n",
       "      <td>453</td>\n",
       "      <td>302</td>\n",
       "      <td>...</td>\n",
       "      <td>3887</td>\n",
       "      <td>3128</td>\n",
       "      <td>3048</td>\n",
       "      <td>3337</td>\n",
       "      <td>4582</td>\n",
       "      <td>3792</td>\n",
       "      <td>4519</td>\n",
       "      <td>2189</td>\n",
       "      <td>2309</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1803</td>\n",
       "      <td>1493</td>\n",
       "      <td>1201</td>\n",
       "      <td>1332</td>\n",
       "      <td>632</td>\n",
       "      <td>514</td>\n",
       "      <td>73</td>\n",
       "      <td>2951</td>\n",
       "      <td>428</td>\n",
       "      <td>370</td>\n",
       "      <td>...</td>\n",
       "      <td>4404</td>\n",
       "      <td>3352</td>\n",
       "      <td>3082</td>\n",
       "      <td>3512</td>\n",
       "      <td>4697</td>\n",
       "      <td>4056</td>\n",
       "      <td>4862</td>\n",
       "      <td>2155</td>\n",
       "      <td>2156</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1621</td>\n",
       "      <td>1583</td>\n",
       "      <td>1296</td>\n",
       "      <td>1383</td>\n",
       "      <td>493</td>\n",
       "      <td>415</td>\n",
       "      <td>75</td>\n",
       "      <td>1087</td>\n",
       "      <td>402</td>\n",
       "      <td>368</td>\n",
       "      <td>...</td>\n",
       "      <td>4064</td>\n",
       "      <td>3426</td>\n",
       "      <td>3206</td>\n",
       "      <td>3517</td>\n",
       "      <td>4834</td>\n",
       "      <td>4011</td>\n",
       "      <td>4719</td>\n",
       "      <td>2256</td>\n",
       "      <td>2230</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         00:00  00:15  00:30  00:45  01:00  01:15  01:30  01:45  02:00  02:15  \\\n",
       "tile_id                                                                         \n",
       "66        1834   1596   1378   1575    637    421    203   1366    547    254   \n",
       "353       2000   1687   1357   1548    764    484    195   2492    591    407   \n",
       "354       1621   1540   1258   1381    490    375     94   1131    453    302   \n",
       "640       1803   1493   1201   1332    632    514     73   2951    428    370   \n",
       "641       1621   1583   1296   1383    493    415     75   1087    402    368   \n",
       "\n",
       "         ...  21:30  21:45  22:00  22:15  22:30  22:45  23:00  23:15  23:30  \\\n",
       "tile_id  ...                                                                  \n",
       "66       ...   4114   2992   2887   3297   4634   4208   4886   2095   2066   \n",
       "353      ...   4673   3288   3156   3778   5123   4400   5300   2187   2176   \n",
       "354      ...   3887   3128   3048   3337   4582   3792   4519   2189   2309   \n",
       "640      ...   4404   3352   3082   3512   4697   4056   4862   2155   2156   \n",
       "641      ...   4064   3426   3206   3517   4834   4011   4719   2256   2230   \n",
       "\n",
       "         23:45  \n",
       "tile_id         \n",
       "66         919  \n",
       "353        984  \n",
       "354        984  \n",
       "640       1074  \n",
       "641       1073  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_path = txt_paths[0]\n",
    "df_Apple_Vid_DL = load_netmob(txt_path,day)\n",
    "df_Apple_Vid_DL.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sensor 6 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2019,2020]\n",
    "#FOLDER_PATH = '../../Data/Comptages_Velo_Routier/CRITER/'\n",
    "FOLDER_PATH = '../../../data/rrochas/raw_data/Comptages_Velo_Routier/CRITER/'\n",
    "list_files = sorted(glob.glob(os.path.join(f'{FOLDER_PATH}6 min {years[0]}', \"*.txt\"))) + sorted(glob.glob(os.path.join(f'{FOLDER_PATH}6 min {years[1]}', \"*.txt\")))\n",
    "oct_2019_mar_2020 = list_files[9:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rrochas/prediction-validation/build_inputs/load_raw_data.py:48: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(txt_path, sep=';',infer_datetime_format=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../data/rrochas/raw_data/Comptages_Velo_Routier/CRITER/6 min 2019/6mn_01_Janvier_2019.txt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_POINT_MESURE</th>\n",
       "      <th>NOM_POINT_MESURE</th>\n",
       "      <th>DEBIT_HEURE</th>\n",
       "      <th>TAUX_HEURE</th>\n",
       "      <th>HORODATE</th>\n",
       "      <th>NOMBRE_ECH_1_MIN_MANQUANTS</th>\n",
       "      <th>day</th>\n",
       "      <th>str_hour_min</th>\n",
       "      <th>hour_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Berthelot_Servant_Mace</td>\n",
       "      <td>380</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0:0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Berthelot_Servant_Mace</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-01 00:06:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0:6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Berthelot_Servant_Mace</td>\n",
       "      <td>270</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-01 00:12:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0:12</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Berthelot_Servant_Mace</td>\n",
       "      <td>270</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-01 00:18:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0:18</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Berthelot_Servant_Mace</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-01 00:24:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0:24</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_POINT_MESURE        NOM_POINT_MESURE  DEBIT_HEURE  TAUX_HEURE  \\\n",
       "0                1  Berthelot_Servant_Mace          380           3   \n",
       "1                1  Berthelot_Servant_Mace          240           2   \n",
       "2                1  Berthelot_Servant_Mace          270           2   \n",
       "3                1  Berthelot_Servant_Mace          270           2   \n",
       "4                1  Berthelot_Servant_Mace          200           1   \n",
       "\n",
       "             HORODATE  NOMBRE_ECH_1_MIN_MANQUANTS  day str_hour_min  hour_min  \n",
       "0 2019-10-01 00:00:00                           0    1          0:0       0.0  \n",
       "1 2019-10-01 00:06:00                           0    1          0:6       1.0  \n",
       "2 2019-10-01 00:12:00                           0    1         0:12       2.0  \n",
       "3 2019-10-01 00:18:00                           0    1         0:18       3.0  \n",
       "4 2019-10-01 00:24:00                           0    1         0:24       4.0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_CRITER(oct_2019_mar_2020[0])\n",
    "len_init = len(df)\n",
    "print((list_files[0]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1er Etape : Prédiction Métro\n",
    "- On va d'abord prédire la demande sur une ligne (disons A).  \n",
    "- On va comparer des modèle : LSTM, CNN, CNN-LSTM, GNN.\n",
    "    - A priori pas de \"raison\" que le GNN marche mieux. Si c'est le cas, c'est peut être simplement que le modèle est plus complexe, mais j'ai du mal à croire que si on donne les bonnes informations (historique -7d, -1d, -4,3,2,1t), on a des meilleurs résultats avec GNN. Sauf si il y a des relation asynchrone \"récurrentes\", mais sans causalité. De la même manière que l'historique -7d sert de référence, mais ne témoigne pas d'un lien causal.\n",
    "- Identifier des moments interessants : anomalies sur entrée/sortie métro. Voir les prédictions sur ces moments là particulier.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Preprocessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
