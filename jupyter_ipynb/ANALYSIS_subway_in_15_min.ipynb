{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de Subway_in  :\n",
    "**Code Bokeh qui fonctionne pas bien. Il faudrait faire un checkbox en menu déroulant, pas tout afficher d'un coup, un bouton pour tout désactiver car 40 plot c'est long. Rajouter un 'hover', etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtenir le chemin du dossier parent\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "# current_path = os.path.dirname()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "\n",
    "# Ajouter le dossier parent au chemin de recherche des modules\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(Kt=3, stblock_num=2, Ks=2, graph_conv_type='graph_conv', gso_type='sym_norm_lap', enable_bias=True, adj_type='corr', enable_padding=True, threeshold=0.3, act_func='glu', input_dim=1, h_dim=16, C_outs=[16, 1], num_layers=2, bias=True, bidirectional=True, lstm=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "for model_name in ['STGCN','LSTM']:\n",
    "    file_path = f\"dl_models.{model_name}.load_config\"\n",
    "    config_file = importlib.import_module(file_path)\n",
    "    globals()[f\"args_{model_name}\"] = config_file.args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(input_dim=1, h_dim=16, C_outs=[16, 1], num_layers=2, bias=True, bidirectional=True, lstm=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_inputs.load_adj import load_adj\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import linalg\n",
    "\n",
    "\n",
    "adj_mx,n_vertex = load_adj(adj_type = 'adj')\n",
    "sp_adj_mx = sp.coo_matrix(adj_mx.T)\n",
    "d = np.array(sp_adj_mx.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from bokeh.models import Legend, LegendItem,HoverTool\n",
    "from bokeh.palettes import Turbo256\n",
    "from bokeh.layouts import row\n",
    "\n",
    "# Personnal Import \n",
    "from utils.utilities_DL import load_raw_data\n",
    "from dataset import DataSet\n",
    "# ...\n",
    "\n",
    "# Paths\n",
    "FOLDER_PATH = 'data/'\n",
    "\n",
    "#Init and load data: \n",
    "H,W,D = 6,1,1\n",
    "L = H+W+D \n",
    "step_ahead = 1\n",
    "\n",
    "window_pred = np.arange(2*96)\n",
    "\n",
    "FILE_NAME = 'subway_IN_interpol_neg_15_min_2019_2020.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_raw_data() missing 1 required positional argument: 'FILE_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vc/gn83ctb97rd5lmlbh8djj9fr0000gr/T/ipykernel_3714/633685688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load df, remove forbidden values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvalid_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_step_per_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLDER_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msingle_station\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_step_per_hour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step_per_hour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeeks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_len\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_ahead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_ahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shift_between_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# get shift indice and shift date from the first element / between each dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Build 'df_shifted'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_raw_data() missing 1 required positional argument: 'FILE_NAME'"
     ]
    }
   ],
   "source": [
    "# Load df, remove forbidden values: \n",
    "df,invalid_dates,time_step_per_hour = load_raw_data(FOLDER_PATH,FILE_NAME,single_station = False)\n",
    "dataset = DataSet(df,time_step_per_hour=time_step_per_hour, Weeks = W, Days = D, historical_len= H,step_ahead=step_ahead)\n",
    "dataset.get_shift_between_set()   # get shift indice and shift date from the first element / between each dataset \n",
    "dataset.get_feature_vect()  # Build 'df_shifted'.\n",
    "dataset.remove_forbidden_prediction(invalid_dates) # Build 'df_verif' , which is df_shifted without sequences which contains invalid date\n",
    "\n",
    "# Find atypical Value. Check if we need to modify them.\n",
    "valid_df = dataset.df[~(dataset.df.index.isin(invalid_dates))]\n",
    "limit = 1500\n",
    "all_plot = False\n",
    "\n",
    "p = figure(x_axis_type='datetime', height=600, width=1400, sizing_mode=\"scale_width\")\n",
    "\n",
    "# Stocker les renderers pour les ajouter à la légende\n",
    "renderers = []\n",
    "\n",
    "if all_plot:\n",
    "    for i, column in enumerate(df.columns):\n",
    "        x, y = df.index, df[column]\n",
    "        color = Turbo256[int(256 / len(df.columns) * i)]  \n",
    "        renderer = p.line(x, y, line_width=2, color=color, alpha=0.8, legend_label=column, muted_color=color, muted_alpha=0)\n",
    "        renderer.visible = False\n",
    "        renderers.append(renderer)\n",
    "\n",
    "    legend = Legend(items=[LegendItem(label=col, renderers=[rend], index=i) for i, (col, rend) in enumerate(zip(df.columns, renderers))])\n",
    "\n",
    "else:\n",
    "\n",
    "    for i,column in enumerate(valid_df):\n",
    "        color = Turbo256[int(256 / len(df.columns) * i)]  \n",
    "        sub_df = valid_df[valid_df[column] > limit]\n",
    "        if not sub_df.empty:\n",
    "            x,y = sub_df.index,sub_df[column]\n",
    "            renderer = p.scatter(x, y, color=color, alpha=0.8, legend_label=column, muted_color=color, muted_alpha=0)\n",
    "            renderers.append(renderer)\n",
    "\n",
    "    x,y = dataset.df.index,dataset.df.quantile(0.9,axis = 1)\n",
    "    renderer = p.line(x, y, line_width=2, color='black', alpha=0.8, legend_label='all_stations', muted_color=color, muted_alpha=0)\n",
    "    renderers.append(renderer)\n",
    "\n",
    "    legend = Legend(items=[LegendItem(label=col, renderers=[rend], index=i) for i, (col, rend) in enumerate(zip(list(df.columns)+['all_stations'], renderers))])  \n",
    "\n",
    "\n",
    "p.add_layout(legend, 'right')\n",
    "p.legend.click_policy = \"mute\"\n",
    "hover = HoverTool()\n",
    "p.add_tools(hover)\n",
    "output_notebook()\n",
    "show(p) \n",
    "\n",
    "saving = False\n",
    "if saving:\n",
    "    output_file(\"df_IN_outliers.html\")\n",
    "save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(x_axis_type='datetime', height=600, width=1400, sizing_mode=\"scale_width\")\n",
    "\n",
    "column = 'Ampère Victor Hugo'\n",
    "column = 'Bellecour'\n",
    "x,y = dataset.df.index,dataset.df[column]\n",
    "\n",
    "renderer = p.line(x, y, color='blue', alpha=0.8, legend_label=column, muted_color=color, muted_alpha=0)\n",
    "\n",
    "output_notebook() \n",
    "show(p)\n",
    "\n",
    "output_file(f\"df_IN_{column}.html\")\n",
    "save(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessingclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
