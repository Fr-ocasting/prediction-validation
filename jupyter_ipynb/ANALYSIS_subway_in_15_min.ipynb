{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de Subway_in  :\n",
    "**Code Bokeh qui fonctionne pas bien. Il faudrait faire un checkbox en menu déroulant, pas tout afficher d'un coup, un bouton pour tout désactiver car 40 plot c'est long. Rajouter un 'hover', etc...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"addmm_sparse_cuda\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Multiplication avec la matrice sparse\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     support_float32 \u001b[38;5;241m=\u001b[39m support\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Assurez-vous que support est float32\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43msupport_float32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0_float32\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Multiplication en float32\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Continuer avec d'autres opérations en précisions mixtes\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# result = some_other_operation(x1)  # Exemples d'autres opérations\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# scaler.step(optimizer)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# scaler.update()\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResult:\u001b[39m\u001b[38;5;124m\"\u001b[39m, x1)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"addmm_sparse_cuda\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Initialisation de GradScaler pour la gestion de la précision mixte\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Créer un tenseur sparse\n",
    "indices = torch.tensor([[0, 1], [2, 0]], device='cuda')  # Indices de la matrice sparse sur GPU\n",
    "values = torch.tensor([3.0, 4.0], dtype=torch.float32, device='cuda')  # Valeurs sur GPU\n",
    "size = torch.Size([3, 3])\n",
    "support = torch.sparse.FloatTensor(indices.t(), values, size).to('cuda')  # Matrice sparse sur GPU\n",
    "\n",
    "# Créer un tenseur dense en float16 pour mixed precision\n",
    "x0 = torch.rand((3, 2), dtype=torch.float16, device='cuda')  # Exemple de matrice dense sur GPU\n",
    "\n",
    "# Utiliser autocast pour la précision mixte\n",
    "with autocast():\n",
    "    # Convertir x0 en float32 pour l'opération sparse\n",
    "    x0_float32 = x0.to(torch.float32)  # Convertir x0 en float32\n",
    "\n",
    "    # Multiplication avec la matrice sparse\n",
    "    support_float32 = support.to(torch.float32)  # Assurez-vous que support est float32\n",
    "    x1 = torch.sparse.mm(support_float32, x0_float32)  # Multiplication en float32\n",
    "\n",
    "    # Continuer avec d'autres opérations en précisions mixtes\n",
    "    # result = some_other_operation(x1)  # Exemples d'autres opérations\n",
    "\n",
    "# Utilisation de GradScaler pour la rétropropagation\n",
    "# optimizer.zero_grad()\n",
    "# scaler.scale(loss).backward()  # Exemple de calcul de perte\n",
    "# scaler.step(optimizer)\n",
    "# scaler.update()\n",
    "\n",
    "print(\"Result:\", x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(crow_indices=tensor([0, 3, 6, 9]),\n",
       "       col_indices=tensor([0, 1, 2, 0, 1, 2, 0, 1, 2]),\n",
       "       values=tensor([ 0.7266, -0.0333, -0.1309, -2.1055,  1.4854,  0.1091,\n",
       "                       3.5449, -1.5596, -0.5527]), device='cuda:0',\n",
       "       size=(3, 3), nnz=9, dtype=torch.float16, layout=torch.sparse_csr)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda'\n",
    "\n",
    "t = torch.randn(3,3).to(torch.float16).to(device).to_sparse_csr()\n",
    "a = torch.randn(3,3).to(torch.float16).to(device).to_sparse_csr()\n",
    "torch.sparse.mm(t,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Obtenir le chemin du dossier parent\n",
    "current_path = notebook_dir = os.getcwd()\n",
    "# current_path = os.path.dirname()\n",
    "parent_dir = os.path.abspath(os.path.join(current_path, '..'))\n",
    "\n",
    "# Ajouter le dossier parent au chemin de recherche des modules\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook, output_file, save\n",
    "from bokeh.models import Legend, LegendItem,HoverTool\n",
    "from bokeh.palettes import Turbo256\n",
    "from bokeh.layouts import row\n",
    "\n",
    "# Personnal Import \n",
    "from utils.utilities_DL import load_raw_data\n",
    "from dataset import DataSet\n",
    "# ...\n",
    "\n",
    "# Paths\n",
    "FOLDER_PATH = 'data/'\n",
    "\n",
    "#Init and load data: \n",
    "H,W,D = 6,1,1\n",
    "L = H+W+D \n",
    "step_ahead = 1\n",
    "\n",
    "window_pred = np.arange(2*96)\n",
    "\n",
    "FILE_NAME = 'subway_IN_interpol_neg_15_min_2019_2020.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_raw_data() missing 1 required positional argument: 'FILE_NAME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vc/gn83ctb97rd5lmlbh8djj9fr0000gr/T/ipykernel_3714/633685688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load df, remove forbidden values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minvalid_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_step_per_hour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_raw_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFOLDER_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFILE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msingle_station\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime_step_per_hour\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_step_per_hour\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeeks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistorical_len\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep_ahead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_ahead\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shift_between_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# get shift indice and shift date from the first element / between each dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_vect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Build 'df_shifted'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_raw_data() missing 1 required positional argument: 'FILE_NAME'"
     ]
    }
   ],
   "source": [
    "# Load df, remove forbidden values: \n",
    "df,invalid_dates,time_step_per_hour = load_raw_data(FOLDER_PATH,FILE_NAME,single_station = False)\n",
    "dataset = DataSet(df,time_step_per_hour=time_step_per_hour, Weeks = W, Days = D, historical_len= H,step_ahead=step_ahead)\n",
    "dataset.get_shift_between_set()   # get shift indice and shift date from the first element / between each dataset \n",
    "dataset.get_feature_vect()  # Build 'df_shifted'.\n",
    "dataset.remove_forbidden_prediction(invalid_dates) # Build 'df_verif' , which is df_shifted without sequences which contains invalid date\n",
    "\n",
    "# Find atypical Value. Check if we need to modify them.\n",
    "valid_df = dataset.df[~(dataset.df.index.isin(invalid_dates))]\n",
    "limit = 1500\n",
    "all_plot = False\n",
    "\n",
    "p = figure(x_axis_type='datetime', height=600, width=1400, sizing_mode=\"scale_width\")\n",
    "\n",
    "# Stocker les renderers pour les ajouter à la légende\n",
    "renderers = []\n",
    "\n",
    "if all_plot:\n",
    "    for i, column in enumerate(df.columns):\n",
    "        x, y = df.index, df[column]\n",
    "        color = Turbo256[int(256 / len(df.columns) * i)]  \n",
    "        renderer = p.line(x, y, line_width=2, color=color, alpha=0.8, legend_label=column, muted_color=color, muted_alpha=0)\n",
    "        renderer.visible = False\n",
    "        renderers.append(renderer)\n",
    "\n",
    "    legend = Legend(items=[LegendItem(label=col, renderers=[rend], index=i) for i, (col, rend) in enumerate(zip(df.columns, renderers))])\n",
    "\n",
    "else:\n",
    "\n",
    "    for i,column in enumerate(valid_df):\n",
    "        color = Turbo256[int(256 / len(df.columns) * i)]  \n",
    "        sub_df = valid_df[valid_df[column] > limit]\n",
    "        if not sub_df.empty:\n",
    "            x,y = sub_df.index,sub_df[column]\n",
    "            renderer = p.scatter(x, y, color=color, alpha=0.8, legend_label=column, muted_color=color, muted_alpha=0)\n",
    "            renderers.append(renderer)\n",
    "\n",
    "    x,y = dataset.df.index,dataset.df.quantile(0.9,axis = 1)\n",
    "    renderer = p.line(x, y, line_width=2, color='black', alpha=0.8, legend_label='all_stations', muted_color=color, muted_alpha=0)\n",
    "    renderers.append(renderer)\n",
    "\n",
    "    legend = Legend(items=[LegendItem(label=col, renderers=[rend], index=i) for i, (col, rend) in enumerate(zip(list(df.columns)+['all_stations'], renderers))])  \n",
    "\n",
    "\n",
    "p.add_layout(legend, 'right')\n",
    "p.legend.click_policy = \"mute\"\n",
    "hover = HoverTool()\n",
    "p.add_tools(hover)\n",
    "output_notebook()\n",
    "show(p) \n",
    "\n",
    "saving = False\n",
    "if saving:\n",
    "    output_file(\"df_IN_outliers.html\")\n",
    "save(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = figure(x_axis_type='datetime', height=600, width=1400, sizing_mode=\"scale_width\")\n",
    "\n",
    "column = 'Ampère Victor Hugo'\n",
    "column = 'Bellecour'\n",
    "x,y = dataset.df.index,dataset.df[column]\n",
    "\n",
    "renderer = p.line(x, y, color='blue', alpha=0.8, legend_label=column, muted_color=color, muted_alpha=0)\n",
    "\n",
    "output_notebook() \n",
    "show(p)\n",
    "\n",
    "output_file(f\"df_IN_{column}.html\")\n",
    "save(p)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "preprocessingclone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
