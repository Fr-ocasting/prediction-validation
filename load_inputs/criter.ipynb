{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "current_file_path = os.getcwd()\n",
    "parent_dir = os.path.abspath(os.path.join(current_file_path,'..'))\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0,parent_dir)\n",
    "\n",
    "from dataset import DataSet\n",
    "from datetime import datetime \n",
    "from utils.utilities import filter_args\n",
    "from constants.paths import USELESS_DATES,FOLDER_PATH\n",
    "''' This file has to :\n",
    " - return a DataSet object, with specified data, and spatial_units.\n",
    " - add argument 'n_vertex', 'C' to the NameSpace. These are specific to this data\n",
    " - Detail 'INVALID_DATE' and the 'coverage' period of the dataset.\n",
    "'''\n",
    "\n",
    "FILE_NAME = 'CRITER_3lanes/CRITER_3lanes'\n",
    "\n",
    "list_of_invalid_period = []\n",
    "#ist_of_invalid_period.append([datetime(2019,1,10,15,30),datetime(2019,1,14,15,30)])\n",
    "\n",
    "\n",
    "INVALID_DATES = []\n",
    "for start,end in list_of_invalid_period:\n",
    "    INVALID_DATES = INVALID_DATES + list(pd.date_range(start,end,freq = f'15min'))\n",
    "C = 1\n",
    "n_vertex = 40\n",
    "COVERAGE = pd.date_range(start='01/01/2019', end='01/01/2020', freq='15min')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_period = None\n",
    "freq = '30min'\n",
    "time_step_per_hour = 2\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for month_name in ['Mars','Avril','Mai']:\n",
    "    df_i = pd.read_csv(f\"{parent_dir}/{FOLDER_PATH}/{FILE_NAME}_{month_name}.csv\",index_col = 0)\n",
    "    df_i.HORODATE = pd.to_datetime(df_i.HORODATE)\n",
    "    df_i = df_i.groupby(['ID_POINT_MESURE',pd.Grouper(key = 'HORODATE',freq=freq)]).mean()\n",
    "    df = pd.concat([df,df_i])\n",
    "    df = df.reset_index()\n",
    "    if coverage_period is not None:\n",
    "        df = df[(df.HORODATE <= coverage_period.max())&(df.HORODATE >= coverage_period.min()) ]\n",
    "    df_loop_occupancy_rate = df.pivot_table(index = 'HORODATE',column = 'ID_POINT_MESURE',value = 'TAUX_HEURE')\n",
    "    df_flow = df.pivot_table(index = 'HORODATE',column = 'ID_POINT_MESURE',value = 'DEBIT_HEURE')\n",
    "\n",
    "    for df_i,name_i in zip([df_loop_occupancy_rate,df_flow],['loop_occupancy_rate','flow']):\n",
    "        df_i.columns.name = 'sensor'\n",
    "        \n",
    "        if (hasattr(args,'set_spatial_units')) and (args.set_spatial_units is not None) :\n",
    "            print('Considered Spatial-Unit: ',args.set_spatial_units)\n",
    "            spatial_unit = args.set_spatial_units\n",
    "            indices_spatial_unit = [list(df_i.columns).index(station_i) for station_i in  spatial_unit]\n",
    "            df_i = df_i[spatial_unit]\n",
    "        else:\n",
    "            spatial_unit = df_i.columns\n",
    "            indices_spatial_unit = np.arange(len(df_i.columns))\n",
    "\n",
    "        weekly_period =  int((24-len(USELESS_DATES['hour']))*(7-len(USELESS_DATES['weekday']))*time_step_per_hour)\n",
    "        daily_period =  int((24-len(USELESS_DATES['hour']))*time_step_per_hour)\n",
    "        periods = [weekly_period,daily_period]  \n",
    "\n",
    "        args_DataSet = filter_args(DataSet, args)\n",
    "\n",
    "        globals()[f\"ataset_{name_i}\"] = DataSet(df_i,\n",
    "                        time_step_per_hour=time_step_per_hour, \n",
    "                        spatial_unit = spatial_unit,\n",
    "                        indices_spatial_unit = indices_spatial_unit,\n",
    "                        dims = [0],\n",
    "                        city = 'Lyon',\n",
    "                        periods = periods,\n",
    "                        **args_DataSet)\n",
    "    return globals()[f\"dataset_loop_occupancy_rate\"],globals()[f\"dataset_flow\"]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    df.columns.name = 'Station'\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "\n",
    "    df = restrain_df_to_specific_period(df,coverage_period)\n",
    "    time_step_per_hour = (60*60)/(df.iloc[1].name - df.iloc[0].name).seconds\n",
    "    assert time_step_per_hour == 4, 'TIME STEP PER HOUR = {time_step_per_hour} ALORS QU ON VEUT =4 '\n",
    "\n",
    "    df_correspondance = get_trigram_correspondance()\n",
    "    df_correspondance.set_index('Station').reindex(df.columns)\n",
    "    df.columns = df_correspondance.COD_TRG\n",
    "\n",
    "    # Remove ouliers\n",
    "    df = remove_outliers(df)\n",
    "\n",
    "    if (hasattr(args,'set_spatial_units')) and (args.set_spatial_units is not None) :\n",
    "        print('Considered Spatial-Unit: ',args.set_spatial_units)\n",
    "        spatial_unit = args.set_spatial_units\n",
    "        indices_spatial_unit = [list(df.columns).index(station_i) for station_i in  spatial_unit]\n",
    "        df = df[spatial_unit]\n",
    "    else:\n",
    "        spatial_unit = df.columns\n",
    "        indices_spatial_unit = np.arange(len(df.columns))\n",
    "\n",
    "    weekly_period =  int((24-len(USELESS_DATES['hour']))*(7-len(USELESS_DATES['weekday']))*time_step_per_hour)\n",
    "    daily_period =  int((24-len(USELESS_DATES['hour']))*time_step_per_hour)\n",
    "    periods = [weekly_period,daily_period]  \n",
    "\n",
    "    args_DataSet = filter_args(DataSet, args)\n",
    "\n",
    "    dataset = DataSet(df,\n",
    "                      time_step_per_hour=time_step_per_hour, \n",
    "                      spatial_unit = spatial_unit,\n",
    "                      indices_spatial_unit = indices_spatial_unit,\n",
    "                      dims = [0],\n",
    "                      city = 'Lyon',\n",
    "                      periods = periods,\n",
    "                      **args_DataSet)\n",
    "\n",
    "    return(dataset)\n",
    "    \n",
    "\n",
    "def remove_outliers(df):\n",
    "    '''\n",
    "    Replace the outliers by linear interpolation. Outliers are identified as MaxiMum flow recorded during the 'light festival' in Lyon. \n",
    "    It's an atypical event which reach the highest possible flow. Having higher flow on passenger is almost impossible.\n",
    "    '''\n",
    "    limits = {\n",
    "        'BEL': 2700,\n",
    "        'CHA': 1700,\n",
    "        'GOR': 1700\n",
    "    }\n",
    "    default_limit = 1500\n",
    "\n",
    "    # Appliquer les limites\n",
    "    for column in df.columns:\n",
    "        limit = limits.get(column, default_limit)\n",
    "        df[column] = df[column].where(df[column] <= limit, None)\n",
    "\n",
    "    # Interpolation linéaire\n",
    "    df_interpolated = df.interpolate(method='linear')\n",
    "\n",
    "    # Remplacer les valeurs originales par les interpolées\n",
    "    df.update(df_interpolated)\n",
    "    return df\n",
    "\n",
    "def restrain_df_to_specific_period(df,coverage_period):\n",
    "    if coverage_period is not None:\n",
    "        df = df.loc[coverage_period]\n",
    "\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_trigram_correspondance():\n",
    "    ''' Some surprise : \n",
    "        Vieux Lyon : Jea\n",
    "        Gare d'oulins : OGA\n",
    "    '''\n",
    "    df = pd.DataFrame(columns = ['Station','COD_TRG'])\n",
    "    df['COD_TRG'] = ['AMP','BEL','BRO','COR',\n",
    "                     'CUI','CUS','FLA','GOR',\n",
    "                     'BLA','GRA','GUI','GIL',\n",
    "                     'HEN','HOT','LAE','MAS',\n",
    "                     'MER','LUM','PRY','PER',\n",
    "                     'SAN','SAX','VMY','JEA',\n",
    "                     'BON','CHA','VAI','VEN',\n",
    "                     'MAC','GAR','FOC','REP',\n",
    "                     'GER','DEB','JAU','CPA',\n",
    "                     'CRO','PAR','SOI','OGA']\n",
    "    \n",
    "    df['Station'] =['Ampère Victor Hugo','Bellecour','Brotteaux','Cordeliers',\n",
    "                    'Cuire','Cusset','Flachet','Gorge de Loup',\n",
    "                    'Grange Blanche','Gratte Ciel','Place Guichard','Guillotière',\n",
    "                    'Hénon','Hôtel de ville - Louis Pradel','Laënnec','Masséna',\n",
    "                    'Mermoz - Pinel','Monplaisir Lumière','Parilly','Perrache',\n",
    "                    'Sans Souci','Saxe - Gambetta','Valmy','Vieux Lyon',\n",
    "                    'Laurent Bonnevay','Charpennes','Gare de Vaise','Gare de Vénissieux',\n",
    "                    'Jean Macé','Garibaldi','Foch','République Villeurbanne',\n",
    "                    'Stade de Gerland','Debourg','Place Jean Jaurès','Croix Paquet',\n",
    "                    'Croix-Rousse','Part-Dieu','La soie',\"Gare d'Oullins\"]\n",
    "    return(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-2.0.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
